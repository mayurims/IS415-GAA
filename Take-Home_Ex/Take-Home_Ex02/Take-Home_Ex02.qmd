---
title: "Take-Home Excercise 02"
author: "Mayuri Salunke"
date: "30 January 2023"
date-modified: "`r Sys.Date()`"
execute: 
  echo: true
  eval: true
  message: false
  warning: false
editor: visual
---

# 1.0 Overview

As of the latest available data, Jakarta, the capital city of Indonesia, has been one of the hardest-hit regions in the country in terms of COVID-19 cases. The first confirmed case in Jakarta was reported on March 2, 2020, and since then, the number of cases has steadily increased.

As of February 24, 2023, the total number of confirmed cases in Jakarta has reached over 1.4 million, which is around 12% of the total cases in Indonesia. The number of active cases has decreased over the past few months, but there are still several thousand active cases in Jakarta.

The Jakarta government has implemented various measures to curb the spread of the virus, including social distancing rules, mandatory mask-wearing in public, and limiting public gatherings. The government has also conducted mass testing and contact tracing efforts to isolate those who have been infected.

Overall, the situation in Jakarta remains concerning, but the government's efforts to control the spread of the virus have helped to mitigate the impact of the pandemic on the city.

[![Jakarta records 584 new confirmed COVID-19 cases This article was published in thejakartapost.com with the title "Jakarta records 584 new confirmed COVID-19 cases".](images/image-565006615.png)](https://www.thejakartapost.com/news/2020/07/29/jakarta-records-584-new-confirmed-covid-19-cases.html)

# 2.0 Setup

## 2.1 Packages Used

-   sf : Used for importing geospatial data, assigning or transforming coordinate systems, and converting geospatial and aspatial data into a sf data frame

-   tidyverse : Used for transforming and better presentation of Data

-   tmap : Used for plotting static point patterns maps or interactive map

    kableExtra : Used for table customization

-   sfdep : Used for functions creates not present in spdep.

-   readxl : Used for reading Microsoft Excel files

-   plyr : Used for splitting, applying and combining data in a "split-apply-combine" framework

-   Kendall : Used for computnig Kendall tau and is used for Mann Kendall Test

-   plotly : Used for creating interactive web-based visualisations

```{r}
pacman::p_load(sf, tmap, kableExtra, tidyverse, sfdep, readxl, plyr, Kendall, plotly)
```

## 2.2 Datasets Used

```{r, echo = FALSE}

# initialise a dataframe of our geospatial and aspatial dataset details
datasets <- data.frame(
  Type=c("Geospatial",
         "Aspatial"),
  
  Name=c("DKI Jakarta Provincial Village Boundary",
         "District Based Vaccination History"),
  
  Format=c(".shp", 
           ".xlsx"),
  
  Source=c("(https://www.indonesia-geospasial.com/2020/04/download-shapefile-shp-batas-desa.html)",
           "(https://riwayat-file-vaksinasi-dki-jakarta-jakartagis.hub.arcgis.com/)"),
  
  Description=c("It has the District level boundary data of DKI Jakarta of 2019",
                "The muiliple excel files consists of all the vaccinations done at Village and District based.")
  )

# with reference to this guide on kableExtra:
# https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html
# kable_material is the name of the kable theme
# 'hover' for to highlight row when hovering, 'scale_down' to adjust table to fit page width
library(knitr)
library(kableExtra)
kable(datasets, caption="Datasets Used") %>%
  kable_material("hover", latex_options="scale_down")
```

Things to Note for Aspatial Data:

To retrieve the monthly cumulative records for the COVID-19 cases in Jakarta, I took the data compiled on the last of every month (e.g - 31st July, 30tt August ... ) from July 2021 to June 2022. I had started with taking the first of every month, however, i realized that the data for 1st March 2022 is actually of 2nd March 2022. And to have consistency in the data, I decided to use the last day of every month instead.

Further, the data consists of the following groups -

-   Vaccination of Elderly (Lansia)

-   Vaccination of Public Servant (Pelayan Publik)

-   Mutual Cooperation (Goton Royong) Vaccination

-   Vaccination of Health Workers (Tenaga Kesehatan)

-   Stage 3 (Tahapan) Vaccinations

-   Vaccination of Teenagers (Remaja)

# 3.0 Data Wrangling : Geospatial Data

## 3.1 Importing Geospatial Data

We will begin by importing Geospatial data into R by using the st_read() of sf package. It imports the BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA shapefile into R as a polygon data frame. We provide 2 arguments - dsn (which is the data path) and layer (the shapefile name)

```{r}
jakarta <- st_read(dsn="data/geospatial",
                   layer="BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA")
```

From the output message, we learn that:

-   Geometry type is multipolygon

-   269 features, 161 fields

-   Assigned CRS is [WGS 84](https://epsg.io/4326), the 'World Geodetic System 1984'. This is not right, and will be rectified in [3.2.3 Verifying + Transforming Coordinates](#verifying-transforming-coordinates)

## 3.2 Data Pre-processing {data-link="3.2 Data Pre-processing"}

### 3.2.1 Dropping Invalid Dimensions

Since, we only have one dataframe, there are no invalid dimensions, and hence, this step is not required.

### 3.2.2 Missing Values

Now lets check if there are any missing values.

```{r}
jakarta[rowSums(is.na(jakarta))!=0,]
```

We can see that there are 2 rows containing 'NA' values. However, since the data is big, we need to find the columns with missing NA values so that we can work on it.

```{r}
names(which(colSums(is.na(jakarta))>0))
```

We can see that there are two particular rows with missing values for KAB_KOTA (City), KECAMATAN (District) and DESA_KELUR (Village).

Hence, we remove rows with NA value in DESA_KELUR. There are other columns with NA present as well, however, since we are only looking at the sub-district level, it is most appropriate to remove DESA_KELUR

```{r}
jakarta <- na.omit(jakarta,c("DESA_KELUR"))
```

Lets double check if the rows with missing values are removed.

```{r}
jakarta[rowSums(is.na(jakarta))!=0,]
```

### 3.2.3 Verifying + Transforming Coordinates {#verifying-transforming-coordinates}

Now, we use the `st_crs()` to check the coordinate system of the data. As we can see, it uses the WGS 84 coordinate system. The data is using a Geographic projected system, however, this is system is not appropriate since we need to use distance and area measures.

```{r}
st_crs(jakarta)
```

Hence, we use `st_transform()` and not `st_set_crs()` as `st_set_crs()` assigns the EPSG code to the data frame. And we need to transform the data frame from geographic to projected coordinate system. We will be using crs=23845 (found from the [EPSG](https://epsg.io/?q=DGN95&page=3) for Indonesia).

```{r}
jakarta <- st_transform(jakarta, 23845)
```

Lets double check if CRS has been assigned

```{r}
st_crs(jakarta)
```

### 3.2.3 Removal of Outer Islands

Now that we have done our basic pre-processing, lets quickly visualize the data

```{r}
plot(st_geometry(jakarta))
```

As we can see from the diagram, `jakarta` includes both mainland and outer islands. And since we don't require the outer islands (as per the requirements), we can remove them.

**DIAGRAMM EXPLAINING THE DATAA**

We know that the date is grouped by KAB_KOTA (City), KECAMATAN (Sub-District) and DESA_KELUR (Village). Now, lets plot the map and see how we can use KAB_KOTA to remove the outer islands.

```{r}
tm_shape(jakarta) + 
  tm_polygons("KAB_KOTA")
```

From the map, we can see that all the cities in Jakarta start with 'Jakarta' as their prefix and hence, 'Kepulauan Seribu' are the other outer islands. When translated in English, the name means 'Thousand Islands'. Now we know what to remove, and we shall proceed with that.

```{r}
jakarta <- filter(jakarta, KAB_KOTA != "KEPULAUAN SERIBU")
```

Now, lets double check if the outer islands have been removed.

```{r}
tm_shape(jakarta) + 
  tm_polygons("KAB_KOTA")
```

### 3.2.4 Retaining first 9 fields of `jakarta`

Additionally, the assignment only requires us to retain the relevant fields - which are the first 9 fields.

```{r}
jakarta <- jakarta[, 0:9]
```

### 3.2.5 Renaming Columns with Translation

Since the columns names are in Indonesian, lets rename them to English for better ease of use.

```{r}
jakarta <- jakarta %>% 
  
  dplyr::rename(
    Object_ID=OBJECT_ID,
    Village_Code=KODE_DESA, 
    Code=KODE,
    Village=DESA,
    Province=PROVINSI, 
    City=KAB_KOTA, 
    District=KECAMATAN, 
    Sub_District=DESA_KELUR,
    Total_Population=JUMLAH_PEN
    )
```

# 4.0 Data Wrangling : Aspatial Data

## 4.1 Pre-Importing EDA

For this assignment, we will be working on data from July 2021 to June 2022, as a result we will be having several excel files. Thus, it is safer to preview the data first and check for any discrepancies, before compiling all the data.

```{r}
jul2021 <- read_xlsx("data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Juli 2021).xlsx")
glimpse(jul2021)
```

The above output shows that there are no duplicates. So we will check for all of them just to ensure that there are no duplicates and no inconsistencies

::: panel-tabset
**August 2021**

```{r}
aug2021 <- read_xlsx("data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Agustus 2021).xlsx")
glimpse(aug2021)
```

**September 2021**

```{r}
sep2021 <- read_xlsx("data/aspatial/Data Vaksinasi Berbasis Kelurahan (30 September 2021).xlsx")
glimpse(sep2021)
```

**October 2021**

```{r}
oct2021 <- read_xlsx("data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Oktober 2021).xlsx")
glimpse(oct2021)
```

**November 2021**

```{r}
nov2021 <- read_xlsx("data/aspatial/Data Vaksinasi Berbasis Kelurahan (30 November 2021).xlsx")
glimpse(nov2021)
```

**December 2021**

```{r}
dec2021 <- read_xlsx("data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Desember 2021).xlsx")
glimpse(dec2021)
```

**January 2021**

```{r}
jan2022 <- read_xlsx("data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Januari 2022).xlsx")
glimpse(jan2022)
```
:::

::: panel-tabset
**February 2022**

```{r}
feb2022 <- read_xlsx("data/aspatial/Data Vaksinasi Berbasis Kelurahan (27 Februari 2022).xlsx")
glimpse(feb2022)
```

**March 2022**

```{r}
mar2022 <- read_xlsx("data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Maret 2022).xlsx")
glimpse(mar2022)
```

**April 2022**

```{r}
apr2022 <- read_xlsx("data/aspatial/Data Vaksinasi Berbasis Kelurahan (30 April 2022).xlsx")
glimpse(apr2022)
```

**May 2022**

```{r}
may2022 <- read_xlsx("data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Mei 2022).xlsx")
glimpse(may2022)
```

**June 2022**

```{r}
jun2022 <- read_xlsx("data/aspatial/Data Vaksinasi Berbasis Kelurahan (30 Juni 2022).xlsx")
glimpse(jun2022)
```
:::

As we can see, till February 2022, the number of columns is 27. However, from March 2022 the number of columns is 34. Upon researching about the difference between the number of columns, i realized that the data files from March 2022 has a separate column for Dosage 3, where has all the data files before March 2022 don't have any dosage 3 column. This could attribute to the the fact that, dosage 3 vaccination was only provided from March 2022.

Hence, we will address this issue in the next section.

## 4.2 Creating an Aspatial Data Pre-Processing Function

For the assignment, we don't require all the columns. Only the following columns are required -

-   KODE KELURAHAN (Sub-District Code)

-   KELURAHAN (Sub-District)

-   SASARAN (Target)

-   BELUM VASKIN (Yet to be vaccinated / Not yet vaccinated)

This solves the issue of some months having extra columns. However, we need to create an 'Date' column that shows the month and year of the observation, which is originally the file name. Each file has the naming convention 'Data Vaksinasi Berbasis Keluarahan (DD Month YYYY).

We will be combining the mentioned steps into a function

```{r}
# takes in an aspatial data filepath and returns a processed output
aspatial_preprocess <- function(filepath){
  # We have to remove the first row of the file (subheader row) and hence, we use [-1,] to remove it.
  result_file <- read_xlsx(filepath)[-1,]
  
  # We then create the Date Column, the format of our files is: Data Vaksinasi Berbasis Kelurahan (DD Month YYYY)
  # While the start is technically "(", "(" is part of a regular expression and leads to a warning message, so we'll use "Kelurahan" instead. The [[1]] refers to the first element in the list.
  # We're loading it as DD-Month-YYYY format
  # We use the length of the filepath '6' to get the end index (which has our Date)
  # as such, the most relevant functions are substr (returns a substring) and either str_locate (returns location of substring as an integer matrix) or gregexpr (returns a list of locations of substring)
  # reference https://stackoverflow.com/questions/14249562/find-the-location-of-a-character-in-string
  startpoint <- gregexpr(pattern="Kelurahan", filepath)[[1]] + 11
  
  result_file$Date <- substr(filepath, startpoint, nchar(filepath)-6)
  
  # Retain the Relevant Columns
  result_file <- result_file %>% 
    select("Date", 
           "KODE KELURAHAN", 
           "KELURAHAN", 
           "SASARAN", 
           "BELUM VAKSIN")
  return(result_file)
}
```

## 4.3 Feeding files into the aspatial_preprocess function

Instead of manually feeding the files, line by line, we will be using the function list.files() and lapply() to get our process done faster!

```{r}
# in the folder 'data/aspatial', find files with the extension '.xlsx' and add it to our fileslist 
# the full.names=TRUE prepends the directory path to the file names, giving a relative file path - otherwise, only the file names (not the paths) would be returned 
# reference: https://stat.ethz.ch/R-manual/R-devel/library/base/html/list.files.html
fileslist <-list.files(path = "data/aspatial", pattern = "*.xlsx", full.names=TRUE)

# afterwards, for every element in fileslist, apply aspatial_process function
dflist <- lapply(seq_along(fileslist), function(x) aspatial_preprocess(fileslist[x]))
```

We will then convert the dflist into an actual dataframe with ldply() using the below code

```{r}
vaccination_jakarta <- ldply(dflist, data.frame)
```

Now, lets take a look into our data

```{r}
glimpse(vaccination_jakarta)
```

## 4.4 Formatting Date Column

The Dates are in Bahasa Indonesia, and hence, we need to translate them to English for ease of use. However, since the values in Date column were derived from sub-strings, they are in a string format and thus, first need to be converted to datetime.

```{r}
# parses the 'Date' column into Month(Full Name)-YYYY datetime objects
# reference: https://stackoverflow.com/questions/53380650/b-y-date-conversion-gives-na

# locale="ind" means that the locale has been set as Indonesia
Sys.setlocale(locale="ind")
```

```{r}
vaccination_jakarta$Date <- c(vaccination_jakarta$Date) %>% 
  as.Date(vaccination_jakarta$Date, format ="%d %B %Y")

glimpse(vaccination_jakarta)
```

## 4.5 Renaming the Column names into English

We can now rename the column names into English for ease of use

```{r}
# renames the columns in the style New_Name = OLD_NAME
vaccination_jakarta <- vaccination_jakarta %>% 
  dplyr::rename(
    Date=Date,
    Sub_District_Code=KODE.KELURAHAN,
    Sub_District=KELURAHAN, 
    Target=SASARAN, 
    Not_Yet_Vaccinated=BELUM.VAKSIN
    )
```

```{r}
glimpse(vaccination_jakarta)
```

As we can see, the columns have successfully been renamed in English.

## 4.5 Further Data Processing

Now that we have our Aspatial data into our desired dataframe, lets perform any pre-processing to check out for anything we might have missed.

```{r}
vaccination_jakarta[rowSums(is.na(vaccination_jakarta))!=0,]
```

From the output, we can see there are no missing values.

# 5.0 Geospatial Data Integration

## 5.1 Preliminary joining + EDA

Now that we have both our Geospatial and Aspatial data, we need to join them. However, we need to first find a common header to join them.

```{r}
colnames(jakarta)
```

```{r}
colnames(vaccination_jakarta)
```

We can see that both the dataframes have Sub_District and hence we can join them by the Sub_District and Sub_District_Code (same as Village_Code in 'jakarta').

```{r}
# joins vaccination_jakarta to jakarta based on Sub_District and  Sub_District_Code
combined_jakarta <- left_join(jakarta, vaccination_jakarta,
                              by=c(
                                "Village_Code"="Sub_District_Code", 
                                "Sub_District"="Sub_District")
                              )
```

Now, lets take a look into the columns of combined_jakarta

```{r}
colnames(combined_jakarta)
```

We can then subcategorize the data into 'Target population to be Vaccinated' , 'Not Yet Vaccinated Population' and 'Total Population'

```{r}
target = tm_shape(combined_jakarta)+
  tm_fill("Target") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title="Target Count")

not_yet_vaccinated = tm_shape(combined_jakarta)+
  tm_fill("Not_Yet_Vaccinated") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title="Not Yet Vaccinated Count")

total_population = tm_shape(combined_jakarta)+
  tm_fill("Total_Population") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title="Total Population Count")

tmap_arrange(target, not_yet_vaccinated, total_population)
```

What is interesting to note, is that there seems to be a 'Missing' value in the Target and Not_Yet_Vaccinated maps. Even though, when we had previously checked for missing values, it didn't show any missing values. However, we shall double check again.

```{r}
jakarta[rowSums(is.na(jakarta))!=0,]
```

```{r}
vaccination_jakarta[rowSums(is.na(vaccination_jakarta))!=0,]
```

As seen, we don't have any mission values in our dataframes. Hence, the most likely reasons for the missing values must be due to mismatched values when we combined (left-join) the Geospatial and Aspatial data.

## 5.2 Identifying Mismatched Sub-District Records

Since, we had conducted left-join using the Sub-District, there must be a mismatch in the naming of the subdistricts. Lets check it by looking at the unique subdistrict names in both `jakarta` and `vaccination_jakarta`

```{r}
# checks for unique values of Sub_District in jakarta that aren't already present in vaccination_jakarta and vice versa
jakarta_subdistrict <- c(jakarta$Sub_District)
vaccination_subdistrict <- c(vaccination_jakarta$Sub_District)

unique(jakarta_subdistrict[!(jakarta_subdistrict %in% vaccination_subdistrict)])
```

```{r}
unique(vaccination_subdistrict[!(vaccination_subdistrict %in% jakarta_subdistrict)])
```

We can see that there are same names in both the list but are just written in different ways. However, there are 6 words in the `vaccination_subdistrict` which are not in the `jakarta_subdistrict`. We shall take a look into that after we first correct the mismatched values.

Now, lets view the differences --

```{r}
# initialise a dataframe of our cases vs bd subdistrict spelling
spelling <- data.frame(
  Aspatial_Cases=c("BALE KAMBANG", "HALIM PERDANA KUSUMAH", "JATI PULO", "KAMPUNG TENGAH", "KERENDANG", "KRAMAT JATI", "PAL MERIAM", "PINANG RANTI", "RAWA JATI"),
  Geospatial_BD=c("BALEKAMBAG", "HALIM PERDANA KUSUMA", "JATIPULO", "TENGAH", "KRENDANG", "KRAMATJATI", "PALMERIAM", "PINANGRANTI", "RAWAJATI")
  )

# with dataframe a input, outputs a kable
library(knitr)
library(kableExtra)
kable(spelling, caption="Mismatched Records") %>%
  kable_material("hover", latex_options="scale_down")
```

As we can see these records have the same name, except that there is not standardization on how it is to be written. As a result, there is a mismatch between them. So now, lets correct this mismatch

```{r}
# We are replacing the mistmatched values in jakarta with the correct value
jakarta$Sub_District[jakarta$Sub_District == 'BALEKAMBANG'] <- 'BALE KAMBANG'
jakarta$Sub_District[jakarta$Sub_District == 'HALIM PERDANA KUSUMA'] <- 'HALIM PERDANA KUSUMAH'
jakarta$Sub_District[jakarta$Sub_District == 'JATIPULO'] <- 'JATI PULO'
jakarta$Sub_District[jakarta$Sub_District == 'KALI BARU'] <- 'KALIBARU'
jakarta$Sub_District[jakarta$Sub_District == 'TENGAH'] <- 'KAMPUNG TENGAH'
jakarta$Sub_District[jakarta$Sub_District == 'KRAMATJATI'] <- 'KRAMAT JATI'
jakarta$Sub_District[jakarta$Sub_District == 'KRENDANG'] <- 'KERENDANG'
jakarta$Sub_District[jakarta$Sub_District == 'PALMERIAM'] <- 'PAL MERIAM'
jakarta$Sub_District[jakarta$Sub_District == 'PINANGRANTI'] <- 'PINANG RANTI'
jakarta$Sub_District[jakarta$Sub_District == 'RAWAJATI'] <- 'RAWA JATI'
```

Now, lets look into the 6 subdistrict names that we say in `vaccination_jakarta` which were not present in `jakarta`. This ideally suggests that these districts are not a part of Jakarta, however, we need to double check it just to be sure.

![Unique Subdistricts](images/image-2131298069.png)

![Subdistricts in Jakarta](images/image-779347305.png)

This can be verified by taking a look at our excel file. The 2nd screenshot shows the subdistricts in Jakarta as they have the name Jakarta in 'WILAYAH KOTA' which means City Area. However, as seen in the 1st screenshot, these 6 subdistricts do not have the name Jakarta in 'WILAYAH KOTA' confirming the fact that they are not a part of Jakarta. Hence, we need to remove them.

```{r}
vaccination_jakarta <- vaccination_jakarta[!(vaccination_jakarta$Sub_District=="PULAU HARAPAN" | vaccination_jakarta$Sub_District=="PULAU KELAPA" | vaccination_jakarta$Sub_District=="PULAU PANGGANG" | vaccination_jakarta$Sub_District=="PULAU PARI" | vaccination_jakarta$Sub_District=="PULAU TIDUNG" | vaccination_jakarta$Sub_District=="PULAU UNTUNG JAWA"), ]
```

## 5.3 Rejoining + EDA

Now, that we have a more standardized common identifier and have removed all the unnecessary values from our data, we can join them again once more!

```{r}
# joins vaccination_jakarta to jakarta based on Sub_District and  Sub_District_Code
combined_jakarta <- left_join(jakarta, vaccination_jakarta,
                              by=c(
                                "Village_Code"="Sub_District_Code", 
                                "Sub_District"="Sub_District")
                              )
```

Let's check if there are any NA values now

```{r}
combined_jakarta[rowSums(is.na(combined_jakarta))!=0,]
```

Let's re-visualize the data into 'Target population to be Vaccinated' , 'Not Yet Vaccinated Population' and 'Total Population'

```{r}
target = tm_shape(combined_jakarta)+
  tm_fill("Target") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title="Target Count")

not_yet_vaccinated = tm_shape(combined_jakarta)+
  tm_fill("Not_Yet_Vaccinated") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title="Not Yet Vaccinated Count")

total_population = tm_shape(combined_jakarta)+
  tm_fill("Total_Population") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title="Total Population Count")

tmap_arrange(target, not_yet_vaccinated, total_population)
```

# 

# 6.0 Calculations for Vaccination Rate

Before we proceed with EDA and Thematic mapping, we need to compute the monthly vaccination rate (in %) at the sub-district level

$$
Vaccination Rate = ((Target - Numberofpeople not vaccinated) / Target) * 100
$$

Note : We use 'Target' (SASARAN) instead of Population, as the Indonesian government excludes people aged 14 and below for vaccination. As a result, they will be excluded from the total population.

```{r}
# grouping based on the sub-district and date
vaccination_rate <- vaccination_jakarta %>%
  inner_join(jakarta, by=c("Sub_District" = "Sub_District")) %>%
  group_by(Sub_District, Date) %>%
  dplyr::summarise(`vaccination_rate` = ((Target-Not_Yet_Vaccinated)/Target)*100) %>%
  
  #afterwards, pivots the table based on the Dates, using the cumulative case rate as the values
  ungroup() %>% pivot_wider(names_from = Date,
              values_from = vaccination_rate)
```

Now, lets look at how computed vaccination_rate looks like

```{r}
vaccination_rate
```

## 6.1 Converting dataframs to sf objects

Before we move on into the mapping, we need to convert the dataframes into sf objects. We will convert combined_jakarta and vaccination_rate which will be using for our analysis.

```{r}
combined_jakarta <- st_as_sf(combined_jakarta)

# need to join our previous dataframes with the geospatial data to ensure that geometry column is present
vaccination_rate <- vaccination_rate%>% left_join(jakarta, by=c("Sub_District"="Sub_District"))
vaccination_rate <- st_as_sf(vaccination_rate)
```

# 7.0 Choropleth Mapping and Anlaysis

There are multiple ways to classify data in Choropleth maps, here are the some of them -

1.  Equal Interval - This method divides the range of data into equal-sized intervals. However, this can be misleading as it does not take into account the distribution of values
2.  Quantile - This method divides the data into equal-sized groups, each containing an equal number of data points. However, they are quite sensitive to outliers
3.  Jenks - This method uses statistical algorithm to group data into classes based on natural break/gaps in the distribution of values (even with low variance).

For this assignment, I am choosing the Jenks classification method as it seeks to minimize the variance within each group while maximizing the variance between groups. As a result it accurately reflects the distribution of values in the data.

## 7.1.1 Jenks Choropleth Maps

After testing, I have decided to stick to 6 classes, as too many classes makes it hard for the human eye to differentiate between the gradients, while too few makes it hard for any differentiation to be seen. Hence, 6 classes is the optimum number of classes.

```{r}
# using the jenks method, with 6 classes
tmap_mode("plot")
tm_shape(vaccination_rate)+
  tm_fill("2021-07-31", 
          n= 6,
          style = "jenks", 
          title = "Vaccination Rate") +
  tm_layout(main.title = "Distribution of Vaccination Rate in July 2021",
            main.title.position = "center",
            main.title.size = 1,
            legend.height = 0.5, 
            legend.width = 0.4,
            frame = TRUE) +
  tm_borders(alpha = 0.5)
```

We have to plot it for all the months, hence, let's have a function to help us do it!

```{r}
# input: the dataframe and the variable name - in this case, the month 
# with style="jenks" for the jenks classification method
jenks_plot <- function(df, varname) {
  tm_shape(vaccination_rate) +
    tm_polygons() +
  tm_shape(df) +
    tm_fill(varname, 
          n= 6,
          style = "jenks", 
          title = "Vaccination Rate") +
    tm_layout(main.title = varname,
          main.title.position = "center",
          main.title.size = 1.2,
          legend.height = 0.45, 
          legend.width = 0.35,
          frame = TRUE) +
    tm_borders(alpha = 0.5)
}
```

```{r}
tmap_mode("plot")
tmap_arrange(jenks_plot(vaccination_rate, "2021-07-31"),
             jenks_plot(vaccination_rate, "2021-08-31"),
             jenks_plot(vaccination_rate, "2021-09-30"),
             jenks_plot(vaccination_rate, "2021-10-31"))
```

```{r}
tmap_mode("plot")
tmap_arrange(jenks_plot(vaccination_rate, "2021-11-30"),
             jenks_plot(vaccination_rate, "2021-12-31"),
             jenks_plot(vaccination_rate, "2022-01-31"),
             jenks_plot(vaccination_rate, "2022-02-27"))
```

```{r}
tmap_mode("plot")
tmap_arrange(jenks_plot(vaccination_rate, "2022-03-31"),
             jenks_plot(vaccination_rate, "2022-04-30"),
             jenks_plot(vaccination_rate, "2022-05-31"),
             jenks_plot(vaccination_rate, "2022-06-30"))
```

Plotting all 12 maps together

```{r}
tmap_mode("plot")
tmap_arrange(jenks_plot(vaccination_rate, "2021-07-31"),
             jenks_plot(vaccination_rate, "2021-08-31"),
             jenks_plot(vaccination_rate, "2021-09-30"),
             jenks_plot(vaccination_rate, "2021-10-31"),
             jenks_plot(vaccination_rate, "2021-11-30"),
             jenks_plot(vaccination_rate, "2021-12-31"),
             jenks_plot(vaccination_rate, "2022-01-31"),
             jenks_plot(vaccination_rate, "2022-02-27"),
             jenks_plot(vaccination_rate, "2022-03-31"),
             jenks_plot(vaccination_rate, "2022-04-30"),
             jenks_plot(vaccination_rate, "2022-05-31"),
             jenks_plot(vaccination_rate, "2022-06-30")
             )
```

## 7.1.2 Observations from Jenks Choropleth maps

We can notice the following things for sub-districts regarding high vaccination rate (sub-district in darker colour) :

-   The highest vaccination rate from the periods of 31/07/2021 to 31/08/2021 seems to be more concentrated towards the North of Jakarta.

-   From the period of 30/09/2021 to 30/11/2021, the high vaccination rates are more spread out throughout Jakarta

-   The high vaccination rates seem to be more concentrated towards the South and East of Jakarta from the period of 31/12/2021.

We can notice the following things for sub-districts regarding low vaccination rate (sub-district in lighter colour) :

-   The map of 31/08/2021 shows more sub-districts with a lighter colour (indicating) low vaccination rate

-   However, it looks like most of the sub-district caught up the following month (30/09/2021) with a more uniform colour (i.e. fewer sub-districts with light colours)

-   From the period 31/01/2022, there were more sub-districts with lower vaccination rate (lighter colour). Especially sub-districts in the North and West (except for a few sub-districts in the North with a relatively higher vaccination rate). Further, some of the sub-districts in the Central seem to have the lowest vaccination rate consistently from as seen from the maps from 27/02/2022 onward.

## **7.2.1 Spatio-Temporal Mapping With Custom Breakpoints**

In the above section, we see that each month has its own vaccination rate range, but in order to see the spatio-temporal progression of vaccination rates, we need to set a fixed range. Hence, we need to customise our breakpoints into 6 breakpoints (just like we did above into 6 classes)

For that, we need to find the highest and lowest vaccination rate. The highest vaccination rate will come from the latest month - June 2022. Whereas, the lowest vaccination rate will come from the first month - July 2021.

```{r}
max(vaccination_rate$`2022-06-30`)
```

```{r}
min(vaccination_rate$`2021-07-31`)
```

```{r}
summary(vaccination_rate)
```

Our range for the breakpoints is 37 to 90. After experimenting with the breakpoints, I have chosen the following breakpoints as they provide a proper categorization such that we can differentiate sub-districts with lower vaccination rate from those with higher vaccination rate (i.e. not making majority of sub-districts) in the same colour.

```{r}
breakpoints = c(37, 55, 72, 80, 84, 90)
```

Now lets create a function to help us plot for 12 months

```{r}
break_plot <- function(df, varname) {
  tm_shape(vaccination_rate) +
    tm_polygons() +
  tm_shape(df) +
    tm_fill(varname, 
          breaks= breakpoints,
          title = "Vaccination Rate") +
    tm_layout(main.title = varname,
          main.title.position = "center",
          main.title.size = 1.2,
          legend.height = 0.45, 
          legend.width = 0.35,
          frame = TRUE) +
    tm_borders(alpha = 0.5)
}
```

```{r}
tmap_mode("plot")
tmap_arrange(break_plot(vaccination_rate, "2021-07-31"),
             break_plot(vaccination_rate, "2021-08-31"),
             break_plot(vaccination_rate, "2021-09-30"),
             break_plot(vaccination_rate, "2021-10-31"))
```

```{r}
tmap_mode("plot")
tmap_arrange(break_plot(vaccination_rate, "2021-11-30"),
             break_plot(vaccination_rate, "2021-12-31"),
             break_plot(vaccination_rate, "2022-01-31"),
             break_plot(vaccination_rate, "2022-02-27"))
```

```{r}
tmap_mode("plot")
tmap_arrange(break_plot(vaccination_rate, "2022-03-31"),
             break_plot(vaccination_rate, "2022-04-30"),
             break_plot(vaccination_rate, "2022-05-31"),
             break_plot(vaccination_rate, "2022-06-30"))
```

## **7.2.2 Observations from Spatio-Temporal Map**

![Vaccination Rate gif created using https://imgflip.com/gif-maker](images/7ce334-02.gif){fig-align="center"}

Now, we can supplement our our observations made in [6.1.2 Observations from Jenks Choropleth maps](https://is415-mayurims.netlify.app/take-home_ex/take-home_ex02/take-home_ex02#observations-from-jenks-choropleth-maps). Here are the observations -

-   In July 2021, we can see a slightly higher vaccination rate in the North and Central districts

-   In the month August and September 2021, there seems to be a more uniform distribution of vaccination rate (almost same colour range throughout Jakarta)

-   However, from December 2021, some sub-districts have a consistent/increasing high vaccination rate. This seems to be most evident in the sub-districts in the South and East district (with most of them having high Vaccination Rate). But we can also see an increasing vaccination rate in many sub-districts in the North and Central Jakarta.

# **8.0 Local Gi\* Anlaysis**

I will be conducting a Local Gi\* Analysis, also known as Local Spatial Autocorrelation which will be used to identify ideas sub-districts in Jakarta with high or low vaccination rate. Time-series analysis will be conducted to understand the evolution of spatial hot spots and cold spots across time.

**Interpretation of Gi\* values**

-   Gi∗\>0 : indicates sub-districts with higher vaccination rate than average

-   Gi∗\<0 : indicates sub-districts with higher vaccination rate than average

For significant (p_value\<0.05) Gi\* statistic values, two spatial associations can be inferred :

-   **Hot spot areas**: where Gi∗>0, indicating that a location is associated with relatively high values in the surrounding locations.

-   **Cold spot areas**: where Gi∗<0, indicating that a location is associated with relatively low values in the surrounding locations.

## **8.1 Computing Local Gi\* Values of Monthly Vaccination Rate**

**8.1.1 Create an Attribute Table**

Before we create a time series cube, we need to first have an attribute table with the relevant data - Date, Sub_District and Vaccination Rate.

```{r}
# Make new vaccination attribute table with Date, Sub_District, Target, Not_Yet_Vaccinated
vacc_attr_table <- combined_jakarta %>% select(10, 8, 11, 12) %>% st_drop_geometry()

# Adding a new field for Vaccination_Rate
vacc_attr_table$Vaccination_Rate <- ((vacc_attr_table$Target - vacc_attr_table$Not_Yet_Vaccinated) / vacc_attr_table$Target) *100

# Vaccination attribute table with just Date, Sub_District, Vaccination_Rate
vacc_attr_table <- tibble(vacc_attr_table %>% select(1,2,5))
```

Now, lets look into the attribute table we created and make sure everything is correct

```{r}
vacc_attr_table
```

### **8.1.2 Create a Spatio-Temporal Cube**

Now we use `spacetime()` to create an spatio-temporal cube

```{r}
vacc_rate_st <- spacetime(vacc_attr_table, jakarta,
                          .loc_col = "Sub_District",
                          .time_col = "Date")
```

Next we need to verify if `vacc_rate_st` is indeed a space-time cube by using the `is_spacetime_cube()` of sfdep package

```{r}
is_spacetime_cube(vacc_rate_st)
```

The **TRUE** return confirms that `vacc_rate_st` object is indeed an time-space cube.

### **8.1.3 Derive Spatial Weights**

Next, we will compute the local Gi\* weights, but before that we need derive the spatial weights. The below code chunk is used to identify neighbors and derive an inverse distance weights.

```{r}
vacc_rate_nb <- vacc_rate_st %>%
  activate("geometry") %>%
  mutate(nb = include_self(st_contiguity(geometry)),
         wt = st_inverse_distance(nb, geometry,
                                  scale=1,
                                  alpha=1),
         .before=1) %>%
  set_nbs("nb") %>%
  set_wts("wt")
```

Note -

-   `activate()` is used to activate the geometry context

-   `mutate()` is used to create two new columns *nb* and *wt*.

-   Then we will activate the data context again and copy over the nb and wt columns to each time-slice using `set_nbs()` and `set_wts()`

    -   row order is very important so do not rearrange the observations after using `set_nbs()` or `set_wts()`.

As a result, this dataset has neighbors and weights for each time-slice

```{r}
head(vacc_rate_nb)
```

We will use `set.seed()` before performing simulation to ensure that the computation is reproducible. When a random number generator is used, the results can be different each time the code is run, which makes it difficult to reproduce results. By setting the seed to a specific value (e.g., **`set.seed(1234)`**), the same random numbers will be generated each time the code is run, making the results reproducible and consistent.

```{r}
set.seed(1234)
```

### **8.1.4 Computing Gi\* Value**

We will now compute the Gi\* value for each sub-district, grouping by Date

```{r}
gi_values <- vacc_rate_nb |>
  group_by(Date) |>
  mutate(gi_values = local_gstar_perm(
    Vaccination_Rate, nb, wt, nsim=99)) |>
      tidyr::unnest(gi_values)
```

Let's take a look at the Gi\* values calculated

```{r}
gi_values
```

## **8.2 Visualizing the Gi\* values of Monthly Vaccination Rate**

In order for us to be able to visualize the Gi\* values of the monthly vaccination rate, we need to join it with `combined_jakarta`, to be able to plot the Gi\* values on the map. As the `gi_values` do not have any coordinates.

```{r}
jakarta_gi_values <- combined_jakarta %>%
  left_join(gi_values)
```

We can see that, it has joined them by 'Sub_District' and 'Date'. Now, lets look into what our `jakarta_gi_values` look like

```{r}
jakarta_gi_values
```

Now, we can start with the visualization process. Let's proceed with visualizing the first month (July 2021). We will be plotting both the Gi\* value and the p-value of Gi\* for the Vaccination Rates.

Note - As per requirement, we will only be plotting the significant (i.e. p-value \< 0.05)

```{r}
gi_value_plot <- function(date, title) {
  gi_star_map = tm_shape(filter(jakarta_gi_values, Date == date)) +
    tm_fill("gi_star") +
    tm_borders(alpha=0.5) +
    tm_view(set.zoom.limits = c(6,8)) +
    tm_layout(main.title = paste("Gi* values for vaccination rates in", title), main.title.size=0.8)

  p_value_map = tm_shape(filter(jakarta_gi_values, Date == date)) +
    tm_fill("p_sim",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) +
    tm_borders(alpha=0.5) + 
    tm_layout(main.title = paste("p-values of Gi* for vaccination rates in", title), main.title.size=0.8)

  tmap_arrange(gi_star_map, p_value_map)
}
```

```{r}
gi_value_plot("2021-07-31", "July 2021")
```

```{r}
gi_value_plot("2021-08-31", "August 2021")
```

```{r}
gi_value_plot("2021-09-30", "September 2021")
```

```{r}
gi_value_plot("2021-10-31", "October 2021")
```

```{r}
gi_value_plot("2021-11-30", "November 2021")
```

```{r}
gi_value_plot("2021-12-31", "December 2021")
```

```{r}
gi_value_plot("2022-01-31", "January 2022")
```

```{r}
gi_value_plot("2022-02-27", "February 2022")
```

```{r}
gi_value_plot("2022-03-31", "March 2022")
```

```{r}
gi_value_plot("2022-04-30", "April 2022")
```

```{r}
gi_value_plot("2022-05-31", "May 2022")
```

```{r}
gi_value_plot("2022-06-30", "June 2022")
```

## **8.3 Analyzing the Results**

The p-value represents the probability of observing a clustering. Sub-districts with significant p-value (i.e., p_value\<0.05) suggests that the observed pattern is unlikely to have occurred by chance and may indicate the presence of a spatial process. Hence, the vaccination rate of the sub-district at that
period is significant. From the maps plotted, we see that there is in increase in number of sub-districts (with p_values\<0.05) in the southern and eastern sub-district.

Now, lets find the hot and cold spots. The above code filters our sub-districts with p-value\<0.05. Hence, we can find which sub-districts are hot or cold spots, depending on their g-value.

```{r}
significant <- function(date, title){
 significant_gi = tm_shape(filter(jakarta_gi_values, Date == date)) +
    tm_polygons() +
    tm_shape(filter(jakarta_gi_values, Date == date) %>% filter(p_sim <0.05)) +
    tm_fill("gi_star",
            style="equal",
            n=5) +
    tm_borders(alpha = 0.5) +
    tm_layout(main.title = paste("Siginificant Gi* values in ", title), main.title.size=0.8)
  return(significant_gi)
}
```

```{r}
tmap_arrange(
  significant("2021-07-31", "July 2021"),
  significant("2021-08-31", "August 2021"),
  significant("2021-09-30", "September 2021"),
  significant("2021-10-31", "October 2021")
)
```

```{r}
tmap_arrange(
  significant("2021-11-30", "November 2021"),
  significant("2021-12-31", "December 2021"),
  significant("2022-01-31", "January 2022"),
  significant("2022-02-27", "February 2022")
)
```

```{r}
tmap_arrange(
  significant("2022-03-31", "March 2022"),
  significant("2022-04-30", "April 2022"),
  significant("2022-05-31", "May 2022"),
  significant("2022-06-30", "June 2022")
  )
```

Sub-districts with gi_star \> 0 are hot spot areas, where those \< 0 are cold spot areas. Hot spot areas are areas with clustering of high concentration of vaccination rate. Where as cold spot areas are sub-districts with low concentration. In the above maps, sub-districts in the shade of green are hot spot areas and those in the shades of red are cold-spot areas.

In the beginning, there were more hot-spot areas in the North Jakarta, however, we see a change where most of the hotspots are now concentrated in the South Jakarta. This could be due to higher percentage of ageing population in South Jakarta or an increase in availability and accessibility of vaccine sites in South Jakarta. For the cold spots, some sub-districts in the Center seem to be a cold-spot. This suggests that there is a continuous shortage of vaccine or that the residents are unwilling to take the vaccine.

# 9.0 Emerging Hot Spot Anlaysis (EHSA)

Emerging Hot Spot Analysis (EHSA) is a spatio-temporal analysis method for revealing and describing how hot spot and cold spot areas evolve over time. Since, we have already built a space-time cube and calculate the Gi\* statistict, we can directly conduct the Mann-Kendall trend test to evaluate 3 sub-districts for a trend. The Mann-Kendall test is a non-parametric statistical method used to analyze trends in time series data. For this analysis, I will be choosing HALIM PERDANA KUSUMAH, KOTA BAMBU SELATAN and KAMAL.

Here are the hypothesis for Mann-Kendall Test --

-   H~0~: There is no trend in the data, meaning that the data points are independent and identically distributed

-   H~1~: There is a trend (positive or negative)

We will be observing 2 values -

-   tau - It is a measure of strength and direction a monotonic trend between two variables. It ranges from +1 to -1, where a value of 1 indicates a perfect increasing monotonic trend, a value of -1 indicates a perfect decreasing monotonic trend, and a value of 0 indicates no monotonic trend.

-   sl - This stands for significance level

## 9.1 Mann-Kendall Trend Test

### 9.1.1 Sub-District -- Halim Perdana Kusumah

```{r}
halim_pk <- gi_values |>
  ungroup() |>
  filter(Sub_District == "HALIM PERDANA KUSUMAH") |>
  select(Sub_District, Date, gi_star)
```

Now, we plot the result by using ggplot2 functions.

```{r}
ggplot(data = halim_pk, 
       aes(x = Date, 
           y = gi_star)) +
  geom_line() +
  theme_light()
```

We can also plot this interactively

```{r}
p <- ggplot(data = halim_pk, 
       aes(x = Date, 
           y = gi_star)) +
  geom_line() +
  theme_light()

ggplotly(p)
```

```{r}
halim_pk %>%
  summarise(mk = list(
    unclass(
      Kendall::MannKendall(gi_star)))) %>% 
  tidyr::unnest_wider(mk)
```

The p-value is 0.086 which is \> 0.05 hence p-value is not significant. This result tells us that there is no trend and the data points are independent and identically distributed.

### 9.1.2 Sub-District -- Bale Kambang

```{r}
bale_k <- gi_values |>
  ungroup() |>
  filter(Sub_District == "BALE KAMBANG") |>
  select(Sub_District, Date, gi_star)
```

Now, we plot the results

```{r}
p <- ggplot(data = bale_k, 
       aes(x = Date, 
           y = gi_star)) +
  geom_line() +
  theme_light()

ggplotly(p)
```

```{r}
bale_k %>%
  summarise(mk = list(
    unclass(
      Kendall::MannKendall(gi_star)))) %>% 
  tidyr::unnest_wider(mk)
```

The tau value is greater than 0 indicating a monotonic increasing trend. Further, p-value is 0.01 which is \< 0.05 hence p-value is significant. This result tells us that here is an overall upward (positive) trend. This means that as time passes, the Gi\* value will increase, thus a higher clustering of high vaccination rate. That is more people will be getting their vaccine.

### 9.1.3 Sub-District -- Kamal

```{r}
kamal <- gi_values |>
  ungroup() |>
  filter(Sub_District == "KAMAL") |>
  select(Sub_District, Date, gi_star)
```

Now, we plot the results

```{r}
p <- ggplot(data = kamal, 
       aes(x = Date, 
           y = gi_star)) +
  geom_line() +
  theme_light()

ggplotly(p)
```

```{r}
kamal %>%
  summarise(mk = list(
    unclass(
      Kendall::MannKendall(gi_star)))) %>% 
  tidyr::unnest_wider(mk)
```

The tau value (-0.84) is negative, indicating a strong monotonic decreasing trend. The p-value is 0.0001 which is \< 0.05 hence p-value is significant. This result tells us that here is an overall negative trend. As time passes by, the Gi\* value will decrease, thus a higher clustering of low vaccination rate. This could either be due to shortage of vaccines or the residents of Kamal are increasingly becoming resistant towards taking vaccine. This is not good, and the issue must be addressed immediately in this pandemic era.

## 9.2 EHSA map of the Gi\* values of the vaccination rate

In order for us to find the significant hot and cold spots, we need to conduct the Mann Kendall test on all the subdistricts. Hence, we will conduct this by using the `group_by()` for Sub_Districts.

```{r}
ehsa <- gi_values %>%
  group_by(Sub_District) %>%
  summarise(mk = list(
    unclass(
      Kendall::MannKendall(gi_star)))) %>%
  tidyr::unnest_wider(mk)
```

Then we arrange to show significant emerging hot/cold spots

```{r}
emerging <- ehsa %>% 
  arrange(sl, abs(tau)) %>% 
  slice(1:5)
emerging
```

Lastly, we will perform EHSA analysis by using [`emerging_hotspot_analysis()`](https://sfdep.josiahparry.com/reference/emerging_hotspot_analysis.html) of sfdep package. It takes a spacetime object x (i.e. vacc_rate_st), and the quoted name of the variable of interest (i.e. Vaccinaton Rate) for .var argument. The k argument is used to specify the number of time lags which is set to 1 by default. Lastly, nsim map numbers of simulation to be performed.

```{r}
ehsa <- emerging_hotspot_analysis(
  x = vacc_rate_st,
  .var = "Vaccination_Rate",
  k = 1,
  nsim = 99
)
```

We then visualize the distribution of the EHSA classes

```{r}
ggplot(data = ehsa,
       aes(x=classification, fill=classification)) + 
  geom_bar()
```

Figure above shows that sporadic hot spots class has the high numbers of sub-districts.

Before, we visualise the geographic distribution EHSA classes, we need to combine `jakarta` and `ehsa` together

```{r}
jakarta_ehsa <- jakarta %>%
  left_join(ehsa, by = c("Sub_District" = "location"))
```

Next, tmap functions will be used to plot a categorical choropleth map by using the code chunk below.

```{r}
# We use the filter to filter out values with p-value < 0.05
jakarta_ehsa_sig <- jakarta_ehsa  %>%
  filter(p_value < 0.05)
tmap_mode("plot")
tm_shape(jakarta_ehsa) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(jakarta_ehsa_sig) +
  tm_fill("classification") + 
  tm_borders(alpha = 0.4)
```

Below are the meanings of the terms -

-   Oscilating hotspot - It refers to a spatial pattern where a location or area alternates between being a hot spot (i.e., having a statistically significant high value) and a cold spot (i.e., having a statistically significant low value) over time. These hot-spots have an increasing trend in intensity over time.

-   Oscilating coldspot - It refers to areas that consistently experience lower values or intensity than surrounding areas, but the intensity levels in these areas fluctuate over time. They have a decreasing trend over time.

-   Sporadic coldspot - Sub-disticts which exhibits unusually low values for vaccination rate, as compared to its surrounding areas.

-   No pattern detected - Sub-districts that do not fall into any hot or cold spot patterns

The maps shows the largest number of oscillating hotspots which are located evenly in Jakarta. This means that there is a fluctuation between people getting vaccine with people not being able to get vaccine. This could be due to shortage of vaccines sometimes. This is followed by Spordiac coldspot
(lesser than oscillating hotspots), which is quite spread out in Jakarta. These have extremely low vaccination rate and hence, needs to be looked at immediately. This is lastly followed by Oscilating coldspot which appear to be more around the border and in the central of Jakarta. Lastly, there are areas with no pattern detected, these are mainly located in the central area. Further, the sub-districts with p-value \> 0.05 are in grey colour as they are insignificant.

# 10.0 Conclusion

The analysis of Jakarta's sub-districts vaccination rate is important as it provides valuable insights into the spatial patterns of vaccination coverage in different areas. By using the above techniques, we can identify areas where vaccination rates are low and where more vaccination campaigns are required. It also helps to identify areas where vaccination campaigns have been successful. We have identified hotspots or coldspots where targeted interventions may be required to improve the coverage of the vaccine. This can help policymakers make informed decisions about where to allocate resources and where to focus vaccination campaigns. It can also help in identifying the areas where vaccine hesitancy or lack of access to healthcare services may be contributing to low vaccination rates. Overall, the analysis of vaccination rates in Jakarta's sub-districts is crucial for effective planning and implementation of vaccination programs, and for achieving higher vaccination coverage rates.

# 11.0 References

Thank your Prof. Kim for all the resources and insightful Hands-On and Take-Home Excercises. Special thanks goes to the Senior Sample Submissions that Prof. Kam recommended!
