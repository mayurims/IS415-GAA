[
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05.html",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05.html",
    "title": "In-Class Excercise 5",
    "section": "",
    "text": "# sfdep (gonna use for the take home excercise 2)\npacman::p_load(tidyverse, tmap, sf, sfdep)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05.html#visualizing-the-sf-layers",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex05.html#visualizing-the-sf-layers",
    "title": "In-Class Excercise 5",
    "section": "Visualizing the sf layers",
    "text": "Visualizing the sf layers\n\ntmap_mode(\"view\")\ntm_shape(studyArea)+\n  tm_polygons()+\ntm_shape(stores)+\n  tm_dots(col = \"Name\",\n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5)+\n  tm_view(set.zoom.limits = c(12, 16))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "title": "Take-Home Excercise 01",
    "section": "",
    "text": "Water is an essential part of our life, without which we won’t be able to survive for more than 3 days. Living in Singapore, we have access to clean drinkable water 24/7 and as a result we don’t realize the struggles of people who don’t have access to clean water at all. An an example of such are the people in Nigeria. Despite 70% of Nigerians having access to basic water services, more than half of them are contamintated (Reference).\nFor this assignment, we will be focusing on the State of Osun in Nigeria. Osun, located in the southwestern Nigeria is bounded to the east by Ekiti and Ondo states, Kwara on the north, Ogun to the south and to the west by Oyo State (Reference). Their economy is mainly based on the agriculture and it inhibits the Osun River, a sacred river. However, in the recent years, the river has been polluted by the several mining activities from the surrounding communities (Reference). Hence, it is integral for us to address the issue of providing clean and sustainable water to the people of Osun. Through this assignment, I aim to apply the relevant spatial point pattern analysis learned in class to analyse the Functional and Non-Functional water points in State of Osun, Nigera.\n\n\n\nOsun River"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#packages-used",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#packages-used",
    "title": "Take-Home Excercise 01",
    "section": "2.1 Packages Used",
    "text": "2.1 Packages Used\n\nsf : Used for importing geospatial data, assigning or transforming coordinate systems, and converting geospatial and aspatial data into a sf data frame\ntidyverse : Used for transforming and better presentation of Data\ntmap : Used for plotting static point patterns maps or interactive maps\nspatstat : Used for point-pattern analysis\nraster : Used to read, write, manipulate, analyse and model gridded spatial data\nmaptools : Used to provide a set of tools for manipulating geographic data\nkableExtra : Used for table customization\nfunModeling : Used to data cleaning, importance variable, analysis and model performance\nsfdep :Used for functions creates not present in spdep.\n\n\npacman::p_load(sf, maptools, raster, spatstat, tmap, kableExtra, tidyverse, funModeling, sfdep)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#datasets-used",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#datasets-used",
    "title": "Take-Home Excercise 01",
    "section": "2.2 Datasets Used",
    "text": "2.2 Datasets Used\nThe below diagram shows the datasets used for the Assignment. We have two types of data - geospatial and aspatial.\nFor the Aspatial data, we are extracting the data from WPdx Global Data Repositories. The data source consists of two types of data - WPdx-Basic and WPdx+, for the purpose of this project, we will be using the WPdx+.\nFor the Geospatial data, we will be using the Nigeria Level-2 Administrative Boundary polygon features GIS data. There are two data source for this - Humanitarian Data Exchange (HDE) and geoBoundaries.\n\n# initialise a dataframe of our geospatial and aspatial dataset details\ndatasets <- data.frame(\n  Type=c(\"Geospatial\",\n         \"Geospatial\",\n         \"Geospatial\",\n         \"Geospatial\",\n         \"Geospatial\",\n         \"Geospatial\",\n         \"Geospatial\",\n         \"Geospatial\",\n         \"Geospatial\",\n         \"Geospatial\",\n         \"Geospatial\",\n         \"Geospatial\",\n         \"Geospatial\",\n         \"Geospatial\",\n         \n         \"Aspatial\"),\n  \n  Name=c(\"geoBoundaries-NGA-ADM2\",\n         \"geoBoundaries-NGA-ADM2\",\n         \"geoBoundaries-NGA-ADM2\",\n         \"geoBoundaries-NGA-ADM2\",\n         \"geoBoundaries-NGA-ADM2\",\n         \"geoBoundaries-NGA-ADM2\",\n         \"nga_admbnda_adm2_osgof_20190417\",\n         \"nga_admbnda_adm2_osgof_20190417\",\n         \"nga_admbnda_adm2_osgof_20190417\",\n         \"nga_admbnda_adm2_osgof_20190417\",\n         \"nga_admbnda_adm2_osgof_20190417\",\n         \"nga_admbnda_adm2_osgof_20190417\",\n         \"nga_admbnda_adm2_osgof_20190417\",\n         \"nga_admbnda_adm2_osgof_20190417\",\n         \n         \"WPdx\"),\n  \n  Format=c(\".dbf\", \n           \".geojson\", \n           \".prj\", \n           \".shp\", \n           \".shx\", \n           \".topojson\",\n           \".CPG\",\n           \".dbf\",\n           \".prj\",\n           \".sbn\", \n           \".sbx\", \n           \".shp\", \n           \".shp\", \n           \".shx\", \n          \n           \".csv\"),\n  \n  Source=c(\"[geoBoundaries](https://www.geoboundaries.org/index.html#getdata)\",\n           \"[geoBoundaries](https://www.geoboundaries.org/index.html#getdata)\",\n           \"[geoBoundaries](https://www.geoboundaries.org/index.html#getdata)\",\n           \"[geoBoundaries](https://www.geoboundaries.org/index.html#getdata)\",\n           \"[geoBoundaries](https://www.geoboundaries.org/index.html#getdata)\",\n           \"[geoBoundaries](https://www.geoboundaries.org/index.html#getdata)\",\n           \n          \"[Humanitarian Data Exchange](https://data.humdata.org/dataset/cod-ab-nga)\",\n           \"[Humanitarian Data Exchange](https://data.humdata.org/dataset/cod-ab-nga)\",\n           \"[Humanitarian Data Exchange](https://data.humdata.org/dataset/cod-ab-nga)\",\n           \"[Humanitarian Data Exchange](https://data.humdata.org/dataset/cod-ab-nga)\",\n           \"[Humanitarian Data Exchange](https://data.humdata.org/dataset/cod-ab-nga)\",\n           \"[Humanitarian Data Exchange](https://data.humdata.org/dataset/cod-ab-nga)\",\n           \"[Humanitarian Data Exchange](https://data.humdata.org/dataset/cod-ab-nga)\",\n           \"[Humanitarian Data Exchange](https://data.humdata.org/dataset/cod-ab-nga)\",\n           \n           \"[ WPdx Global Data Repositories](https://www.waterpointdata.org/access-data/)\")\n  )\n\n# with reference to this guide on kableExtra:\n# https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html\n# kable_material is the name of the kable theme\n# 'hover' for to highlight row when hovering, 'scale_down' to adjust table to fit page width\nlibrary(knitr)\nlibrary(kableExtra)\nkable(datasets, caption=\"Datasets Used\") %>%\n  kable_material(\"hover\", latex_options=\"scale_down\")\n\n\n\nDatasets Used\n \n  \n    Type \n    Name \n    Format \n    Source \n  \n \n\n  \n    Geospatial \n    geoBoundaries-NGA-ADM2 \n    .dbf \n    [geoBoundaries](https://www.geoboundaries.org/index.html#getdata) \n  \n  \n    Geospatial \n    geoBoundaries-NGA-ADM2 \n    .geojson \n    [geoBoundaries](https://www.geoboundaries.org/index.html#getdata) \n  \n  \n    Geospatial \n    geoBoundaries-NGA-ADM2 \n    .prj \n    [geoBoundaries](https://www.geoboundaries.org/index.html#getdata) \n  \n  \n    Geospatial \n    geoBoundaries-NGA-ADM2 \n    .shp \n    [geoBoundaries](https://www.geoboundaries.org/index.html#getdata) \n  \n  \n    Geospatial \n    geoBoundaries-NGA-ADM2 \n    .shx \n    [geoBoundaries](https://www.geoboundaries.org/index.html#getdata) \n  \n  \n    Geospatial \n    geoBoundaries-NGA-ADM2 \n    .topojson \n    [geoBoundaries](https://www.geoboundaries.org/index.html#getdata) \n  \n  \n    Geospatial \n    nga_admbnda_adm2_osgof_20190417 \n    .CPG \n    [Humanitarian Data Exchange](https://data.humdata.org/dataset/cod-ab-nga) \n  \n  \n    Geospatial \n    nga_admbnda_adm2_osgof_20190417 \n    .dbf \n    [Humanitarian Data Exchange](https://data.humdata.org/dataset/cod-ab-nga) \n  \n  \n    Geospatial \n    nga_admbnda_adm2_osgof_20190417 \n    .prj \n    [Humanitarian Data Exchange](https://data.humdata.org/dataset/cod-ab-nga) \n  \n  \n    Geospatial \n    nga_admbnda_adm2_osgof_20190417 \n    .sbn \n    [Humanitarian Data Exchange](https://data.humdata.org/dataset/cod-ab-nga) \n  \n  \n    Geospatial \n    nga_admbnda_adm2_osgof_20190417 \n    .sbx \n    [Humanitarian Data Exchange](https://data.humdata.org/dataset/cod-ab-nga) \n  \n  \n    Geospatial \n    nga_admbnda_adm2_osgof_20190417 \n    .shp \n    [Humanitarian Data Exchange](https://data.humdata.org/dataset/cod-ab-nga) \n  \n  \n    Geospatial \n    nga_admbnda_adm2_osgof_20190417 \n    .shp \n    [Humanitarian Data Exchange](https://data.humdata.org/dataset/cod-ab-nga) \n  \n  \n    Geospatial \n    nga_admbnda_adm2_osgof_20190417 \n    .shx \n    [Humanitarian Data Exchange](https://data.humdata.org/dataset/cod-ab-nga) \n  \n  \n    Aspatial \n    WPdx \n    .csv \n    [ WPdx Global Data Repositories](https://www.waterpointdata.org/access-data/)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#importing-geospatial-data",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#importing-geospatial-data",
    "title": "Take-Home Excercise 01",
    "section": "3.1 Importing Geospatial Data",
    "text": "3.1 Importing Geospatial Data\n\nNGA <- st_read(\"data/geospatial\", \n                  layer = \"nga_admbnda_adm2_osgof_20190417\") %>%\n  filter(ADM1_EN == \"Osun\") %>%\n  st_transform(crs = 26392)\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `C:\\mayurims\\IS415-GAA\\Take-Home_Ex\\Take-Home_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\n(Talk about CRS)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-pre-processing",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-pre-processing",
    "title": "Take-Home Excercise 01",
    "section": "3.2 Data Pre-processing",
    "text": "3.2 Data Pre-processing\n\n3.2.1 Dropping Invalid Dimensions\nSince, we only have one dataframe, there are no invalid dimensions, and hence, this step is not required.\n\n\n3.2.2 Invalid Geometries\nThe st_is_valid() function checks whether a geometry is valid and returns the indices. Whereas, the length() gives you a count of the indices with invalid geometries.\n\nlength(which(st_is_valid(NGA) == FALSE))\n\n[1] 0\n\n\nNone of the values are Invalid, so we are good to go!!\n\n\n3.2.3 Checking for Duplicated Names\nWe need to check for duplicate name in the data main data fields. Using duplicated() of Base R, we can flag out LGA names that might be duplicated as shown in the code chunk below.\n\nNGA$ADM2_EN[duplicated(NGA$ADM2_EN)==TRUE]\n\ncharacter(0)\n\n\nThere are no duplicated values, so we are good to go!\n\n\n3.2.4 Initial Visualization\n\nplot(st_geometry(NGA))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#importing-aspatial-data",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#importing-aspatial-data",
    "title": "Take-Home Excercise 01",
    "section": "4.1 Importing Aspatial Data",
    "text": "4.1 Importing Aspatial Data\nSince the WPdx data is in CSV format, we will use read_csv() of readr package to import WPdx.csv. The output is called wp_nga and is a tibble dataframe\n\nwp_nga <- read_csv(\"data/aspatial/WPdx.csv\") %>%\n  filter(`#clean_country_name` == \"Nigeria\" & `#clean_adm1` == \"Osun\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#converting-water-point-data-into-sf-point-features",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#converting-water-point-data-into-sf-point-features",
    "title": "Take-Home Excercise 01",
    "section": "4.2 Converting water point data into sf point features",
    "text": "4.2 Converting water point data into sf point features\nConverting an aspatial data into an sf data.frame involves two steps.\nFirst, we need to convert the wkt field into sfc field by using st_as_sfc() function. The function stores it in a tibble data format.\n\nwp_nga$Geometry = st_as_sfc(wp_nga$`New Georeferenced Column`)\nwp_nga\n\n# A tibble: 5,557 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429123 GRID3             8.02    5.06 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2  70566 Federal Minis…    7.32    4.79 05/11/… No      Protec… Well    Mechan…\n 3  70578 Federal Minis…    7.76    4.56 05/11/… No      Boreho… Well    Mechan…\n 4  66401 Federal Minis…    8.03    4.64 04/30/… No      Boreho… Well    Mechan…\n 5 422190 GRID3             7.87    4.88 08/29/… Unknown <NA>    <NA>    Tapsta…\n 6 422064 GRID3             7.7     4.89 08/29/… Unknown <NA>    <NA>    Tapsta…\n 7  65607 Federal Minis…    7.89    4.71 05/12/… No      Boreho… Well    Mechan…\n 8  68989 Federal Minis…    7.51    4.27 05/07/… No      Boreho… Well    <NA>   \n 9  67708 Federal Minis…    7.48    4.35 04/29/… Yes     Boreho… Well    Mechan…\n10  66419 Federal Minis…    7.63    4.50 05/08/… Yes     Boreho… Well    Hand P…\n# … with 5,547 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nNext, we use the st_sf() to convert the tibble data.frame into an sf object. It is also important for us to include the referencing system of the data into the sf object.\n\nwp_sf <- st_sf(wp_nga, crs=4326)\nwp_sf\n\nSimple feature collection with 5557 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 4.032004 ymin: 7.060309 xmax: 5.06 ymax: 8.061898\nGeodetic CRS:  WGS 84\n# A tibble: 5,557 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429123 GRID3             8.02    5.06 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2  70566 Federal Minis…    7.32    4.79 05/11/… No      Protec… Well    Mechan…\n 3  70578 Federal Minis…    7.76    4.56 05/11/… No      Boreho… Well    Mechan…\n 4  66401 Federal Minis…    8.03    4.64 04/30/… No      Boreho… Well    Mechan…\n 5 422190 GRID3             7.87    4.88 08/29/… Unknown <NA>    <NA>    Tapsta…\n 6 422064 GRID3             7.7     4.89 08/29/… Unknown <NA>    <NA>    Tapsta…\n 7  65607 Federal Minis…    7.89    4.71 05/12/… No      Boreho… Well    Mechan…\n 8  68989 Federal Minis…    7.51    4.27 05/07/… No      Boreho… Well    <NA>   \n 9  67708 Federal Minis…    7.48    4.35 04/29/… Yes     Boreho… Well    Mechan…\n10  66419 Federal Minis…    7.63    4.50 05/08/… Yes     Boreho… Well    Hand P…\n# … with 5,547 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nLike step 3.2 Data Pre-processing, we transform the projection from wgs84 to the appropriate projected coordinate system of Nigeria.\n\nwp_sf <- wp_sf %>%\n  st_transform(crs = 26392)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-wrangling-for-water-data-point",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-wrangling-for-water-data-point",
    "title": "Take-Home Excercise 01",
    "section": "4.3 Data Wrangling for Water Data Point",
    "text": "4.3 Data Wrangling for Water Data Point\nExploratory Data Analysis (EDA) helps to gain initial understanding of the data. The freq() of funModeling package is used to reveal the distribution of water point status visually.\n\nfreq(data = wp_sf,\n     input = '#status_clean')\n\n\n\n\n                     #status_clean frequency percentage cumulative_perc\n1                       Functional      2319      41.73           41.73\n2                   Non-Functional      2008      36.13           77.86\n3                             <NA>       748      13.46           91.32\n4      Functional but needs repair       248       4.46           95.78\n5 Non-Functional due to dry season       151       2.72           98.50\n6        Functional but not in use        63       1.13           99.63\n7                        Abandoned        15       0.27           99.90\n8         Abandoned/Decommissioned         5       0.09          100.00\n\n\nThe diagram shows that there are nine classes present in the ‘status_clean’ field. Hence, now we will be performing data wrangling tasks to create 3 data object - Functional, Non-Functional and Unknown.\nWe use rename() function from the dplyr package to rename the column from #status_clean to status_clean for easier handling in subsequent steps. select() is used to include status_clean in the output sf data.frame. We use the mutate() and replace_na() functions to re-code all the NA values in status_clean into unknown.\n\nwp_sf_nga <- wp_sf %>% \n  rename(status_clean = '#status_clean') %>%\n  select(status_clean) %>%\n  mutate(status_clean = replace_na(\n    status_clean, \"unknown\"))\n\n\n4.3.1 Extracting Water Point Data\nNow we are ready to extract the water point data according to their status.\nThe code chunk below is used to extract functional water point.\n\nwp_functional <- wp_sf_nga %>%\n  filter(status_clean %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\nThe code chunk below is used to extract nonfunctional water point.\n\nwp_nonfunctional <- wp_sf_nga %>%\n  filter(status_clean %in%\n           c(\"Abandoned/Decommissioned\",\n             \"Abandoned\",\n             \"Non-Functional due to dry season\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\"))\n\nThe code chunk below is used to extract water point with unknown status.\n\nwp_unknown <- wp_sf_nga %>%\n  filter(status_clean == \"unknown\")\n\nPerforming a quick EDA on the derived sfa.dataframes\n\nfreq(data = wp_functional,\n     input = 'status_clean')\n\n\n\n\n                 status_clean frequency percentage cumulative_perc\n1                  Functional      2319      88.17           88.17\n2 Functional but needs repair       248       9.43           97.60\n3   Functional but not in use        63       2.40          100.00\n\n\n\nfreq(data = wp_nonfunctional,\n     input = 'status_clean')\n\n\n\n\n                      status_clean frequency percentage cumulative_perc\n1                   Non-Functional      2008      92.15           92.15\n2 Non-Functional due to dry season       151       6.93           99.08\n3                        Abandoned        15       0.69           99.77\n4         Abandoned/Decommissioned         5       0.23          100.00\n\n\n\nfreq(data = wp_unknown,\n     input = 'status_clean')\n\n\n\n\n  status_clean frequency percentage cumulative_perc\n1      unknown       748        100             100\n\n\nWe can see from the map below, the proportion of functional and non-functional water is quite similar.\n\ntmap_mode(\"view\")\ntm_shape(wp_functional) +\n tm_dots(col = \"status_clean\",\n         pal = \"blue\",\n         title = \"Functional\") +\ntm_shape(wp_nonfunctional) +\n tm_dots(col = \"status_clean\",\n         pal = \"red\",\n         title = \"Non-Functional\") +\n  tm_view(set.zoom.limits = c(8.5,15)) \n\n\n\n\n\n\n\n\n4.3.2 Performing Point-In Polygon Count\nNext, we want to find out the number of total, functional, nonfunctional and unknown water points in Osun State. This is performed in the following code chunk. First, it identifies the functional water points in each LGA by using st_intersects() of sf package. Next, length() is used to calculate the number of functional water points that fall inside each LGA.\n\nNGA_wp <- NGA %>% \n  mutate(`total_wp` = lengths(\n    st_intersects(NGA, wp_sf_nga))) %>%\n  mutate(`wp_functional` = lengths(\n    st_intersects(NGA, wp_functional))) %>%\n  mutate(`wp_nonfunctional` = lengths(\n    st_intersects(NGA, wp_nonfunctional))) %>%\n  mutate(`wp_unknown` = lengths(\n    st_intersects(NGA, wp_unknown)))\nNGA_wp\n\nSimple feature collection with 30 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 176503.2 ymin: 331434.7 xmax: 291043.8 ymax: 454520.1\nProjected CRS: Minna / Nigeria Mid Belt\nFirst 10 features:\n          ADM2_EN ADM2_PCODE ADM1_EN ADM1_PCODE                       geometry\n1        Aiyedade   NG030001    Osun      NG030 MULTIPOLYGON (((213526.6 34...\n2        Aiyedire   NG030002    Osun      NG030 MULTIPOLYGON (((212542.6 40...\n3  Atakumosa East   NG030003    Osun      NG030 MULTIPOLYGON (((265746.8 37...\n4  Atakumosa West   NG030004    Osun      NG030 MULTIPOLYGON (((248871.4 40...\n5      Boluwaduro   NG030005    Osun      NG030 MULTIPOLYGON (((266092.2 43...\n6          Boripe   NG030006    Osun      NG030 MULTIPOLYGON (((255072.5 43...\n7       Ede North   NG030007    Osun      NG030 MULTIPOLYGON (((236386.9 41...\n8       Ede South   NG030008    Osun      NG030 MULTIPOLYGON (((236386.9 41...\n9        Egbedore   NG030009    Osun      NG030 MULTIPOLYGON (((220756 4317...\n10         Ejigbo   NG030010    Osun      NG030 MULTIPOLYGON (((214422.1 42...\n   total_wp wp_functional wp_nonfunctional wp_unknown\n1       389           157              154         78\n2       175            89               57         29\n3       223            98               92         33\n4       246           111              103         32\n5       129            63               51         15\n6       177            79               85         13\n7       216           141               50         25\n8       146            72               39         35\n9       142            63               44         35\n10      434           274              126         34\n\n\nWe then visualise attributes by using statistcal graph. We use functions of ggplot2 package to reveal the distribution of total water points in Osun’s LGA using histogram.\n\nggplot(data = NGA_wp,\n       aes(x = total_wp)) + \n  geom_histogram(bins=20,\n                 color=\"black\",\n                 fill=\"light blue\") +\n  geom_vline(aes(xintercept=mean(\n    total_wp, na.rm=T)),\n             color=\"red\", \n             linetype=\"dashed\", \n             size=0.8) +\n  ggtitle(\"Distribution of total water points\") +\n  xlab(\"No. of water points\") +\n  ylab(\"No. of\\nLGAs\") +\n  theme(axis.title.y=element_text(angle = 0))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#converting-sf-data-frames-to-sps-spatial-class",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#converting-sf-data-frames-to-sps-spatial-class",
    "title": "Take-Home Excercise 01",
    "section": "5.1 Converting sf data frames to sp’s Spatial* Class",
    "text": "5.1 Converting sf data frames to sp’s Spatial* Class\nWe use the as_spatial() function to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nwp_functional_spatial = as_Spatial(wp_functional)\nwp_nonfunctional_spatial = as_Spatial(wp_nonfunctional)\nNGA_spatial <- as_Spatial(NGA)\n\n\nNGA_spatial\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 30 \nextent      : 176503.2, 291043.8, 331434.7, 454520.1  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       :  ADM2_EN, ADM2_PCODE, ADM1_EN, ADM1_PCODE \nmin values  : Aiyedade,   NG030001,    Osun,      NG030 \nmax values  :   Osogbo,   NG030030,    Osun,      NG030 \n\n\n\nwp_functional_spatial\n\nclass       : SpatialPointsDataFrame \nfeatures    : 2630 \nextent      : 177285.9, 290751, 343128.1, 450859.7  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 1\nnames       :              status_clean \nmin values  :                Functional \nmax values  : Functional but not in use \n\n\n\nwp_nonfunctional_spatial\n\nclass       : SpatialPointsDataFrame \nfeatures    : 2179 \nextent      : 180539, 290616, 340054.1, 450780.1  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 1\nnames       :                     status_clean \nmin values  :                        Abandoned \nmax values  : Non-Functional due to dry season"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#converting-from-spatial-classes-to-sp-format",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#converting-from-spatial-classes-to-sp-format",
    "title": "Take-Home Excercise 01",
    "section": "5.2 Converting from Spatial* classes to sp format",
    "text": "5.2 Converting from Spatial* classes to sp format\nIn order to use the spatstat for our analysis, we need our data to be in the ppp object form. Hence, we first need to convert them into Spatial object first and then into ppp object.\n\n# convert into respective sp (in our case, either polygons or points)\nwp_functional_sp <- as(wp_functional_spatial, \"SpatialPoints\")\nwp_nonfunctional_sp <- as(wp_nonfunctional_spatial, \"SpatialPoints\")\nNGA_sp <-as(NGA_spatial, \"SpatialPolygons\")\n\n\nwp_functional_sp\n\nclass       : SpatialPoints \nfeatures    : 2630 \nextent      : 177285.9, 290751, 343128.1, 450859.7  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \n\n\n\nwp_nonfunctional_sp\n\nclass       : SpatialPoints \nfeatures    : 2179 \nextent      : 180539, 290616, 340054.1, 450780.1  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \n\n\n\nNGA_sp\n\nclass       : SpatialPolygons \nfeatures    : 30 \nextent      : 176503.2, 291043.8, 331434.7, 454520.1  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#converting-from-sp-format-to-spatstat-ppp-format",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#converting-from-sp-format-to-spatstat-ppp-format",
    "title": "Take-Home Excercise 01",
    "section": "5.3 Converting from sp format to spatstat ppp format",
    "text": "5.3 Converting from sp format to spatstat ppp format\nWe can’t convert SpatialPolygons to ppp format - nor is there any need to. Hence, we won’t be including our ‘base map’, NGA.\n\n# from sp object, convert into ppp format\nwp_functional_ppp <- as(wp_functional_sp, \"ppp\")\nwp_nonfunctional_ppp <- as(wp_nonfunctional_sp, \"ppp\")\n\nThe below map shows the point patterns for both functional and non-functional water points.\n\npar(mfrow=c(1,2))\nplot(wp_nonfunctional_ppp)\nplot(wp_functional_ppp)\n\n\n\n\n\n5.3.1 Handling Duplicated Points + Jittering\n\nany(duplicated(wp_functional_ppp)) \n\n[1] FALSE\n\n\n\nany(duplicated(wp_nonfunctional_ppp)) \n\n[1] FALSE\n\n\nSince there is no duplication, we don’t have to apply the process of Jittering."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#creating-owin-object",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#creating-owin-object",
    "title": "Take-Home Excercise 01",
    "section": "5.4 Creating Owin Object",
    "text": "5.4 Creating Owin Object\nWe need to now confine the analysis with a geographical area - Osun State and we do this by creating a object called owin which represent the polygonal region. The below code covert the SpatialPolygon (NGA_sp) created into an owin object.\n\nNGA_owin <- as(NGA_sp, \"owin\")\nplot(NGA_owin)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#combining-point-events-object-and-owin-object",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#combining-point-events-object-and-owin-object",
    "title": "Take-Home Excercise 01",
    "section": "5.5 Combining point events object and owin object",
    "text": "5.5 Combining point events object and owin object\nIn this step, we extract the functional and non-functional water points that are located within Osun, Nigeria. This combines both the point and polygon feature into one ppp object class.\n\nwp_functional_ppp = wp_functional_ppp[NGA_owin]\nwp_nonfunctional_ppp = wp_nonfunctional_ppp[NGA_owin]\n\n\npar(mfrow=c(1,2))\nplot(wp_nonfunctional_ppp)\nplot(wp_functional_ppp)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#kernel-density-estimation",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#kernel-density-estimation",
    "title": "Take-Home Excercise 01",
    "section": "6.1 Kernel Density Estimation",
    "text": "6.1 Kernel Density Estimation\n\n6.1.1 Computing Kernel Density Estimation\nThere are two types of bandwidth methods - Fixed (Automatic) and Adaptive bandwidth method. These methods employ different uniform bases in density calculation.\nComputing using Automatic Bandwidth selection method\nWe can compute the kernel density by using the bw.ppl() or bw.diggle(). As learned in Chapter 04, the ppl() method is prefered for patterns consisting predominantly of prominent clusters. Whereas, bw.diggle() is best used to detect a single tight cluster in the midst of random noise.\nFrom the maps below, we can see that bw.ppl() method is better able to identify the prominent clusters as the data does not contain a single tight cluster. Hence, we will be using the bw.ppl() method.\n\nbw.diggle() Method\n\nkde_wpfunctional_bw_diggle <- density(wp_functional_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \nkde_wpnonfunctional_bw_diggle <- density(wp_nonfunctional_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\npar(mfrow=c(1,2))\nplot(kde_wpfunctional_bw_diggle,\n     main = \"Functional Water Points\",\n     ribside=c(\"right\"))\nplot(kde_wpnonfunctional_bw_diggle,\n     main = \"Non-Functional Water Points\",\n     ribside=c(\"right\"))\n\n\n\n\nbw.ppl() Method\n\nkde_wpfunctional_bw <- density(wp_functional_ppp,\n                              sigma=bw.ppl,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \nkde_wpnonfunctional_bw <- density(wp_nonfunctional_ppp,\n                              sigma=bw.ppl,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\npar(mfrow=c(1,2))\nplot(kde_wpfunctional_bw,\n     main = \"Functional Water Points\",\n     ribside=c(\"right\"))\nplot(kde_wpnonfunctional_bw,\n     main = \"Non-Functional Water Points\",\n     ribside=c(\"right\"))\n\n\n\n\n\nComputing using Adaptive Bandwidth selection method\n\nkde_wpfunctional_adaptive <- adaptive.density(wp_functional_ppp, method=\"kernel\")\n\nkde_wpnonfunctional_adaptive <- adaptive.density(wp_nonfunctional_ppp, method=\"kernel\")\n\npar(mfrow=c(1,2))\nplot(kde_wpfunctional_adaptive,\n     main = \"Functional Water Points\",\n     ribside=c(\"right\"))\nplot(kde_wpnonfunctional_adaptive,\n     main = \"Non-Functional Water Points\",\n     ribside=c(\"right\"))\n\n\n\n\nComparing Automated and Adapting Bandwidth Methods (side-by-side)\n\nFunctional Water Point\n\npar(mfrow=c(1,2))\nplot(kde_wpfunctional_bw,\n     main = \"Functional Water Points - Automated\",\n     ribside=c(\"right\"))\nplot(kde_wpfunctional_adaptive,\n     main = \"Functional Water Points - Adaptive\",\n     ribside=c(\"right\"))\n\n\n\n\nNon-Functional Water Point\n\npar(mfrow=c(1,2))\nplot(kde_wpnonfunctional_bw,\n     main = \"Non-Functional Water Points - Automated\",\n     ribside=c(\"right\"))\nplot(kde_wpnonfunctional_adaptive,\n     main = \"Non-Functional Water Points - Adaptive\",\n     ribside=c(\"right\"))\n\n\n\n\n\n\n\n6.1.2 Rescalling KDE Values\nAs we can the KDE values are small (ranging from 0 to 0.000035). This is because the default unit of measurement of svy21 is in meter. As a result, the density values computed is in “number of points per square meter”. So rescale() is used to covert the unit of measurement from meter to kilometer.\n\nwp_functional_ppp_km <- rescale(wp_functional_ppp, 1000, \"km\")\nwp_nonfunctional_ppp_km <- rescale(wp_nonfunctional_ppp, 1000, \"km\")\n\nNow we re-plot the graphs\n\nAutomated Bandwidth Method\n\nkde_wpfunctional_km <- density(wp_functional_ppp_km,\n                              sigma=bw.ppl,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \nkde_wpnonfunctional_km <- density(wp_nonfunctional_ppp_km,\n                              sigma=bw.ppl,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\npar(mfrow=c(1,2))\nplot(kde_wpfunctional_bw,\n     main = \"Functional Water Points\",\n     ribside=c(\"right\"))\nplot(kde_wpnonfunctional_bw,\n     main = \"Non-Functional Water Points\",\n     ribside=c(\"right\"))\n\n\n\n\nAdaptive Bandwidth Method\n\nkde_wpfunctional_adaptive_km <- adaptive.density(wp_functional_ppp_km, method=\"kernel\")\n\nkde_wpnonfunctional_adaptive_km <- adaptive.density(wp_nonfunctional_ppp_km, method=\"kernel\")\n\npar(mfrow=c(1,2))\nplot(kde_wpfunctional_adaptive,\n     main = \"Functional Water Points\",\n     ribside=c(\"right\"))\nplot(kde_wpnonfunctional_adaptive,\n     main = \"Non-Functional Water Points\",\n     ribside=c(\"right\"))\n\n\n\n\n\nFor this assignment, we will be using the Automated Bandwidth method because it defines its base in geographical space, where as the Adaptive method defines it in population (Reference). As we learned in Chapter 04, Automated Bandwidth is very sensitive to highly skew distribution of spatial point patterns over geographical units (e.g - urban versus rural). However, since we don’t have highly skewed data (as seen in the distribution graph in 4.3.2 Performing Point-In Polygon Count), we can use Fixed/Automated Bandwidth method."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#converting-kde-output-into-grid-object",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#converting-kde-output-into-grid-object",
    "title": "Take-Home Excercise 01",
    "section": "6.2 Converting KDE output into grid object",
    "text": "6.2 Converting KDE output into grid object\n\ngridded_wpfunctional <- as.SpatialGridDataFrame.im(kde_wpfunctional_km)\ngridded_wpnonfunctional <- as.SpatialGridDataFrame.im(kde_wpnonfunctional_km)\n\nspplot(gridded_wpfunctional)\n\n\n\nspplot(gridded_wpnonfunctional)\n\n\n\n\n\n6.2.1 Converting Gridded Output into Raster\nNext, we convert the gridded kernal density objects into RasterLayer object by using raster() of raster package.\n\nkde_wpfunctional_raster <- raster(gridded_wpfunctional)\nkde_wpfunctional_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -4.99773e-16, 10.55944  (min, max)\n\n\n\nkde_wpnonfunctional_raster <- raster(gridded_wpnonfunctional)\nkde_wpnonfunctional_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -2.52505e-16, 9.25861  (min, max)\n\n\n\n\n6.2.2 Assigning Projection Systems\n\nprojection(kde_wpfunctional_raster) <- CRS(\"+init=EPSG:26392 +datum:WGS84 +units=km\")\nkde_wpfunctional_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +units=km +no_defs \nsource     : memory\nnames      : v \nvalues     : -4.99773e-16, 10.55944  (min, max)\n\n\n\nprojection(kde_wpnonfunctional_raster) <- CRS(\"+init=EPSG:26392 +datum:WGS84 +units=km\")\nkde_wpnonfunctional_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +units=km +no_defs \nsource     : memory\nnames      : v \nvalues     : -2.52505e-16, 9.25861  (min, max)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#kernel-density-maps-on-openstreetmap",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#kernel-density-maps-on-openstreetmap",
    "title": "Take-Home Excercise 01",
    "section": "6.3 Kernel Density Maps on OpenStreetMap",
    "text": "6.3 Kernel Density Maps on OpenStreetMap\nNow, as the assignment requirements has specified, we should plot our kernel density maps on OpenStreetMap. Since we’ll be plotting a lot of kernel density maps, let’s create a function:\n\ndensity_map <- function(raster_object, map_title) {\n  tmap_mode(\"view\")\n  tm_basemap(\"OpenStreetMap\") +\ntm_shape(raster_object) +\n  tm_raster(\"v\", alpha=0.9) + \n  tm_layout(legend.position = c(\"right\", \"bottom\"), \n            legend.height = 0.5, \n            legend.width = 0.4,\n            main.title = map_title,\n            main.title.position = 'center',\n            main.title.size = 1,\n            frame = TRUE) + \n  tm_view(set.zoom.limits = c(8, 13))\n  } \n\n\nkde_wpfunctional_density_map <- density_map(kde_wpfunctional_raster, map_title = \"Functional Water Points in Osun State\")\nkde_wpnonfunctional_density_map <- density_map(kde_wpnonfunctional_raster, map_title = \"Non-Functional Water Points in Osun State\")\n\n\nFunctional Density Map\n\nkde_wpfunctional_density_map\n\n\n\n\n\nNon-Functional Density Map\n\nkde_wpnonfunctional_density_map\n\n\n\n\n\n\n\nFunctional Density Map\n\ntmap_mode('plot')\ntm_basemap(\"OpenStreetMap\") +\ntm_shape(kde_wpfunctional_raster) +\n  tm_raster(\"v\")\n\n\n\n\nNon-Functional Density Map\n\ntmap_mode('plot')\ntm_basemap(\"OpenStreetMap\") +\ntm_shape(kde_wpnonfunctional_raster) +\n  tm_raster(\"v\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#kernel-density-maps-analysis",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#kernel-density-maps-analysis",
    "title": "Take-Home Excercise 01",
    "section": "6.4 Kernel Density Maps Analysis",
    "text": "6.4 Kernel Density Maps Analysis\nAs we can see in the map in 4.3 Data Wrangling for Water Data Point, the number of functional and non-functional water points are quite close, with there being 2319 Functional and 2008 Non-functional water points. As a result, both the density maps are similar. But what is interesting to note is that, there seems to be more concentrated density points for the Non-Functional water points, compared to the Functional water points. Further, from the density maps above, we can see that both the Functional and Non-Functional water points are relatively more concentrated in the center and the upper part of Osun and we don’t see that many water points in lower part of Osun. This patter is reflected in the map in [[5.5 Combining point events object and owin object]], where we see less concentration of points in the lower part of Osun."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#advantage-of-kernel-density-map-over-point-map",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#advantage-of-kernel-density-map-over-point-map",
    "title": "Take-Home Excercise 01",
    "section": "6.5 Advantage of Kernel Density Map over Point Map",
    "text": "6.5 Advantage of Kernel Density Map over Point Map\nTo understand the advantage of Kernel Density Map over Point Map, we first need to plot the two and compare the differences.\n\ntmap_mode(\"plot\")\ntm_shape(NGA_wp) +\n  tm_borders(alpha = 0.5) +\n  tmap_options(check.and.fix = TRUE) +\ntm_shape(wp_nonfunctional) +\n  tm_dots(col=\"red\", size=0.05) +\n  tm_layout(main.title = \"Non-Functional Water Points\",\n          main.title.position = \"center\",\n          main.title.size = 1.2,\n          frame = TRUE)\n\n\n\n\n\nkde_wpnonfunctional_density_map\n\n\n\n\nWith the Kernel Density Map, denser areas with a heavier distribution of Non-Functional Water Points are easily spotted. This is because the kernel density z-estimate helps to smooth out the points in a given area. Compared to the point map which just shows the points. Further, the gradient colour available (ranging from yellow to green) helps in understanding the density/concentration of water pumps in the area. It clearly shows the viewer which are the areas with more non-functional water pumps, however, with the point map, the users have to gauge/estimate which are the denser with more non-functional water points.\nFurther, another advantage of Kernel Density Maps is that it uses the Inverse Distance Weighed method which is estimating cell values by using a linearly weighted combination of a set of sample points (Reference). This is quite useful, because it takes into consideration of water points that are further away (from the residential area) and hence, people might have to travel further to access the water points. And this is accounted by the kernel function, and not the Point Map.\nHence to conclude, the Kernal Density provides a quantitative value representing the concentration of points, where as this can only be observed/gauged in Point Map."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#nearest-neighbour-analysis",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#nearest-neighbour-analysis",
    "title": "Take-Home Excercise 01",
    "section": "6.6?? Nearest Neighbour Analysis",
    "text": "6.6?? Nearest Neighbour Analysis\nThe 95% confident interval will be used.\nThe test hypotheses for Functional Water Point is :\nH0 : The distribution of Functional Water Point in Osun State is randomly distributed.\nH1 : The distribution of Functional Water Point in Osun State is not randomly distributed.\n\nclarkevans.test(wp_functional_ppp,\n                correction=\"none\",\n                clipregion=\"NGA_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  wp_functional_ppp\nR = 0.44265, p-value = 0.01\nalternative hypothesis: clustered (R < 1)\n\n\nConclusion :\nThe test hypotheses for Non-Functional Water Point is :\nH0 : The distribution of Non-Functional Water Point in Osun State is randomly distributed.\nH1 : The distribution of Non-Functional Water Point in Osun State is not randomly distributed.\n\nclarkevans.test(wp_nonfunctional_ppp,\n                correction=\"none\",\n                clipregion=\"nga_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  wp_nonfunctional_ppp\nR = 0.43223, p-value = 0.01\nalternative hypothesis: clustered (R < 1)\n\n\nConclusion :"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#analysing-spatial-point-process-using-g-function",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#analysing-spatial-point-process-using-g-function",
    "title": "Take-Home Excercise 01",
    "section": "7.1 Analysing Spatial Point Process Using G-Function",
    "text": "7.1 Analysing Spatial Point Process Using G-Function\nWe will be using the G-Function for analyse the spatial point process. This function deals with the cumulative distribution of the nearest neighbor distances. It computes the nearest neighbor distance for each event, which is then sorted from smallest to largest. This is used to construct a cumulative distribution.\n\n7.1.1 Functional Water Point\nComputing G-function estimation\n\nG_wp_functional = Gest(wp_functional_ppp, correction = \"border\")\nplot(G_wp_functional, xlim=c(0,500))\n\n\n\n\nPerforming Complete Spatial Randomness Test\n\nG_wp_functional.csr <- envelope(wp_functional_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(G_wp_functional.csr)\n\n\n\n\nConclusion: The gray band shows for every distance, the smallest value and the largest value for of G(r) that is obtained out of 1000 simulations. The observed G(r) is far above the G(theo) as well as the envelope - indicating that Functional Water Points are clustered. Hence, we reject the null hypothesis that Functional Water Points are randomly distributed at 99% confident interval. Since the G(r) is above the randomization envelope, that is there are a lot of functional water points that intervent distances, as a result the curve climbs up very quickly. This suggests clustering.\n\n\n7.1.2 Non-Functional Water Point\nComputing G-function estimation\n\nG_wp_nonfunctional = Gest(wp_nonfunctional_ppp, correction = \"border\")\nplot(G_wp_nonfunctional, xlim=c(0,500))\n\n\n\n\nPerforming Complete Spatial Randomness Test\n\n# eval = FALSE\nG_wp_nonfunctional.csr <- envelope(wp_nonfunctional_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(G_wp_nonfunctional.csr)\n\n\n\n\nConclusion: The observed G(r) is far above the G(theo) as well as the envelope - indicating that Non-Functional Water Points are clustered. Hence, we reject the null hypothesis that Non Functional Water Points are randomly distributed at 99% confident interval. Since the G(r) is above the randomization envelope, that is there are a lot of functional water points that intervent distances, as a result the curve climbs up very quickly. This suggests clustering."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#analysing-spatial-point-process-using-f-function",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#analysing-spatial-point-process-using-f-function",
    "title": "Take-Home Excercise 01",
    "section": "7.2 Analysing Spatial Point Process using F-Function",
    "text": "7.2 Analysing Spatial Point Process using F-Function\n\n7.2.1 Functional Water Points\nComputing F-function estimation\n\n#F_wp_functional = Fest(wp_functional_ppp)\n#plot(F_wp_functional)\n\nPerforming Complete Spatial Randomness Test\n\n#F_wp_functional.csr <- envelope(wp_functional_ppp, Fest, nsim = 999)\n\n\n#plot(F_wp_functional.csr)\n\n\n\n7.2.2 Non-Functional Water Points\nComputing F-function estimation\n\n#F_wp_nonfunctional = Fest(wp_nonfunctional_ppp, correction=\"best\")\n#plot(F_wp_functional)\n\nPerforming Complete Spatial Randomness Test\n\n#F_wp_nonfunctional.csr <- envelope(wp_nonfunctional_ppp, Fest, nsim = 999)\n\n\n#plot(F_wp_nonfunctional.csr)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#analysing-spatial-point-process-using-k-function",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#analysing-spatial-point-process-using-k-function",
    "title": "Take-Home Excercise 01",
    "section": "7.3 Analysing Spatial Point Process Using K-Function",
    "text": "7.3 Analysing Spatial Point Process Using K-Function\n\n7.3.1 Functional Water Point\nComputing K-function estimate\n\n#K_wp_functional = Kest(wp_functional_ppp, correction = \"Ripley\")\n#plot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\nPerforming Complete Spatial Randomness\n\n#K_wp_functional.csr <- envelope(wp_functional_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\n\n#plot(K_wp_functional.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n7.3.1 Non-Functional Water Point\nComputing K-function estimate\n\n#K_wp_nonfunctional = Kest(wp_nonfunctional_ppp, correction = \"Ripley\")\n#plot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\nPerforming Complete Spatial Randomness\n\n#K_wp_nonfunctional.csr <- envelope(wp_nonfunctional_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\n\n#plot(K_wp_nonfunctional.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#analysing-spatial-point-process-using-l-function",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#analysing-spatial-point-process-using-l-function",
    "title": "Take-Home Excercise 01",
    "section": "7.2 Analysing Spatial Point Process Using L-Function",
    "text": "7.2 Analysing Spatial Point Process Using L-Function\n\n7.2.1 Functional Water Point\n\n#|eval: false\n#L_wp = Lest(wp_functional_ppp, correction = \"Ripley\")\n#plot(L_wp, . -r ~ r, \n     #ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n#|eval: false\n#L_wp.csr <- envelope(wp_functional_ppp, Lest, nsim = 39, rank = 1, glocal=TRUE)\n\n\n#|eval: false\n#plot(L_wp.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#importing-and-transforming-geospatial-data",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#importing-and-transforming-geospatial-data",
    "title": "Take-Home Excercise 01",
    "section": "3.1 Importing and Transforming Geospatial Data",
    "text": "3.1 Importing and Transforming Geospatial Data\nWe will begin by importing Geospatial data into R by using the st_read() of sf package. It imports the nga_admbnda_adm2_osgof_20190417 shapefile into R as a polygon data frame. We provide 2 arguments - dsn (which is the data path) and layer (the shapefile name)\nWe use the st_transform() to perform projection transaction.\n\ngeoNGA <- st_read(\"data/geospatial\", \n                  layer = \"geoBoundaries-NGA-ADM2\")\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `C:\\mayurims\\IS415-GAA\\Take-Home_Ex\\Take-Home_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\n\nNGA <- st_read(dsn = \"data/geospatial\", \n                  layer = \"nga_admbnda_adm2_osgof_20190417\")\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `C:\\mayurims\\IS415-GAA\\Take-Home_Ex\\Take-Home_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\nWe can use the glimpse() of dplyr to know more about the associated attribute information of the dataframe.\n\nglimpse(geoNGA)\n\nRows: 774\nColumns: 7\n$ shapeName  <chr> \"Aba North\", \"Aba South\", \"Arochukwu\", \"Bende\", \"Ikwuano\", …\n$ pcode      <chr> \"NG001001\", \"NG001002\", \"NG001003\", \"NG001004\", \"NG001005\",…\n$ level      <chr> \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"AD…\n$ shapeID    <chr> \"NGA-ADM2-13203401B25860527\", \"NGA-ADM2-13203401B76240303\",…\n$ shapeGroup <chr> \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NGA\", \"NG…\n$ shapeType  <chr> \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"ADM2\", \"AD…\n$ geometry   <MULTIPOLYGON [°]> MULTIPOLYGON (((7.387495 5...., MULTIPOLYGON (…\n\n\n\nglimpse(NGA)\n\nRows: 774\nColumns: 17\n$ Shape_Leng <dbl> 0.2370744, 0.2624772, 3.0753158, 2.5379842, 0.6871498, 1.06…\n$ Shape_Area <dbl> 0.0015239210, 0.0035311037, 0.3268678399, 0.0683785064, 0.0…\n$ ADM2_EN    <chr> \"Aba North\", \"Aba South\", \"Abadam\", \"Abaji\", \"Abak\", \"Abaka…\n$ ADM2_PCODE <chr> \"NG001001\", \"NG001002\", \"NG008001\", \"NG015001\", \"NG003001\",…\n$ ADM2_REF   <chr> \"Aba North\", \"Aba South\", \"Abadam\", \"Abaji\", \"Abak\", \"Abaka…\n$ ADM2ALT1EN <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM2ALT2EN <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ ADM1_EN    <chr> \"Abia\", \"Abia\", \"Borno\", \"Federal Capital Territory\", \"Akwa…\n$ ADM1_PCODE <chr> \"NG001\", \"NG001\", \"NG008\", \"NG015\", \"NG003\", \"NG011\", \"NG02…\n$ ADM0_EN    <chr> \"Nigeria\", \"Nigeria\", \"Nigeria\", \"Nigeria\", \"Nigeria\", \"Nig…\n$ ADM0_PCODE <chr> \"NG\", \"NG\", \"NG\", \"NG\", \"NG\", \"NG\", \"NG\", \"NG\", \"NG\", \"NG\",…\n$ date       <date> 2016-11-29, 2016-11-29, 2016-11-29, 2016-11-29, 2016-11-29…\n$ validOn    <date> 2019-04-17, 2019-04-17, 2019-04-17, 2019-04-17, 2019-04-17…\n$ validTo    <date> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ SD_EN      <chr> \"Abia South\", \"Abia South\", \"Borno North\", \"Federal Capital…\n$ SD_PCODE   <chr> \"NG00103\", \"NG00103\", \"NG00802\", \"NG01501\", \"NG00302\", \"NG0…\n$ geometry   <MULTIPOLYGON [°]> MULTIPOLYGON (((7.401109 5...., MULTIPOLYGON (…\n\n\nFrom the attributes visible, we can see the HDE source (NGA) has a column called ‘ADM1_EN’ which can be used to filter for water points in Osun, Nigeria. However, this is not present in the geoBoundaries dataset. As a result, we will only be using the Humanitarian Data Exchange source - nga_admbnda_adm2.\nHowever, NGA sf data.frame consists of many redundent fields. Hence, the code chunk below uses select() of dplyr to retain column 3, 4, 8 and 9.\n\nNGA <- NGA %>%\n  select(c(3:4, 8:9))\n\nWe then use the filter() to filter out the polygon features of Osun.\n\nNGA <- NGA %>% filter(ADM1_EN == \"Osun\")\n\nNow, we use the st_crs() to check the coordinate system of the data. As we can see, it uses the WGS 84 coordinate system. The data is using a Geographic projected system, however, this is system is not appropriate since we need to use distance and area measures.\n\nst_crs(NGA)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nHence, we use st_transform() and not st_set_crs() as st_set_crs() assigns the EPSG code to the data frame. And we need to transform the data frame from geographic to projected coordinate system. We will be using crs=26392 (found from the EPSG for Nigeria).\n\nNGA <- st_transform(NGA, crs = 26392)\n\nVerify that the CRS of NGA dataframe has changed.\n\nst_crs(NGA)\n\nCoordinate Reference System:\n  User input: EPSG:26392 \n  wkt:\nPROJCRS[\"Minna / Nigeria Mid Belt\",\n    BASEGEOGCRS[\"Minna\",\n        DATUM[\"Minna\",\n            ELLIPSOID[\"Clarke 1880 (RGS)\",6378249.145,293.465,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4263]],\n    CONVERSION[\"Nigeria Mid Belt\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",4,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",8.5,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.99975,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",670553.98,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Nigeria between 6°30'E and 10°30'E, onshore and offshore shelf.\"],\n        BBOX[3.57,6.5,13.53,10.51]],\n    ID[\"EPSG\",26392]]"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#colocation-of-functional-and-non-functional-water-points",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#colocation-of-functional-and-non-functional-water-points",
    "title": "Take-Home Excercise 01",
    "section": "8.2 Colocation of Functional and Non-Functional Water Points",
    "text": "8.2 Colocation of Functional and Non-Functional Water Points\nAdditionally, to understand the spatial correlation, we will be finding the colocation of functional and non-functional water point. The ‘unknown’ water points are not required, and hence, we use the filter() to remove them.\n\nwp_sf_withoutUnknown <- wp_sf_nga %>%  filter(!status_clean=='unknown')\n\nIn the code chunk below, st_knn() of sfdep package is used to determine the k (i.e. 6) nearest neighbors for given point geometry. The function st_kernel_weights() is used to derive a weights list by using a kernel function. To compute LCLQ, the reference point data must be in either character or vector list. We create two vector lists - one of Functional and for Non-Functional water point and are called A and B respectively. The code local_colocation() is used to compute the LCLQ values for each water point. Before we can plot the LCLQ values their p-values, we need to join the output of local_colocation() to the stores sf data.frame.\n\nnb <- include_self(\n  st_knn(st_geometry(wp_sf_withoutUnknown),6))\n\nwt <- st_kernel_weights(nb,\n                        wp_sf_withoutUnknown,\n                        \"gaussian\",\n                        adaptive = TRUE)\n\nA <- wp_functional$status_clean\n\nB <- wp_nonfunctional$status_clean\n\nLCLQ <- local_colocation(A, B, nb, wt, 49)\n\nLCLQ_stores <- cbind(wp_sf_withoutUnknown, LCLQ)\n\nThe below map plots the LCLQ analysis\n\ntmap_mode(\"view\")\ntm_shape(NGA) + \n  tm_polygons() + \n  tm_shape(LCLQ_stores)+\n    tm_dots(col = \"Non.Functional\",\n            size = 0.05,\n            border.col = \"grey\",\n            border.lwd = 0.5) + \n  tm_view(set.zoom.limits = c(8,11))\n\n\n\n\n\n\n\ntmap_mode(\"view\")\ntm_shape(NGA) + \n  tm_polygons() + \n  tm_shape(LCLQ_stores)+\n    tm_dots(col = \"Abandoned\",\n            size = 0.05,\n            border.col = \"grey\",\n            border.lwd = 0.5) + \n  tm_view(set.zoom.limits = c(9,13))\n\n\n\n\n\n\n\ntmap_mode(\"view\")\ntm_shape(NGA) + \n  tm_polygons() + \n  tm_shape(LCLQ_stores)+\n    tm_dots(col = \"Non.Functional.due.to.dry.season\",\n            size = 0.05,\n            border.col = \"grey\",\n            border.lwd = 0.5) + \n  tm_view(set.zoom.limits = c(9,11))\n\n\n\n\n\n\n\ntmap_mode(\"view\")\ntm_shape(NGA) + \n  tm_polygons() + \n  tm_shape(LCLQ_stores)+\n    tm_dots(col = \"Abandoned.Decommissioned\",\n            size = 0.05,\n            border.col = \"grey\",\n            border.lwd = 0.5) + \n  tm_view(set.zoom.limits = c(9,11))\n\n\n\n\n\n\nThe above maps show the colocation of Functional Water Points and Non-Functional Water Points. This means that Non-functional water points in color (‘Non-Functional’, ‘Abandoned’, ‘Non-functional due to dry season’) are surrounded by several Functional water points and hence, are colocated. The above code evaluates each Non-Functional water point individually for colocation with the presence of Functional water points. Hence, if the number of Non-functional water points within the neighborhood of Functional water points are higher than the global proportion of Non-Functional water points, the colocation point will be higher. As we can see from the above maps, there are many Non-functional water points colocated with Functional water points compared to that of ‘Abandoned’ or ‘Non-functional due to dry season’."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#non-functional-l-test",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#non-functional-l-test",
    "title": "Take-Home Excercise 01",
    "section": "Non functional L test",
    "text": "Non functional L test\n\n#L_nonwp = Lest(wp_nonfunctional_ppp, correction = \"Ripley\")\n#plot(L_ck_wp, . -r ~ r, \n     #ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n#|eval: false\n#L_nonwp.csr <- envelope(wp_nonfunctional_ppp, Lest, nsim = 39, rank = 1, glocal=TRUE)\n\n\n#|eval: false\n#plot(L_nonwp.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#choropleth-mapping",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#choropleth-mapping",
    "title": "Take-Home Excercise 01",
    "section": "4.4 Choropleth Mapping",
    "text": "4.4 Choropleth Mapping\nWe will be calculating the proportion of Functional and Non-Functional water points and mapping them to see which area of Osun has more proportions of functional and non-functional water points.\n\nNGA_wp_total <- NGA_wp %>%\n  mutate(pct_functional = wp_functional/total_wp) %>%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\ntm_shape(NGA_wp_total) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)\n\n\n\n\n\n\n\ntm_shape(NGA_wp_total) +\n  tm_fill(\"pct_nonfunctional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of non-functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-pre-processing-1",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-pre-processing-1",
    "title": "Take-Home Excercise 01",
    "section": "8.1 Data Pre-Processing",
    "text": "8.1 Data Pre-Processing\nFor this, we will be using the wp_sf_nga dataframe which has all the water points. We will first convert sf data frames to sp’s Spatial class\n\nwp_spatial <- as_Spatial(wp_sf_nga)\n\nConvert spatial class into generic sp class\n\nwp_sp <- as(wp_spatial, \"SpatialPoints\")\n\nConverting generic sp format into spatstat’s ppp format\n\nwp_ppp <- as(wp_sp, \"ppp\")\nwp_ppp\n\nPlanar point pattern: 5557 points\nwindow: rectangle = [177285.9, 291287.05] x [340054.1, 450859.7] units\n\n\n\nplot(wp_ppp)\n\n\n\n\nFor this analysis, we will be working with marked data, and we know that the values are categorical (different water points), we need to ensure that the marked field is of factor data type. However, as seen from the output, our status_clean field is of chr data type, not factor! Hence, we will use the as.factor() function:\n\nwp_spatial@data$status_clean <-as.factor(wp_spatial@data$status_clean)\n\nWe then convert our spatial data datafram intto ppp format and create an owin object.\n\nwp_spatial_marked_ppp <- as(wp_spatial, \"ppp\")\n\n\nwp_spatial_marked_ppp = wp_spatial_marked_ppp[NGA_owin]\n\n\nplot(wp_spatial_marked_ppp, which.marks = \"status_clean\")\n\n\n\n\nWe use the density() to compute the kernel density objects, and the use plot() to plot it out. Further, we convert the meter to kilometers using rescale()\n\nplot((density(split(rescale(wp_spatial_marked_ppp, 1000)))))\n\n\n\n\nBefore we proceed with our second order spatial analysis, we need to assign marks to the ppp objects + check the levels of the marks:\n\nlevels(marks(wp_spatial_marked_ppp))\n\n[1] \"Abandoned\"                        \"Abandoned/Decommissioned\"        \n[3] \"Functional\"                       \"Functional but needs repair\"     \n[5] \"Functional but not in use\"        \"Non-Functional\"                  \n[7] \"Non-Functional due to dry season\" \"unknown\"                         \n\n\nAs we can see from the marks, and the above density maps, there are 7 levels here. However, we need them to be only classified into 3 - Functional, Non-Functional and unknown. Hence, we will be using the below code to rename the variable.\n\nlevels(marks(wp_spatial_marked_ppp))[levels(marks(wp_spatial_marked_ppp)) == \"Abandoned\"] <- \"Non-Functional\"\n\n\nlevels(marks(wp_spatial_marked_ppp))[levels(marks(wp_spatial_marked_ppp)) == \"Abandoned/Decommissioned\"] <- \"Non-Functional\"\n\n\nlevels(marks(wp_spatial_marked_ppp))[levels(marks(wp_spatial_marked_ppp)) == \"Non-Functional due to dry season\"] <- \"Non-Functional\"\n\n\nlevels(marks(wp_spatial_marked_ppp))[levels(marks(wp_spatial_marked_ppp)) == \"Functional but needs repair\"] <- \"Functional\"\n\n\nlevels(marks(wp_spatial_marked_ppp))[levels(marks(wp_spatial_marked_ppp)) == \"Functional but not in use\"] <- \"Functional\"\n\nNow, upon running the below code, we can see that all the levels are categorized into our 3 desired levels.\n\nlevels(wp_spatial_marked_ppp[[\"marks\"]])\n\n[1] \"Non-Functional\" \"Functional\"     \"unknown\"       \n\n\n\nplot(wp_spatial_marked_ppp, which.marks = \"status_clean\")\n\n\n\n\n\nplot(density(split(wp_spatial_marked_ppp)))\n\n\n\n\nFrom the above density maps, we can observe a relationship between Functional and Non-Functional water points - in the sense that the there seems to be a lot of water Functional water points where ever there are Non-Functional water points. They seem to coexist together quite a lot of times, and hence indicating some level of dependence between them. Hence, to investigate this, we will be using the Cross K-Function.\n\nH0: The spatial distribution of Functional and Non-Functional water points are spatially independent\nH1: The spatial distribution of Functional and Non-Functional water points are not spatially independent\nConfidence Level: 99%\nSignificance Level: 0.01%\n\nThe null-hypothesis will be rejected if the p-value is smaller than alpha value of 0.01.\n\n# eval = FALSE\nwp_spatial_marked_ppp_Lcross.csr <- envelope(wp_spatial_marked_ppp, \n                                 Lcross, \n                                 i=\"Functional\", \n                                 j=\"Non-Functional\", \n                                 correction=\"border\", \n                                 nsim=999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10 [etd 4:31] .........20 [etd 4:06] .........\n30 [etd 4:13] .........40 [etd 4:13] .........50 [etd 4:08] ........\n.60 [etd 4:13] .........70 [etd 4:05] .........80 [etd 4:02] .......\n..90 [etd 3:56] .........100 [etd 3:51] .........110 [etd 3:49] ......\n...120 [etd 3:47] .........130 [etd 3:44] .........140 [etd 3:39] .....\n....150 [etd 3:37] .........160 [etd 3:32] .........170 [etd 3:31] ....\n.....180 [etd 3:28] .........190 [etd 3:25] .........200 [etd 3:23] ...\n......210 [etd 3:20] .........220 [etd 3:17] .........230 [etd 3:16] ..\n.......240 [etd 3:12] .........250 [etd 3:10] .........260 [etd 3:08] .\n........270 [etd 3:06] .........280 [etd 3:03] .........290\n [etd 3:02] .........300 [etd 3:02] .........310 [etd 3:03] .........\n320 [etd 3:00] .........330 [etd 2:57] .........340 [etd 2:55] ........\n.350 [etd 2:53] .........360 [etd 2:51] .........370 [etd 2:48] .......\n..380 [etd 2:46] .........390 [etd 2:43] .........400 [etd 2:41] ......\n...410 [etd 2:37] .........420 [etd 2:36] .........430 [etd 2:34] .....\n....440 [etd 2:31] .........450 [etd 2:28] .........460 [etd 2:26] ....\n.....470 [etd 2:23] .........480 [etd 2:20] .........490 [etd 2:17] ...\n......500 [etd 2:14] .........510 [etd 2:11] .........520 [etd 2:09] ..\n.......530 [etd 2:06] .........540 [etd 2:04] .........550 [etd 2:01] .\n........560 [etd 1:59] .........570 [etd 1:56] .........580\n [etd 1:53] .........590 [etd 1:50] .........600 [etd 1:47] .........\n610 [etd 1:44] .........620 [etd 1:42] .........630 [etd 1:40] ........\n.640 [etd 1:37] .........650 [etd 1:35] .........660 [etd 1:32] .......\n..670 [etd 1:30] .........680 [etd 1:27] .........690 [etd 1:25] ......\n...700 [etd 1:22] .........710 [etd 1:19] .........720 [etd 1:17] .....\n....730 [etd 1:14] .........740 [etd 1:11] .........750 [etd 1:08] ....\n.....760 [etd 1:06] .........770 [etd 1:03] .........780 [etd 1:01] ...\n......790 [etd 58 sec] .........800 [etd 55 sec] .........810 [etd 53 sec] ..\n.......820 [etd 50 sec] .........830 [etd 47 sec] .........840 [etd 44 sec] .\n........850 [etd 41 sec] .........860 [etd 38 sec] .........870\n [etd 36 sec] .........880 [etd 33 sec] .........890 [etd 30 sec] .........\n900 [etd 27 sec] .........910 [etd 24 sec] .........920 [etd 22 sec] ........\n.930 [etd 19 sec] .........940 [etd 16 sec] .........950 [etd 13 sec] .......\n..960 [etd 11 sec] .........970 [etd 8 sec] .........980 [etd 5 sec] ......\n...990 [etd 2 sec] ........ 999.\n\nDone.\n\n\n\nplot(wp_spatial_marked_ppp_Lcross.csr, xlab=\"distance(km)\", xlim=c(0,500))\n\n\n\n\nConclusion : The Functional and Non-Functional water point are not statistically independent as the empirical k-cross line is outside of the envelope of 99% confidence level, and for that we reject the null hypothesis. This lends weight to what we noticed in our previous maps, where the location of the Functional and Non-Functional water points seem to coincide. And hence, the relation between spatial distribution of Functional and Non-Functional water points is not independent."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "Welcome to  IS415 Geospatial Analytics and Applications. \nI am Mayuri Salunke, and this is my Workpage for IS415!"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-On Excercise 06 : Spatial Weights and Applications",
    "section": "",
    "text": "pacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#performing-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#performing-relational-join",
    "title": "Hands-On Excercise 06 : Spatial Weights and Applications",
    "section": "Performing Relational Join",
    "text": "Performing Relational Join\n\nhunan <- left_join(hunan,hunan2012)%>%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-queen-contiguity-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-queen-contiguity-based-neighbours",
    "title": "Hands-On Excercise 06 : Spatial Weights and Applications",
    "section": "Computing (QUEEN) contiguity based neighbours",
    "text": "Computing (QUEEN) contiguity based neighbours\n\nwm_q <- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\n\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-rook-contiguity-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-rook-contiguity-based-neighbours",
    "title": "Hands-On Excercise 06 : Spatial Weights and Applications",
    "section": "Creating (ROOK) contiguity based neighbours",
    "text": "Creating (ROOK) contiguity based neighbours\n\nwm_r <- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-contiguity-weights",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-contiguity-weights",
    "title": "Hands-On Excercise 06 : Spatial Weights and Applications",
    "section": "Visualising contiguity weights",
    "text": "Visualising contiguity weights\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\n\ncoords <- cbind(longitude, latitude)\n\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\nPlotting Queen contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\nPlotting Rook contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\nPlotting both Queen and Rook contiguity based neighbours maps\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\", main=\"Queen Contiguity\")\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\", main=\"Rook Contiguity\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#determine-the-cut-off-distance",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#determine-the-cut-off-distance",
    "title": "Hands-On Excercise 06 : Spatial Weights and Applications",
    "section": "Determine the cut-off distance",
    "text": "Determine the cut-off distance\n\n#coords <- coordinates(hunan)\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\nComputing fixed distance weight matrix\n\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp <- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08, main=\"1st nearest neighbours\")\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6, main=\"Distance link\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands-On Excercise 06 : Spatial Weights and Applications",
    "section": "Computing adaptive distance weight matrix",
    "text": "Computing adaptive distance weight matrix\n\nknn6 <- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-lag-with-row-standardized-weights",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-lag-with-row-standardized-weights",
    "title": "Hands-On Excercise 06 : Spatial Weights and Applications",
    "section": "Spatial lag with row-standardized weights",
    "text": "Spatial lag with row-standardized weights\n\nGDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\n\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\nlag.list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res <- as.data.frame(lag.list)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag GDPPC\")\nhunan <- left_join(hunan,lag.res)\n\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\n\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_gdppc <- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-lag-as-a-sum-of-neighboring-values",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-lag-as-a-sum-of-neighboring-values",
    "title": "Hands-On Excercise 06 : Spatial Weights and Applications",
    "section": "Spatial lag as a sum of neighboring values",
    "text": "Spatial lag as a sum of neighboring values\n\nb_weights <- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 <- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\n\nlag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res <- as.data.frame(lag_sum)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag_sum GDPPC\")\n\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\n\nhunan <- left_join(hunan, lag.res)\n\n\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc <- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-window-average",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-window-average",
    "title": "Hands-On Excercise 06 : Spatial Weights and Applications",
    "section": "Spatial window average",
    "text": "Spatial window average\n\nwm_qs <- include.self(wm_q)\n\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\n\nwm_qs <- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\n\nlag_w_avg_gpdpc <- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\n\nlag.list.wm_qs <- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res <- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) <- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\n\nhunan <- left_join(hunan, lag_wm_qs.res)\n\n\nhunan %>%\n  select(\"County\", \"lag GDPPC\", \"lag_window_avg GDPPC\") %>%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\n\n\n\n\nw_avg_gdppc <- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-window-sum",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-window-sum",
    "title": "Hands-On Excercise 06 : Spatial Weights and Applications",
    "section": "Spatial window sum",
    "text": "Spatial window sum\n\nwm_qs <- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\n\nb_weights <- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\n\nb_weights2 <- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\n\nw_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\n\nw_sum_gdppc.res <- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) <- c(\"NAME_3\", \"w_sum GDPPC\")\n\n\nhunan <- left_join(hunan, w_sum_gdppc.res)\n\n\nhunan %>%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %>%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\n\nw_sum_gdppc <- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex06/In-Class_Ex06.html",
    "href": "In-Class_Ex/In-Class_Ex06/In-Class_Ex06.html",
    "title": "In-Class Excercise 06",
    "section": "",
    "text": "Installing and Loading the required packages\n\npacman::p_load(tmap, sf, sfdep, tidyverse)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex06/In-Class_Ex06.html#importing-geospatial-data",
    "href": "In-Class_Ex/In-Class_Ex06/In-Class_Ex06.html#importing-geospatial-data",
    "title": "In-Class Excercise 06",
    "section": "Importing Geospatial Data",
    "text": "Importing Geospatial Data\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\mayurims\\IS415-GAA\\In-Class_Ex\\In-Class_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex06/In-Class_Ex06.html#importing-attribute-table",
    "href": "In-Class_Ex/In-Class_Ex06/In-Class_Ex06.html#importing-attribute-table",
    "title": "In-Class Excercise 06",
    "section": "Importing Attribute Table",
    "text": "Importing Attribute Table\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex06/In-Class_Ex06.html#combining-both-data-frame-by-using-left-join",
    "href": "In-Class_Ex/In-Class_Ex06/In-Class_Ex06.html#combining-both-data-frame-by-using-left-join",
    "title": "In-Class Excercise 06",
    "section": "Combining both data frame by using left join",
    "text": "Combining both data frame by using left join\nCombine the Geospatial and Aspatial data here. One is a sf data frame and the other is a tibble data frame. One has a geometry column frame and the other doesn’t. If you want to retain the geometry column, then the left one should be the one with sf data frame and the right one should be the tibble data frame.\nNotes :\n\nLeft_join() keeps all observations in x\nRight_join() keeps all observations in y\nFull_join() keeps all observations in x and y\n\nNormally you need to join the unique identifier (common field), but in this case, we did not mention it. But here we can assume that it will find a field which is common. But we need to ensure that both have 88 observations and that the ‘County’ field name is same for both (the lower/upper case, etc.)\nThe select is just asking it to take the columns 1-4, 7 and 15 after they join. Because we just need these columns and the main - GDPPC. Hence, we drop the rest. If we don’t have the select function, we would have had 36 variables. We keep ‘NAME_3’ and ‘County’ for double checking.\n\nhunan_GDPPC <- left_join(hunan, hunan2012) %>%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex06/In-Class_Ex06.html#plotting-a-choropleth-map",
    "href": "In-Class_Ex/In-Class_Ex06/In-Class_Ex06.html#plotting-a-choropleth-map",
    "title": "In-Class Excercise 06",
    "section": "Plotting a Choropleth map",
    "text": "Plotting a Choropleth map\n\n# You NEED this for Take Home Assignment 2!!\ntmap_mode(\"plot\")\ntm_shape(hunan_GDPPC) + \n  tm_fill(\"GDPPC\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"GDPPC\") + \n  tm_layout(main.title = \"Distribution of GDP per capita by district, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) + \n  tm_borders(alpha = 0.5) + \n  # tm_text(\"NAME_3\", size=0.5) + \n  tm_compass(type = \"8star\", size = 2) + \n  tm_scale_bar() + \n  tm_grid(alpha = 0.2)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex06/In-Class_Ex06.html#contiguity-neighbors-method",
    "href": "In-Class_Ex/In-Class_Ex06/In-Class_Ex06.html#contiguity-neighbors-method",
    "title": "In-Class Excercise 06",
    "section": "Contiguity Neighbors Method",
    "text": "Contiguity Neighbors Method\nDefault is Queen. The function poly2nb() used in Hands-on_Ex06 is the same as this function st_contiguity().\n\ncn_queen <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         .before = 1)\n\nHere, when we make the queen = False, it becomes a Rook method. We do have another method called Bishop, but we don’t have it, since no one uses it.\n\ncn_rook <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         queen = FALSE,\n         .before = 1)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex06/In-Class_Ex06.html#computing-contiguity-weights",
    "href": "In-Class_Ex/In-Class_Ex06/In-Class_Ex06.html#computing-contiguity-weights",
    "title": "In-Class Excercise 06",
    "section": "Computing contiguity weights",
    "text": "Computing contiguity weights\n\nContiguity weights: Queen’s method\nThis code makes Contiguity Neighbors Method redundant as this code does that and combines the next code as well.\n\nwm_q <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb),\n         .before = 1)\n\n\n\nContiguity weights: Rook’s method\n\nwm_q <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         queen = FALSE,\n         wt = st_weights(nb),\n         .before = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html",
    "href": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html",
    "title": "Hands-on Excercise 07 Part 1: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "pacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html#import-shapefile-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html#import-shapefile-into-r-environment",
    "title": "Hands-on Excercise 07 Part 1: Global Measures of Spatial Autocorrelation",
    "section": "Import shapefile into r environment",
    "text": "Import shapefile into r environment\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\mayurims\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex07(1)\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html#import-csv-file-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html#import-csv-file-into-r-environment",
    "title": "Hands-on Excercise 07 Part 1: Global Measures of Spatial Autocorrelation",
    "section": "Import csv file into r environment",
    "text": "Import csv file into r environment\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html#performing-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html#performing-relational-join",
    "title": "Hands-on Excercise 07 Part 1: Global Measures of Spatial Autocorrelation",
    "section": "Performing Relational Join",
    "text": "Performing Relational Join\n\nhunan <- left_join(hunan,hunan2012) %>%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html#visualising-regional-development-indicator",
    "title": "Hands-on Excercise 07 Part 1: Global Measures of Spatial Autocorrelation",
    "section": "Visualising Regional Development Indicator",
    "text": "Visualising Regional Development Indicator\n\nequal <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html#computing-contiguity-spatial-weights",
    "title": "Hands-on Excercise 07 Part 1: Global Measures of Spatial Autocorrelation",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\n\nwm_q <- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html#row-standardised-weights-matrix",
    "title": "Hands-on Excercise 07 Part 1: Global Measures of Spatial Autocorrelation",
    "section": "Row-standardised weights matrix",
    "text": "Row-standardised weights matrix\n\nrswm_q <- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html#marons-i-test",
    "href": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html#marons-i-test",
    "title": "Hands-on Excercise 07 Part 1: Global Measures of Spatial Autocorrelation",
    "section": "Maron’s I test",
    "text": "Maron’s I test\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nComputing Monte Carlo Moran’s I\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\nVisualising Monte Carlo Moran’s I\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html#global-spatial-autocorrelation-gearys",
    "href": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html#global-spatial-autocorrelation-gearys",
    "title": "Hands-on Excercise 07 Part 1: Global Measures of Spatial Autocorrelation",
    "section": "Global Spatial Autocorrelation: Geary’s",
    "text": "Global Spatial Autocorrelation: Geary’s\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html#compute-morans-i-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex07(1)/Hands-on_Ex07(1).html#compute-morans-i-correlogram",
    "title": "Hands-on Excercise 07 Part 1: Global Measures of Spatial Autocorrelation",
    "section": "Compute Moran’s I correlogram",
    "text": "Compute Moran’s I correlogram\n\nMI_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nCompute Geary’s C correlogram and plot\n\nGC_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html",
    "href": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html",
    "title": "Hands-on Excercise 07 Part 2: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "pacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#import-shapefile-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#import-shapefile-into-r-environment",
    "title": "Hands-on Excercise 07 Part 2: Local Measures of Spatial Autocorrelation",
    "section": "Import shapefile into r environment",
    "text": "Import shapefile into r environment\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\mayurims\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex07(2)\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#import-csv-file-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#import-csv-file-into-r-environment",
    "title": "Hands-on Excercise 07 Part 2: Local Measures of Spatial Autocorrelation",
    "section": "Import csv file into r environment",
    "text": "Import csv file into r environment\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#performing-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#performing-relational-join",
    "title": "Hands-on Excercise 07 Part 2: Local Measures of Spatial Autocorrelation",
    "section": "Performing relational join",
    "text": "Performing relational join\n\nhunan <- left_join(hunan,hunan2012) %>%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#visualising-regional-development-indicator",
    "title": "Hands-on Excercise 07 Part 2: Local Measures of Spatial Autocorrelation",
    "section": "Visualising Regional Development Indicator",
    "text": "Visualising Regional Development Indicator\n\nequal <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile <- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#computing-contiguity-spatial-weights",
    "title": "Hands-on Excercise 07 Part 2: Local Measures of Spatial Autocorrelation",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\n\nwm_q <- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#row-standardised-weights-matrix",
    "title": "Hands-on Excercise 07 Part 2: Local Measures of Spatial Autocorrelation",
    "section": "Row-standardised weights matrix",
    "text": "Row-standardised weights matrix\n\nrswm_q <- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#global-spatial-autocorrelation-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#global-spatial-autocorrelation-morans-i",
    "title": "Hands-on Excercise 07 Part 2: Local Measures of Spatial Autocorrelation",
    "section": "Global Spatial Autocorrelation: Moran’s I",
    "text": "Global Spatial Autocorrelation: Moran’s I\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#global-spatial-autocorrelation-gearys",
    "href": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#global-spatial-autocorrelation-gearys",
    "title": "Hands-on Excercise 07 Part 2: Local Measures of Spatial Autocorrelation",
    "section": "Global Spatial Autocorrelation: Geary’s",
    "text": "Global Spatial Autocorrelation: Geary’s\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#compute-morans-i-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#compute-morans-i-correlogram",
    "title": "Hands-on Excercise 07 Part 2: Local Measures of Spatial Autocorrelation",
    "section": "Compute Moran’s I correlogram",
    "text": "Compute Moran’s I correlogram\n\nMI_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#compute-gearys-c-correlogram-and-plot",
    "href": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#compute-gearys-c-correlogram-and-plot",
    "title": "Hands-on Excercise 07 Part 2: Local Measures of Spatial Autocorrelation",
    "section": "Compute Geary’s C correlogram and plot",
    "text": "Compute Geary’s C correlogram and plot\n\nGC_corr <- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#plotting-moran-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#plotting-moran-scatterplot",
    "title": "Hands-on Excercise 07 Part 2: Local Measures of Spatial Autocorrelation",
    "section": "Plotting Moran scatterplot",
    "text": "Plotting Moran scatterplot\n\nnci <- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#plotting-moran-scatterplot-with-standardised-variable",
    "href": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#plotting-moran-scatterplot-with-standardised-variable",
    "title": "Hands-on Excercise 07 Part 2: Local Measures of Spatial Autocorrelation",
    "section": "Plotting Moran scatterplot with standardised variable",
    "text": "Plotting Moran scatterplot with standardised variable\n\nhunan$Z.GDPPC <- scale(hunan$GDPPC) %>% \n  as.vector \n\n\nnci2 <- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#preparing-lisa-map-classes",
    "href": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#preparing-lisa-map-classes",
    "title": "Hands-on Excercise 07 Part 2: Local Measures of Spatial Autocorrelation",
    "section": "Preparing LISA map classes",
    "text": "Preparing LISA map classes\n\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))\n\n\nhunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)\nDV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\n\nLM_I <- localMI[,1] - mean(localMI[,1])    \n\n\nsignif <- 0.05       \n\n\nquadrant[DV <0 & LM_I>0] <- 1\nquadrant[DV >0 & LM_I<0] <- 2\nquadrant[DV <0 & LM_I<0] <- 3  \nquadrant[DV >0 & LM_I>0] <- 4      \n\n\nquadrant[localMI[,5]>signif] <- 0\n\n\nquadrant <- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC <- lag.listw(rswm_q, hunan$GDPPC)\nDV <- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I <- localMI[,1]   \nsignif <- 0.05       \nquadrant[DV <0 & LM_I>0] <- 1\nquadrant[DV >0 & LM_I<0] <- 2\nquadrant[DV <0 & LM_I<0] <- 3  \nquadrant[DV >0 & LM_I>0] <- 4    \nquadrant[localMI[,5]>signif] <- 0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#plotting-lisa-map",
    "href": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#plotting-lisa-map",
    "title": "Hands-on Excercise 07 Part 2: Local Measures of Spatial Autocorrelation",
    "section": "Plotting LISA map",
    "text": "Plotting LISA map\n\nhunan.localMI$quadrant <- quadrant\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\ngdppc <- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant <- quadrant\ncolors <- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters <- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap <- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#gi-statistics-using-fixed-distance",
    "href": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#gi-statistics-using-fixed-distance",
    "title": "Hands-on Excercise 07 Part 2: Local Measures of Spatial Autocorrelation",
    "section": "Gi statistics using fixed distance",
    "text": "Gi statistics using fixed distance\n\nfips <- order(hunan$County)\ngi.fixed <- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\n\nhunan.gi <- cbind(hunan, as.matrix(gi.fixed)) %>%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\n\nMapping Gi values with fixed distance weights\n\ngdppc <- qtm(hunan, \"GDPPC\")\n\nGimap <-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#gi-statistics-using-adaptive-distance",
    "href": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#gi-statistics-using-adaptive-distance",
    "title": "Hands-on Excercise 07 Part 2: Local Measures of Spatial Autocorrelation",
    "section": "Gi statistics using adaptive distance",
    "text": "Gi statistics using adaptive distance\n\nfips <- order(hunan$County)\ngi.adaptive <- localG(hunan$GDPPC, knn_lw)\nhunan.gi <- cbind(hunan, as.matrix(gi.adaptive)) %>%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#mapping-gi-values-with-adaptive-distance-weights",
    "href": "Hands-on_Ex/Hands-on_Ex07(2)/Hands-on_Ex07(2).html#mapping-gi-values-with-adaptive-distance-weights",
    "title": "Hands-on Excercise 07 Part 2: Local Measures of Spatial Autocorrelation",
    "section": "Mapping Gi values with adaptive distance weights",
    "text": "Mapping Gi values with adaptive distance weights\n\ngdppc<- qtm(hunan, \"GDPPC\")\n\nGimap <- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html",
    "href": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html",
    "title": "In-Class Excercise 07",
    "section": "",
    "text": "pacman::p_load(tmap, sf, sfdep, tidyverse)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html#importing-geospatial-data",
    "href": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html#importing-geospatial-data",
    "title": "In-Class Excercise 07",
    "section": "Importing Geospatial Data",
    "text": "Importing Geospatial Data\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\mayurims\\IS415-GAA\\In-Class_Ex\\In-Class_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html#importing-attribute-tablecombining-both-data-frame-by-using-left-join",
    "href": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html#importing-attribute-tablecombining-both-data-frame-by-using-left-join",
    "title": "In-Class Excercise 07",
    "section": "Importing Attribute TableCombining Both Data frame by using Left Join",
    "text": "Importing Attribute TableCombining Both Data frame by using Left Join\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\nhunan_GDPPC <- left_join(hunan, hunan2012) %>%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html#plotting-a-choropleth-map",
    "href": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html#plotting-a-choropleth-map",
    "title": "In-Class Excercise 07",
    "section": "Plotting a Choropleth Map",
    "text": "Plotting a Choropleth Map\n\ntmap_mode(\"plot\")\ntm_shape(hunan_GDPPC) + \n  tm_fill(\"GDPPC\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"GDPPC\") + \n  tm_layout(main.title = \"Distribution of GDP per capita by district, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) + \n  tm_borders(alpha = 0.5) + \n  # tm_text(\"NAME_3\", size=0.5) + \n  tm_compass(type = \"8star\", size = 2) + \n  tm_scale_bar() + \n  tm_grid(alpha = 0.2)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html#contiguity-weights-queens-method",
    "href": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html#contiguity-weights-queens-method",
    "title": "In-Class Excercise 07",
    "section": "Contiguity weights: Queen’s method",
    "text": "Contiguity weights: Queen’s method\n\nwm_q <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb),\n         .before = 1)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html#computing-global-morani",
    "href": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html#computing-global-morani",
    "title": "In-Class Excercise 07",
    "section": "Computing Global Moran’I",
    "text": "Computing Global Moran’I\n\nmoranI <- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html#performing-global-moranl-test",
    "href": "In-Class_Ex/In-Class_Ex07/In-Class_Ex07.html#performing-global-moranl-test",
    "title": "In-Class Excercise 07",
    "section": "Performing Global Moran’l test",
    "text": "Performing Global Moran’l test\n\nglobal_moran_test(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nset.seed(1234)\n\nThe below code runs multiple simulations\n\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02.html",
    "href": "Take-Home_Ex/Take-Home_Ex02.html",
    "title": "Take-Home Excercise 02",
    "section": "",
    "text": "wehsbf kjefnb erng lkdjgn elrgnlrk lreig"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02.html#packages-used",
    "href": "Take-Home_Ex/Take-Home_Ex02.html#packages-used",
    "title": "Take-Home Excercise 02",
    "section": "2.1 Packages Used",
    "text": "2.1 Packages Used\n\nsf : Used for importing geospatial data, assigning or transforming coordinate systems, and converting geospatial and aspatial data into a sf data frame\ntidyverse : Used for transforming and better presentation of Data\ntmap : Used for plotting static point patterns maps or interactive maps\nspatstat : Used for point-pattern analysis\nraster : Used to read, write, manipulate, analyse and model gridded spatial data\nmaptools : Used to provide a set of tools for manipulating geographic data\nkableExtra : Used for table customization\nsfdep : Used for functions creates not present in spdep.\nreadxl\nknitr\n\n\npacman::p_load(sf, maptools, raster, spatstat, tmap, kableExtra, tidyverse, sfdep, readxl, knitr)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02.html#datasets-used",
    "href": "Take-Home_Ex/Take-Home_Ex02.html#datasets-used",
    "title": "Take-Home Excercise 02",
    "section": "2.2 Datasets Used",
    "text": "2.2 Datasets Used\n\n# initialise a dataframe of our geospatial and aspatial dataset details\ndatasets <- data.frame(\n  Type=c(\"Geospatial\",\n         \"Aspatial\"),\n  \n  Name=c(\"DKI Jakarta Provincial Village Boundary\",\n         \"District Based Vaccination History\"),\n  \n  Format=c(\".shp\", \n           \".xlsx\"),\n  \n  Source=c(\"[Shapefile (SHP) Batas Desa Provinsi DKI Jakarta](https://www.indonesia-geospasial.com/2020/04/download-shapefile-shp-batas-desa.html)\",\n           \"[Open Data Vaksinasi\nProvinsi DKI Jakarta](https://riwayat-file-vaksinasi-dki-jakarta-jakartagis.hub.arcgis.com/)\"),\n  \n  Description=c(\"It has the District level boundary data of DKI Jakarta of 2019\",\n                \"The muiliple excel files consists of all the vaccinations done at Village and District based.\")\n  )\n\n# with reference to this guide on kableExtra:\n# https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html\n# kable_material is the name of the kable theme\n# 'hover' for to highlight row when hovering, 'scale_down' to adjust table to fit page width\nlibrary(knitr)\nlibrary(kableExtra)\nkable(datasets, caption=\"Datasets Used\") %>%\n  kable_material(\"hover\", latex_options=\"scale_down\")\n\n\n\nDatasets Used\n \n  \n    Type \n    Name \n    Format \n    Source \n    Description \n  \n \n\n  \n    Geospatial \n    DKI Jakarta Provincial Village Boundary \n    .shp \n    [Shapefile (SHP) Batas Desa Provinsi DKI Jakarta](https://www.indonesia-geospasial.com/2020/04/download-shapefile-shp-batas-desa.html) \n    It has the District level boundary data of DKI Jakarta of 2019 \n  \n  \n    Aspatial \n    District Based Vaccination History \n    .xlsx \n    [Open Data Vaksinasi\nProvinsi DKI Jakarta](https://riwayat-file-vaksinasi-dki-jakarta-jakartagis.hub.arcgis.com/) \n    The muiliple excel files consists of all the vaccinations done at Village and District based."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html",
    "title": "Take-Home Excercise 02",
    "section": "",
    "text": "As of the latest available data, Jakarta, the capital city of Indonesia, has been one of the hardest-hit regions in the country in terms of COVID-19 cases. The first confirmed case in Jakarta was reported on March 2, 2020, and since then, the number of cases has steadily increased.\nAs of February 24, 2023, the total number of confirmed cases in Jakarta has reached over 1.4 million, which is around 12% of the total cases in Indonesia. The number of active cases has decreased over the past few months, but there are still several thousand active cases in Jakarta.\nThe Jakarta government has implemented various measures to curb the spread of the virus, including social distancing rules, mandatory mask-wearing in public, and limiting public gatherings. The government has also conducted mass testing and contact tracing efforts to isolate those who have been infected.\nOverall, the situation in Jakarta remains concerning, but the government’s efforts to control the spread of the virus have helped to mitigate the impact of the pandemic on the city.\n\n\n\nJakarta records 584 new confirmed COVID-19 cases This article was published in thejakartapost.com with the title “Jakarta records 584 new confirmed COVID-19 cases”."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#packages-used",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#packages-used",
    "title": "Take-Home Excercise 02",
    "section": "2.1 Packages Used",
    "text": "2.1 Packages Used\n\nsf : Used for importing geospatial data, assigning or transforming coordinate systems, and converting geospatial and aspatial data into a sf data frame\ntidyverse : Used for transforming and better presentation of Data\ntmap : Used for plotting static point patterns maps or interactive map\nkableExtra : Used for table customization\nsfdep : Used for functions creates not present in spdep.\nreadxl : Used for reading Microsoft Excel files\nplyr : Used for splitting, applying and combining data in a “split-apply-combine” framework\nKendall : Used for computnig Kendall tau and is used for Mann Kendall Test\nplotly : Used for creating interactive web-based visualisations\n\n\npacman::p_load(sf, tmap, kableExtra, tidyverse, sfdep, readxl, plyr, Kendall, plotly)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#datasets-used",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#datasets-used",
    "title": "Take-Home Excercise 02",
    "section": "2.2 Datasets Used",
    "text": "2.2 Datasets Used\n\n\n\n\nDatasets Used\n \n  \n    Type \n    Name \n    Format \n    Source \n    Description \n  \n \n\n  \n    Geospatial \n    DKI Jakarta Provincial Village Boundary \n    .shp \n    (https://www.indonesia-geospasial.com/2020/04/download-shapefile-shp-batas-desa.html) \n    It has the District level boundary data of DKI Jakarta of 2019 \n  \n  \n    Aspatial \n    District Based Vaccination History \n    .xlsx \n    (https://riwayat-file-vaksinasi-dki-jakarta-jakartagis.hub.arcgis.com/) \n    The muiliple excel files consists of all the vaccinations done at Village and District based. \n  \n\n\n\n\n\nThings to Note for Aspatial Data:\nTo retrieve the monthly cumulative records for the COVID-19 cases in Jakarta, I took the data compiled on the last of every month (e.g - 31st July, 30tt August … ) from July 2021 to June 2022. I had started with taking the first of every month, however, i realized that the data for 1st March 2022 is actually of 2nd March 2022. And to have consistency in the data, I decided to use the last day of every month instead.\nFurther, the data consists of the following groups -\n\nVaccination of Elderly (Lansia)\nVaccination of Public Servant (Pelayan Publik)\nMutual Cooperation (Goton Royong) Vaccination\nVaccination of Health Workers (Tenaga Kesehatan)\nStage 3 (Tahapan) Vaccinations\nVaccination of Teenagers (Remaja)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#importing-geospatial-data",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#importing-geospatial-data",
    "title": "Take-Home Excercise 02",
    "section": "3.1 Importing Geospatial Data",
    "text": "3.1 Importing Geospatial Data\nWe will begin by importing Geospatial data into R by using the st_read() of sf package. It imports the BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA shapefile into R as a polygon data frame. We provide 2 arguments - dsn (which is the data path) and layer (the shapefile name)\n\njakarta <- st_read(dsn=\"data/geospatial\",\n                   layer=\"BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA\")\n\nReading layer `BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA' from data source \n  `C:\\mayurims\\IS415-GAA\\Take-Home_Ex\\Take-Home_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 269 features and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 106.3831 ymin: -6.370815 xmax: 106.9728 ymax: -5.184322\nGeodetic CRS:  WGS 84\n\n\nFrom the output message, we learn that:\n\nGeometry type is multipolygon\n269 features, 161 fields\nAssigned CRS is WGS 84, the ‘World Geodetic System 1984’. This is not right, and will be rectified in 3.2.3 Verifying + Transforming Coordinates"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#data-pre-processing",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#data-pre-processing",
    "title": "Take-Home Excercise 02",
    "section": "3.2 Data Pre-processing",
    "text": "3.2 Data Pre-processing\n\n3.2.1 Dropping Invalid Dimensions\nSince, we only have one dataframe, there are no invalid dimensions, and hence, this step is not required.\n\n\n3.2.2 Missing Values\nNow lets check if there are any missing values.\n\njakarta[rowSums(is.na(jakarta))!=0,]\n\nSimple feature collection with 2 features and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 106.8412 ymin: -6.154036 xmax: 106.8612 ymax: -6.144973\nGeodetic CRS:  WGS 84\n    OBJECT_ID KODE_DESA             DESA   KODE    PROVINSI KAB_KOTA KECAMATAN\n243     25645  31888888     DANAU SUNTER 318888 DKI JAKARTA     <NA>      <NA>\n244     25646  31888888 DANAU SUNTER DLL 318888 DKI JAKARTA     <NA>      <NA>\n    DESA_KELUR JUMLAH_PEN JUMLAH_KK LUAS_WILAY KEPADATAN PERPINDAHA JUMLAH_MEN\n243       <NA>          0         0          0         0          0          0\n244       <NA>          0         0          0         0          0          0\n    PERUBAHAN WAJIB_KTP SILAM KRISTEN KHATOLIK HINDU BUDHA KONGHUCU KEPERCAYAA\n243         0         0     0       0        0     0     0        0          0\n244         0         0     0       0        0     0     0        0          0\n    PRIA WANITA BELUM_KAWI KAWIN CERAI_HIDU CERAI_MATI U0 U5 U10 U15 U20 U25\n243    0      0          0     0          0          0  0  0   0   0   0   0\n244    0      0          0     0          0          0  0  0   0   0   0   0\n    U30 U35 U40 U45 U50 U55 U60 U65 U70 U75 TIDAK_BELU BELUM_TAMA TAMAT_SD SLTP\n243   0   0   0   0   0   0   0   0   0   0          0          0        0    0\n244   0   0   0   0   0   0   0   0   0   0          0          0        0    0\n    SLTA DIPLOMA_I DIPLOMA_II DIPLOMA_IV STRATA_II STRATA_III BELUM_TIDA\n243    0         0          0          0         0          0          0\n244    0         0          0          0         0          0          0\n    APARATUR_P TENAGA_PEN WIRASWASTA PERTANIAN NELAYAN AGAMA_DAN PELAJAR_MA\n243          0          0          0         0       0         0          0\n244          0          0          0         0       0         0          0\n    TENAGA_KES PENSIUNAN LAINNYA GENERATED KODE_DES_1 BELUM_ MENGUR_ PELAJAR_\n243          0         0       0      <NA>       <NA>      0       0        0\n244          0         0       0      <NA>       <NA>      0       0        0\n    PENSIUNA_1 PEGAWAI_ TENTARA KEPOLISIAN PERDAG_ PETANI PETERN_ NELAYAN_1\n243          0        0       0          0       0      0       0         0\n244          0        0       0          0       0      0       0         0\n    INDUSTR_ KONSTR_ TRANSP_ KARYAW_ KARYAW1 KARYAW1_1 KARYAW1_12 BURUH BURUH_\n243        0       0       0       0       0         0          0     0      0\n244        0       0       0       0       0         0          0     0      0\n    BURUH1 BURUH1_1 PEMBANT_ TUKANG TUKANG_1 TUKANG_12 TUKANG__13 TUKANG__14\n243      0        0        0      0        0         0          0          0\n244      0        0        0      0        0         0          0          0\n    TUKANG__15 TUKANG__16 TUKANG__17 PENATA PENATA_ PENATA1_1 MEKANIK SENIMAN_\n243          0          0          0      0       0         0       0        0\n244          0          0          0      0       0         0       0        0\n    TABIB PARAJI_ PERANCA_ PENTER_ IMAM_M PENDETA PASTOR WARTAWAN USTADZ JURU_M\n243     0       0        0       0      0       0      0        0      0      0\n244     0       0        0       0      0       0      0        0      0      0\n    PROMOT ANGGOTA_ ANGGOTA1 ANGGOTA1_1 PRESIDEN WAKIL_PRES ANGGOTA1_2\n243      0        0        0          0        0          0          0\n244      0        0        0          0        0          0          0\n    ANGGOTA1_3 DUTA_B GUBERNUR WAKIL_GUBE BUPATI WAKIL_BUPA WALIKOTA WAKIL_WALI\n243          0      0        0          0      0          0        0          0\n244          0      0        0          0      0          0        0          0\n    ANGGOTA1_4 ANGGOTA1_5 DOSEN GURU PILOT PENGACARA_ NOTARIS ARSITEK AKUNTA_\n243          0          0     0    0     0          0       0       0       0\n244          0          0     0    0     0          0       0       0       0\n    KONSUL_ DOKTER BIDAN PERAWAT APOTEK_ PSIKIATER PENYIA_ PENYIA1 PELAUT\n243       0      0     0       0       0         0       0       0      0\n244       0      0     0       0       0         0       0       0      0\n    PENELITI SOPIR PIALAN PARANORMAL PEDAGA_ PERANG_ KEPALA_ BIARAW_ WIRASWAST_\n243        0     0      0          0       0       0       0       0          0\n244        0     0      0          0       0       0       0       0          0\n    LAINNYA_12 LUAS_DESA KODE_DES_3 DESA_KEL_1 KODE_12\n243          0         0       <NA>       <NA>       0\n244          0         0       <NA>       <NA>       0\n                          geometry\n243 MULTIPOLYGON (((106.8612 -6...\n244 MULTIPOLYGON (((106.8504 -6...\n\n\nWe can see that there are 2 rows containing ‘NA’ values. However, since the data is big, we need to find the columns with missing NA values so that we can work on it.\n\nnames(which(colSums(is.na(jakarta))>0))\n\n[1] \"KAB_KOTA\"   \"KECAMATAN\"  \"DESA_KELUR\" \"GENERATED\"  \"KODE_DES_1\"\n[6] \"KODE_DES_3\" \"DESA_KEL_1\"\n\n\nWe can see that there are two particular rows with missing values for KAB_KOTA (City), KECAMATAN (District) and DESA_KELUR (Village).\nHence, we remove rows with NA value in DESA_KELUR. There are other columns with NA present as well, however, since we are only looking at the sub-district level, it is most appropriate to remove DESA_KELUR\n\njakarta <- na.omit(jakarta,c(\"DESA_KELUR\"))\n\nLets double check if the rows with missing values are removed.\n\njakarta[rowSums(is.na(jakarta))!=0,]\n\nSimple feature collection with 0 features and 161 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nGeodetic CRS:  WGS 84\n  [1] OBJECT_ID  KODE_DESA  DESA       KODE       PROVINSI   KAB_KOTA  \n  [7] KECAMATAN  DESA_KELUR JUMLAH_PEN JUMLAH_KK  LUAS_WILAY KEPADATAN \n [13] PERPINDAHA JUMLAH_MEN PERUBAHAN  WAJIB_KTP  SILAM      KRISTEN   \n [19] KHATOLIK   HINDU      BUDHA      KONGHUCU   KEPERCAYAA PRIA      \n [25] WANITA     BELUM_KAWI KAWIN      CERAI_HIDU CERAI_MATI U0        \n [31] U5         U10        U15        U20        U25        U30       \n [37] U35        U40        U45        U50        U55        U60       \n [43] U65        U70        U75        TIDAK_BELU BELUM_TAMA TAMAT_SD  \n [49] SLTP       SLTA       DIPLOMA_I  DIPLOMA_II DIPLOMA_IV STRATA_II \n [55] STRATA_III BELUM_TIDA APARATUR_P TENAGA_PEN WIRASWASTA PERTANIAN \n [61] NELAYAN    AGAMA_DAN  PELAJAR_MA TENAGA_KES PENSIUNAN  LAINNYA   \n [67] GENERATED  KODE_DES_1 BELUM_     MENGUR_    PELAJAR_   PENSIUNA_1\n [73] PEGAWAI_   TENTARA    KEPOLISIAN PERDAG_    PETANI     PETERN_   \n [79] NELAYAN_1  INDUSTR_   KONSTR_    TRANSP_    KARYAW_    KARYAW1   \n [85] KARYAW1_1  KARYAW1_12 BURUH      BURUH_     BURUH1     BURUH1_1  \n [91] PEMBANT_   TUKANG     TUKANG_1   TUKANG_12  TUKANG__13 TUKANG__14\n [97] TUKANG__15 TUKANG__16 TUKANG__17 PENATA     PENATA_    PENATA1_1 \n[103] MEKANIK    SENIMAN_   TABIB      PARAJI_    PERANCA_   PENTER_   \n[109] IMAM_M     PENDETA    PASTOR     WARTAWAN   USTADZ     JURU_M    \n[115] PROMOT     ANGGOTA_   ANGGOTA1   ANGGOTA1_1 PRESIDEN   WAKIL_PRES\n[121] ANGGOTA1_2 ANGGOTA1_3 DUTA_B     GUBERNUR   WAKIL_GUBE BUPATI    \n[127] WAKIL_BUPA WALIKOTA   WAKIL_WALI ANGGOTA1_4 ANGGOTA1_5 DOSEN     \n[133] GURU       PILOT      PENGACARA_ NOTARIS    ARSITEK    AKUNTA_   \n[139] KONSUL_    DOKTER     BIDAN      PERAWAT    APOTEK_    PSIKIATER \n[145] PENYIA_    PENYIA1    PELAUT     PENELITI   SOPIR      PIALAN    \n[151] PARANORMAL PEDAGA_    PERANG_    KEPALA_    BIARAW_    WIRASWAST_\n[157] LAINNYA_12 LUAS_DESA  KODE_DES_3 DESA_KEL_1 KODE_12    geometry  \n<0 rows> (or 0-length row.names)\n\n\n\n\n3.2.3 Verifying + Transforming Coordinates\nNow, we use the st_crs() to check the coordinate system of the data. As we can see, it uses the WGS 84 coordinate system. The data is using a Geographic projected system, however, this is system is not appropriate since we need to use distance and area measures.\n\nst_crs(jakarta)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nHence, we use st_transform() and not st_set_crs() as st_set_crs() assigns the EPSG code to the data frame. And we need to transform the data frame from geographic to projected coordinate system. We will be using crs=23845 (found from the EPSG for Indonesia).\n\njakarta <- st_transform(jakarta, 23845)\n\nLets double check if CRS has been assigned\n\nst_crs(jakarta)\n\nCoordinate Reference System:\n  User input: EPSG:23845 \n  wkt:\nPROJCRS[\"DGN95 / Indonesia TM-3 zone 54.1\",\n    BASEGEOGCRS[\"DGN95\",\n        DATUM[\"Datum Geodesi Nasional 1995\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4755]],\n    CONVERSION[\"Indonesia TM-3 zone 54.1\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",139.5,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9999,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",200000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",1500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"easting (X)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"northing (Y)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre.\"],\n        AREA[\"Indonesia - onshore east of 138°E.\"],\n        BBOX[-9.19,138,-1.49,141.01]],\n    ID[\"EPSG\",23845]]\n\n\n\n\n3.2.3 Removal of Outer Islands\nNow that we have done our basic pre-processing, lets quickly visualize the data\n\nplot(st_geometry(jakarta))\n\n\n\n\nAs we can see from the diagram, jakarta includes both mainland and outer islands. And since we don’t require the outer islands (as per the requirements), we can remove them.\nDIAGRAMM EXPLAINING THE DATAA\nWe know that the date is grouped by KAB_KOTA (City), KECAMATAN (Sub-District) and DESA_KELUR (Village). Now, lets plot the map and see how we can use KAB_KOTA to remove the outer islands.\n\ntm_shape(jakarta) + \n  tm_polygons(\"KAB_KOTA\")\n\n\n\n\nFrom the map, we can see that all the cities in Jakarta start with ‘Jakarta’ as their prefix and hence, ‘Kepulauan Seribu’ are the other outer islands. When translated in English, the name means ‘Thousand Islands’. Now we know what to remove, and we shall proceed with that.\n\njakarta <- filter(jakarta, KAB_KOTA != \"KEPULAUAN SERIBU\")\n\nNow, lets double check if the outer islands have been removed.\n\ntm_shape(jakarta) + \n  tm_polygons(\"KAB_KOTA\")\n\n\n\n\n\n\n3.2.4 Retaining first 9 fields of jakarta\nAdditionally, the assignment only requires us to retain the relevant fields - which are the first 9 fields.\n\njakarta <- jakarta[, 0:9]\n\n\n\n3.2.5 Renaming Columns with Translation\nSince the columns names are in Indonesian, lets rename them to English for better ease of use.\n\njakarta <- jakarta %>% \n  \n  dplyr::rename(\n    Object_ID=OBJECT_ID,\n    Village_Code=KODE_DESA, \n    Code=KODE,\n    Village=DESA,\n    Province=PROVINSI, \n    City=KAB_KOTA, \n    District=KECAMATAN, \n    Sub_District=DESA_KELUR,\n    Total_Population=JUMLAH_PEN\n    )"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#pre-importing-eda",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#pre-importing-eda",
    "title": "Take-Home Excercise 02",
    "section": "4.1 Pre-Importing EDA",
    "text": "4.1 Pre-Importing EDA\nFor this assignment, we will be working on data from July 2021 to June 2022, as a result we will be having several excel files. Thus, it is safer to preview the data first and check for any discrepancies, before compiling all the data.\n\njul2021 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Juli 2021).xlsx\")\nglimpse(jul2021)\n\nRows: 268\nColumns: 27\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 4441501, 12333, 13875, 18…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 4499710, 11614, 15506, 10…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 1663218, 4181, 4798, 3658…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 6162928, 15795, 20304, 14…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 502579, 1230, 2012, 865, …\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 440910, 1069, 1729, 701, …\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 943489, 2299, 3741, 1566,…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1052883, 3333, 2586, 2837…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 666009, 2158, 1374, 1761,…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 1718892, 5491, 3960, 4598…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 56660, 78, 122, 174, 71, …\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 38496, 51, 84, 106, 57, 7…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 95156, 129, 206, 280, 128…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 76397, 101, 90, 215, 73, …\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 67484, 91, 82, 192, 67, 3…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 143881, 192, 172, 407, 14…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 2279398, 5506, 9012, 5408…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 446028, 789, 1519, 897, 4…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 2725426, 6295, 10531, 630…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 531793, 1366, 1684, 1261,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 4291, 23, 10, 1, 1, 8, 6,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 536084, 1389, 1694, 1262,…\n\n\nThe above output shows that there are no duplicates. So we will check for all of them just to ensure that there are no duplicates and no inconsistencies\n\nAugust 2021\n\naug2021 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Agustus 2021).xlsx\")\nglimpse(aug2021)\n\nRows: 268\nColumns: 27\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 3277484, 9191, 10400, 125…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 5663727, 14756, 18981, 16…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 3412906, 8935, 10470, 776…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 9076633, 23691, 29451, 24…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 535001, 1300, 2104, 1043,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 468678, 1140, 1849, 780, …\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1003679, 2440, 3953, 1823…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1393352, 4194, 3643, 4293…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1007921, 3135, 2519, 2548…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 2401273, 7329, 6162, 6841…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 65340, 89, 137, 188, 80, …\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 53995, 77, 119, 163, 71, …\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 119335, 166, 256, 351, 15…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 79502, 106, 92, 229, 78, …\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 72588, 96, 83, 203, 74, 3…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 152090, 202, 175, 432, 15…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 2941837, 7385, 11033, 872…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 1377349, 3277, 4541, 3010…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 4319186, 10662, 15574, 11…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 648695, 1682, 1972, 2090,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 432375, 1210, 1359, 1062,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1081070, 2892, 3331, 3152…\n\n\nSeptember 2021\n\nsep2021 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (30 September 2021).xlsx\")\nglimpse(sep2021)\n\nRows: 268\nColumns: 27\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 2235772, 6688, 7581, 8708…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 6705439, 17259, 21800, 20…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 5171697, 13376, 16438, 14…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 11877136, 30635, 38238, 3…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 587215, 1417, 2270, 1263,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 518944, 1263, 2033, 988, …\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1106159, 2680, 4303, 2251…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1468382, 3938, 3883, 4540…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1305200, 3454, 3356, 3903…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 2773582, 7392, 7239, 8443…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 84049, 158, 173, 248, 100…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 75657, 148, 157, 229, 91,…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 159706, 306, 330, 477, 19…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 112296, 140, 135, 329, 11…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 104381, 124, 125, 300, 11…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 216677, 264, 260, 629, 23…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 3677943, 9564, 12969, 114…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 2548057, 6788, 8944, 7023…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 6226000, 16352, 21913, 18…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 775554, 2042, 2370, 2510,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 619458, 1599, 1823, 1969,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1395012, 3641, 4193, 4479…\n\n\nOctober 2021\n\noct2021 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Oktober 2021).xlsx\")\nglimpse(oct2021)\n\nRows: 268\nColumns: 27\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 1880524, 5991, 6557, 7586…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 7060687, 17956, 22824, 21…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 5729001, 14504, 18185, 16…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 12789688, 32460, 41009, 3…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 608940, 1447, 2336, 1322,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 543483, 1296, 2104, 1104,…\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1152423, 2743, 4440, 2426…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1484292, 3972, 3917, 4595…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1349105, 3555, 3465, 4072…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 2833397, 7527, 7382, 8667…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 86323, 165, 175, 259, 101…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 81721, 160, 168, 245, 96,…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 168044, 325, 343, 504, 19…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 113911, 140, 136, 338, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 107383, 128, 128, 310, 12…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 221294, 268, 264, 648, 24…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 3948804, 10101, 13744, 12…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 2949023, 7567, 10266, 849…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 6897827, 17668, 24010, 20…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 818417, 2131, 2516, 2672,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 698286, 1798, 2054, 2220,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1516703, 3929, 4570, 4892…\n\n\nNovember 2021\n\nnov2021 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (30 November 2021).xlsx\")\nglimpse(nov2021)\n\nRows: 268\nColumns: 27\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 1723821, 5527, 5986, 6802…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 7217390, 18420, 23395, 22…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 6172636, 15466, 19404, 18…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 13390026, 33886, 42799, 4…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 624751, 1473, 2391, 1385,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 571830, 1351, 2192, 1224,…\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1196581, 2824, 4583, 2609…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1487961, 3980, 3926, 4614…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1369705, 3601, 3516, 4146…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 2857666, 7581, 7442, 8760…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 86710, 169, 176, 259, 101…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 83506, 163, 172, 252, 98,…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 170216, 332, 348, 511, 19…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 114292, 140, 135, 341, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 109221, 128, 128, 323, 12…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 223513, 268, 263, 664, 24…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 4069550, 10473, 14182, 12…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 3304266, 8329, 11215, 978…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 7373816, 18802, 25397, 22…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 834126, 2185, 2585, 2733,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 734108, 1894, 2181, 2355,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1568234, 4079, 4766, 5088…\n\n\nDecember 2021\n\ndec2021 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Desember 2021).xlsx\")\nglimpse(dec2021)\n\nRows: 268\nColumns: 27\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 1623736, 5062, 5626, 6335…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 7317475, 18885, 23755, 22…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 6370175, 15996, 20026, 18…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 13687650, 34881, 43781, 4…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 634516, 1520, 2427, 1418,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 586624, 1375, 2247, 1294,…\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1221140, 2895, 4674, 2712…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1485857, 3981, 3922, 4603…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1372180, 3607, 3521, 4153…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 2858037, 7588, 7443, 8756…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 86905, 169, 176, 260, 101…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 83995, 164, 174, 253, 99,…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 170900, 333, 350, 513, 20…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 114612, 140, 136, 345, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 110119, 128, 129, 327, 12…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 224731, 268, 265, 672, 24…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 4150113, 10841, 14450, 13…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 3467714, 8782, 11715, 104…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 7617827, 19623, 26165, 23…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 845472, 2234, 2644, 2783,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 749543, 1940, 2240, 2401,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1595015, 4174, 4884, 5184…\n\n\nJanuary 2021\n\njan2022 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Januari 2022).xlsx\")\nglimpse(jan2022)\n\nRows: 268\nColumns: 27\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 1538221, 4647, 5388, 5967…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 7402990, 19300, 23993, 23…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 6516678, 16477, 20463, 19…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 13919668, 35777, 44456, 4…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 644280, 1564, 2459, 1446,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 598309, 1399, 2291, 1327,…\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1242589, 2963, 4750, 2773…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1478564, 3971, 3900, 4592…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1369268, 3604, 3506, 4158…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 2847832, 7575, 7406, 8750…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 88073, 177, 178, 262, 102…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 85942, 171, 179, 260, 99,…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 174015, 348, 357, 522, 20…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 115123, 140, 135, 348, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 111364, 130, 130, 331, 12…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 226487, 270, 265, 679, 24…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 4215232, 11158, 14620, 13…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 3579348, 9173, 12024, 109…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 7794580, 20331, 26644, 24…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 861718, 2290, 2701, 2840,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 772447, 2000, 2333, 2488,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1634165, 4290, 5034, 5328…\n\n\n\n\nFebruary 2022\n\nfeb2022 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (27 Februari 2022).xlsx\")\nglimpse(feb2022)\n\nRows: 268\nColumns: 27\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 1517196, 4592, 5319, 5903…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 7424015, 19355, 24062, 23…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 6590380, 16687, 20738, 19…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 14014395, 36042, 44800, 4…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 646481, 1567, 2465, 1451,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 604751, 1418, 2336, 1348,…\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1251232, 2985, 4801, 2799…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1478545, 3971, 3899, 4590…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1371190, 3614, 3512, 4161…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 2849735, 7585, 7411, 8751…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 88088, 178, 178, 262, 102…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 86046, 171, 179, 260, 99,…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 174134, 349, 357, 522, 20…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 115186, 140, 135, 348, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 111623, 130, 130, 331, 12…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 226809, 270, 265, 679, 24…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 4232389, 11200, 14670, 13…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 3638187, 9327, 12227, 111…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 7870576, 20527, 26897, 24…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 863326, 2299, 2715, 2845,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 778583, 2027, 2354, 2512,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1641909, 4326, 5069, 5357…\n\n\nMarch 2022\n\nmar2022 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Maret 2022).xlsx\")\nglimpse(mar2022)\n\nRows: 268\nColumns: 34\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 1482471, 4522, 5186, 5780…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 7458740, 19425, 24195, 23…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 6682911, 16909, 21000, 20…\n$ `JUMLAH\\r\\nDOSIS 3`                          <dbl> 1836511, 3934, 6122, 4124…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 15978162, 40268, 51317, 4…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 649601, 1574, 2475, 1457,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 610754, 1433, 2350, 1366,…\n$ `LANSIA\\r\\nDOSIS 3`                          <dbl> 610754, 1433, 2350, 1366,…\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1533150, 3545, 6052, 3283…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1481237, 3980, 3910, 4604…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1375686, 3634, 3523, 4175…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 3`                  <dbl> 200536, 579, 660, 453, 24…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 3057459, 8193, 8093, 9232…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 88150, 178, 178, 262, 102…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 86122, 173, 179, 260, 99,…\n$ `GOTONG ROYONG\\r\\nDOSIS 3`                   <dbl> 19460, 22, 53, 57, 19, 41…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 193732, 373, 410, 579, 22…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 115527, 140, 135, 348, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 112027, 130, 130, 331, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 3`                <dbl> 84640, 103, 94, 239, 83, …\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 312194, 373, 359, 918, 32…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 4258776, 11250, 14773, 13…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 3715052, 9502, 12436, 114…\n$ `TAHAPAN 3\\r\\nDOSIS 3`                       <dbl> 1248211, 2671, 4048, 2891…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 9222039, 23423, 31257, 28…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 865449, 2303, 2724, 2851,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 783270, 2037, 2382, 2541,…\n$ `REMAJA\\r\\nDOSIS 3`                          <dbl> 10869, 21, 40, 24, 7, 28,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1659588, 4361, 5146, 5416…\n\n\nApril 2022\n\napr2022 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (30 April 2022).xlsx\")\nglimpse(apr2022)\n\nRows: 268\nColumns: 34\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 1453423, 4449, 5101, 5699…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 7487788, 19498, 24280, 23…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 6727002, 17027, 21134, 20…\n$ `JUMLAH\\r\\nDOSIS 3`                          <dbl> 2720796, 6568, 8915, 6491…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 16935586, 43093, 54329, 5…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 651696, 1579, 2481, 1458,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 613044, 1441, 2360, 1376,…\n$ `LANSIA\\r\\nDOSIS 3`                          <dbl> 613044, 1441, 2360, 1376,…\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1599248, 3750, 6301, 3425…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1483630, 3983, 3920, 4611…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1378338, 3640, 3529, 4187…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 3`                  <dbl> 366145, 1099, 1096, 941, …\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 3228113, 8722, 8545, 9739…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 88200, 178, 178, 262, 102…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 86184, 173, 179, 260, 99,…\n$ `GOTONG ROYONG\\r\\nDOSIS 3`                   <dbl> 38179, 71, 95, 120, 41, 7…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 212563, 422, 452, 642, 24…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 115623, 140, 135, 348, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 112253, 130, 130, 333, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 3`                <dbl> 89811, 109, 105, 259, 91,…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 317687, 379, 370, 940, 33…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 4281576, 11308, 14842, 13…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 3750893, 9596, 12545, 116…\n$ `TAHAPAN 3\\r\\nDOSIS 3`                       <dbl> 1866526, 4503, 6084, 4519…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 9898995, 25407, 33471, 29…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 867063, 2310, 2724, 2858,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 786290, 2047, 2391, 2557,…\n$ `REMAJA\\r\\nDOSIS 3`                          <dbl> 25627, 56, 75, 61, 19, 71…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1678980, 4413, 5190, 5476…\n\n\nMay 2022\n\nmay2022 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Mei 2022).xlsx\")\nglimpse(may2022)\n\nRows: 268\nColumns: 34\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 1445540, 4440, 5084, 5676…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 7495671, 19507, 24297, 23…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 6743764, 17077, 21182, 20…\n$ `JUMLAH\\r\\nDOSIS 3`                          <dbl> 2885301, 7022, 9484, 7030…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 17124736, 43606, 54963, 5…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 652411, 1580, 2482, 1461,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 614259, 1442, 2367, 1378,…\n$ `LANSIA\\r\\nDOSIS 3`                          <dbl> 614259, 1442, 2367, 1378,…\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1615382, 3804, 6385, 3468…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1483896, 3982, 3920, 4612…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1379577, 3645, 3534, 4192…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 3`                  <dbl> 395504, 1185, 1185, 1033,…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 3258977, 8812, 8639, 9837…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 88234, 179, 178, 262, 102…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 86232, 173, 179, 260, 99,…\n$ `GOTONG ROYONG\\r\\nDOSIS 3`                   <dbl> 43402, 100, 111, 132, 53,…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 217868, 452, 468, 654, 25…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 115658, 140, 135, 348, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 112327, 130, 131, 333, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 3`                <dbl> 91061, 110, 108, 262, 93,…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 319046, 380, 374, 943, 33…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 4287820, 11318, 14850, 13…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 3763773, 9632, 12577, 116…\n$ `TAHAPAN 3\\r\\nDOSIS 3`                       <dbl> 1975879, 4777, 6455, 4893…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 10027472, 25727, 33882, 3…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 867652, 2308, 2732, 2858,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 787596, 2055, 2394, 2562,…\n$ `REMAJA\\r\\nDOSIS 3`                          <dbl> 30743, 68, 89, 81, 26, 80…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1685991, 4431, 5215, 5501…\n\n\nJune 2022\n\njun2022 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (30 Juni 2022).xlsx\")\nglimpse(jun2022)\n\nRows: 268\nColumns: 34\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 1431393, 4402, 5041, 5632…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 7509818, 19545, 24340, 23…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 6756584, 17106, 21213, 20…\n$ `JUMLAH\\r\\nDOSIS 3`                          <dbl> 3031594, 7369, 10086, 739…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 17297996, 44020, 55639, 5…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 653401, 1582, 2483, 1466,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 615341, 1447, 2368, 1382,…\n$ `LANSIA\\r\\nDOSIS 3`                          <dbl> 615341, 1447, 2368, 1382,…\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1630553, 3848, 6464, 3495…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1484892, 3982, 3924, 4613…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1380501, 3646, 3536, 4195…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 3`                  <dbl> 420795, 1244, 1265, 1104,…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 3286188, 8872, 8725, 9912…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 88277, 180, 178, 262, 102…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 86277, 174, 179, 260, 99,…\n$ `GOTONG ROYONG\\r\\nDOSIS 3`                   <dbl> 45143, 104, 115, 135, 56,…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 219697, 458, 472, 657, 25…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 115697, 140, 135, 348, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 112383, 130, 131, 333, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 3`                <dbl> 91999, 113, 108, 266, 95,…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 320079, 383, 374, 947, 33…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 4298906, 11352, 14884, 13…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 3773713, 9652, 12601, 116…\n$ `TAHAPAN 3\\r\\nDOSIS 3`                       <dbl> 2075349, 5009, 6872, 5151…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 10147968, 26013, 34357, 3…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 868645, 2309, 2736, 2862,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 788369, 2057, 2398, 2564,…\n$ `REMAJA\\r\\nDOSIS 3`                          <dbl> 36497, 80, 113, 95, 29, 1…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1693511, 4446, 5247, 5521…\n\n\n\nAs we can see, till February 2022, the number of columns is 27. However, from March 2022 the number of columns is 34. Upon researching about the difference between the number of columns, i realized that the data files from March 2022 has a separate column for Dosage 3, where has all the data files before March 2022 don’t have any dosage 3 column. This could attribute to the the fact that, dosage 3 vaccination was only provided from March 2022.\nHence, we will address this issue in the next section."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#creating-an-aspatial-data-pre-processing-function",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#creating-an-aspatial-data-pre-processing-function",
    "title": "Take-Home Excercise 02",
    "section": "4.2 Creating an Aspatial Data Pre-Processing Function",
    "text": "4.2 Creating an Aspatial Data Pre-Processing Function\nFor the assignment, we don’t require all the columns. Only the following columns are required -\n\nKODE KELURAHAN (Sub-District Code)\nKELURAHAN (Sub-District)\nSASARAN (Target)\nBELUM VASKIN (Yet to be vaccinated / Not yet vaccinated)\n\nThis solves the issue of some months having extra columns. However, we need to create an ‘Date’ column that shows the month and year of the observation, which is originally the file name. Each file has the naming convention ’Data Vaksinasi Berbasis Keluarahan (DD Month YYYY).\nWe will be combining the mentioned steps into a function\n\n# takes in an aspatial data filepath and returns a processed output\naspatial_preprocess <- function(filepath){\n  # We have to remove the first row of the file (subheader row) and hence, we use [-1,] to remove it.\n  result_file <- read_xlsx(filepath)[-1,]\n  \n  # We then create the Date Column, the format of our files is: Data Vaksinasi Berbasis Kelurahan (DD Month YYYY)\n  # While the start is technically \"(\", \"(\" is part of a regular expression and leads to a warning message, so we'll use \"Kelurahan\" instead. The [[1]] refers to the first element in the list.\n  # We're loading it as DD-Month-YYYY format\n  # We use the length of the filepath '6' to get the end index (which has our Date)\n  # as such, the most relevant functions are substr (returns a substring) and either str_locate (returns location of substring as an integer matrix) or gregexpr (returns a list of locations of substring)\n  # reference https://stackoverflow.com/questions/14249562/find-the-location-of-a-character-in-string\n  startpoint <- gregexpr(pattern=\"Kelurahan\", filepath)[[1]] + 11\n  \n  result_file$Date <- substr(filepath, startpoint, nchar(filepath)-6)\n  \n  # Retain the Relevant Columns\n  result_file <- result_file %>% \n    select(\"Date\", \n           \"KODE KELURAHAN\", \n           \"KELURAHAN\", \n           \"SASARAN\", \n           \"BELUM VAKSIN\")\n  return(result_file)\n}"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#feeding-files-into-the-aspatial_preprocess-function",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#feeding-files-into-the-aspatial_preprocess-function",
    "title": "Take-Home Excercise 02",
    "section": "4.3 Feeding files into the aspatial_preprocess function",
    "text": "4.3 Feeding files into the aspatial_preprocess function\nInstead of manually feeding the files, line by line, we will be using the function list.files() and lapply() to get our process done faster!\n\n# in the folder 'data/aspatial', find files with the extension '.xlsx' and add it to our fileslist \n# the full.names=TRUE prepends the directory path to the file names, giving a relative file path - otherwise, only the file names (not the paths) would be returned \n# reference: https://stat.ethz.ch/R-manual/R-devel/library/base/html/list.files.html\nfileslist <-list.files(path = \"data/aspatial\", pattern = \"*.xlsx\", full.names=TRUE)\n\n# afterwards, for every element in fileslist, apply aspatial_process function\ndflist <- lapply(seq_along(fileslist), function(x) aspatial_preprocess(fileslist[x]))\n\nWe will then convert the dflist into an actual dataframe with ldply() using the below code\n\nvaccination_jakarta <- ldply(dflist, data.frame)\n\nNow, lets take a look into our data\n\nglimpse(vaccination_jakarta)\n\nRows: 3,204\nColumns: 5\n$ Date           <chr> \"27 Februari 2022\", \"27 Februari 2022\", \"27 Februari 20…\n$ KODE.KELURAHAN <chr> \"3172051003\", \"3173041007\", \"3175041005\", \"3175031003\",…\n$ KELURAHAN      <chr> \"ANCOL\", \"ANGKE\", \"BALE KAMBANG\", \"BALI MESTER\", \"BAMBU…\n$ SASARAN        <dbl> 23947, 29381, 29074, 9752, 26285, 21566, 23886, 47898, …\n$ BELUM.VAKSIN   <dbl> 4592, 5319, 5903, 1649, 4030, 3950, 3344, 9382, 3772, 7…"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#formatting-date-column",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#formatting-date-column",
    "title": "Take-Home Excercise 02",
    "section": "4.4 Formatting Date Column",
    "text": "4.4 Formatting Date Column\nThe Dates are in Bahasa Indonesia, and hence, we need to translate them to English for ease of use. However, since the values in Date column were derived from sub-strings, they are in a string format and thus, first need to be converted to datetime.\n\n# parses the 'Date' column into Month(Full Name)-YYYY datetime objects\n# reference: https://stackoverflow.com/questions/53380650/b-y-date-conversion-gives-na\n\n# locale=\"ind\" means that the locale has been set as Indonesia\nSys.setlocale(locale=\"ind\")\n\n[1] \"LC_COLLATE=Indonesian_Indonesia.1252;LC_CTYPE=Indonesian_Indonesia.1252;LC_MONETARY=Indonesian_Indonesia.1252;LC_NUMERIC=C;LC_TIME=Indonesian_Indonesia.1252\"\n\n\n\nvaccination_jakarta$Date <- c(vaccination_jakarta$Date) %>% \n  as.Date(vaccination_jakarta$Date, format =\"%d %B %Y\")\n\nglimpse(vaccination_jakarta)\n\nRows: 3,204\nColumns: 5\n$ Date           <date> 2022-02-27, 2022-02-27, 2022-02-27, 2022-02-27, 2022-0~\n$ KODE.KELURAHAN <chr> \"3172051003\", \"3173041007\", \"3175041005\", \"3175031003\",~\n$ KELURAHAN      <chr> \"ANCOL\", \"ANGKE\", \"BALE KAMBANG\", \"BALI MESTER\", \"BAMBU~\n$ SASARAN        <dbl> 23947, 29381, 29074, 9752, 26285, 21566, 23886, 47898, ~\n$ BELUM.VAKSIN   <dbl> 4592, 5319, 5903, 1649, 4030, 3950, 3344, 9382, 3772, 7~"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#renaming-the-column-names-into-english",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#renaming-the-column-names-into-english",
    "title": "Take-Home Excercise 02",
    "section": "4.5 Renaming the Column names into English",
    "text": "4.5 Renaming the Column names into English\nWe can now rename the column names into English for ease of use\n\n# renames the columns in the style New_Name = OLD_NAME\nvaccination_jakarta <- vaccination_jakarta %>% \n  dplyr::rename(\n    Date=Date,\n    Sub_District_Code=KODE.KELURAHAN,\n    Sub_District=KELURAHAN, \n    Target=SASARAN, \n    Not_Yet_Vaccinated=BELUM.VAKSIN\n    )\n\n\nglimpse(vaccination_jakarta)\n\nRows: 3,204\nColumns: 5\n$ Date               <date> 2022-02-27, 2022-02-27, 2022-02-27, 2022-02-27, 20~\n$ Sub_District_Code  <chr> \"3172051003\", \"3173041007\", \"3175041005\", \"31750310~\n$ Sub_District       <chr> \"ANCOL\", \"ANGKE\", \"BALE KAMBANG\", \"BALI MESTER\", \"B~\n$ Target             <dbl> 23947, 29381, 29074, 9752, 26285, 21566, 23886, 478~\n$ Not_Yet_Vaccinated <dbl> 4592, 5319, 5903, 1649, 4030, 3950, 3344, 9382, 377~\n\n\nAs we can see, the columns have successfully been renamed in English."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#further-data-processing",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#further-data-processing",
    "title": "Take-Home Excercise 02",
    "section": "4.5 Further Data Processing",
    "text": "4.5 Further Data Processing\nNow that we have our Aspatial data into our desired dataframe, lets perform any pre-processing to check out for anything we might have missed.\n\nvaccination_jakarta[rowSums(is.na(vaccination_jakarta))!=0,]\n\n[1] Date               Sub_District_Code  Sub_District       Target            \n[5] Not_Yet_Vaccinated\n<0 rows> (or 0-length row.names)\n\n\nFrom the output, we can see there are no missing values."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#preliminary-joining-eda",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#preliminary-joining-eda",
    "title": "Take-Home Excercise 02",
    "section": "5.1 Preliminary joining + EDA",
    "text": "5.1 Preliminary joining + EDA\nNow that we have both our Geospatial and Aspatial data, we need to join them. However, we need to first find a common header to join them.\n\ncolnames(jakarta)\n\n [1] \"Object_ID\"        \"Village_Code\"     \"Village\"          \"Code\"            \n [5] \"Province\"         \"City\"             \"District\"         \"Sub_District\"    \n [9] \"Total_Population\" \"geometry\"        \n\n\n\ncolnames(vaccination_jakarta)\n\n[1] \"Date\"               \"Sub_District_Code\"  \"Sub_District\"      \n[4] \"Target\"             \"Not_Yet_Vaccinated\"\n\n\nWe can see that both the dataframes have Sub_District and hence we can join them by the Sub_District and Sub_District_Code (same as Village_Code in ‘jakarta’).\n\n# joins vaccination_jakarta to jakarta based on Sub_District and  Sub_District_Code\ncombined_jakarta <- left_join(jakarta, vaccination_jakarta,\n                              by=c(\n                                \"Village_Code\"=\"Sub_District_Code\", \n                                \"Sub_District\"=\"Sub_District\")\n                              )\n\nNow, lets take a look into the columns of combined_jakarta\n\ncolnames(combined_jakarta)\n\n [1] \"Object_ID\"          \"Village_Code\"       \"Village\"           \n [4] \"Code\"               \"Province\"           \"City\"              \n [7] \"District\"           \"Sub_District\"       \"Total_Population\"  \n[10] \"Date\"               \"Target\"             \"Not_Yet_Vaccinated\"\n[13] \"geometry\"          \n\n\nWe can then subcategorize the data into ‘Target population to be Vaccinated’ , ‘Not Yet Vaccinated Population’ and ‘Total Population’\n\ntarget = tm_shape(combined_jakarta)+\n  tm_fill(\"Target\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=\"Target Count\")\n\nnot_yet_vaccinated = tm_shape(combined_jakarta)+\n  tm_fill(\"Not_Yet_Vaccinated\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=\"Not Yet Vaccinated Count\")\n\ntotal_population = tm_shape(combined_jakarta)+\n  tm_fill(\"Total_Population\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=\"Total Population Count\")\n\ntmap_arrange(target, not_yet_vaccinated, total_population)\n\n\n\n\nWhat is interesting to note, is that there seems to be a ‘Missing’ value in the Target and Not_Yet_Vaccinated maps. Even though, when we had previously checked for missing values, it didn’t show any missing values. However, we shall double check again.\n\njakarta[rowSums(is.na(jakarta))!=0,]\n\nSimple feature collection with 0 features and 9 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: DGN95 / Indonesia TM-3 zone 54.1\n [1] Object_ID        Village_Code     Village          Code            \n [5] Province         City             District         Sub_District    \n [9] Total_Population geometry        \n<0 rows> (or 0-length row.names)\n\n\n\nvaccination_jakarta[rowSums(is.na(vaccination_jakarta))!=0,]\n\n[1] Date               Sub_District_Code  Sub_District       Target            \n[5] Not_Yet_Vaccinated\n<0 rows> (or 0-length row.names)\n\n\nAs seen, we don’t have any mission values in our dataframes. Hence, the most likely reasons for the missing values must be due to mismatched values when we combined (left-join) the Geospatial and Aspatial data."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#identifying-mismatched-sub-district-records",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#identifying-mismatched-sub-district-records",
    "title": "Take-Home Excercise 02",
    "section": "5.2 Identifying Mismatched Sub-District Records",
    "text": "5.2 Identifying Mismatched Sub-District Records\nSince, we had conducted left-join using the Sub-District, there must be a mismatch in the naming of the subdistricts. Lets check it by looking at the unique subdistrict names in both jakarta and vaccination_jakarta\n\n# checks for unique values of Sub_District in jakarta that aren't already present in vaccination_jakarta and vice versa\njakarta_subdistrict <- c(jakarta$Sub_District)\nvaccination_subdistrict <- c(vaccination_jakarta$Sub_District)\n\nunique(jakarta_subdistrict[!(jakarta_subdistrict %in% vaccination_subdistrict)])\n\n[1] \"KRENDANG\"             \"RAWAJATI\"             \"TENGAH\"              \n[4] \"BALEKAMBANG\"          \"PINANGRANTI\"          \"JATIPULO\"            \n[7] \"PALMERIAM\"            \"KRAMATJATI\"           \"HALIM PERDANA KUSUMA\"\n\n\n\nunique(vaccination_subdistrict[!(vaccination_subdistrict %in% jakarta_subdistrict)])\n\n [1] \"BALE KAMBANG\"          \"HALIM PERDANA KUSUMAH\" \"JATI PULO\"            \n [4] \"KAMPUNG TENGAH\"        \"KERENDANG\"             \"KRAMAT JATI\"          \n [7] \"PAL MERIAM\"            \"PINANG RANTI\"          \"PULAU HARAPAN\"        \n[10] \"PULAU KELAPA\"          \"PULAU PANGGANG\"        \"PULAU PARI\"           \n[13] \"PULAU TIDUNG\"          \"PULAU UNTUNG JAWA\"     \"RAWA JATI\"            \n\n\nWe can see that there are same names in both the list but are just written in different ways. However, there are 6 words in the vaccination_subdistrict which are not in the jakarta_subdistrict. We shall take a look into that after we first correct the mismatched values.\nNow, lets view the differences –\n\n# initialise a dataframe of our cases vs bd subdistrict spelling\nspelling <- data.frame(\n  Aspatial_Cases=c(\"BALE KAMBANG\", \"HALIM PERDANA KUSUMAH\", \"JATI PULO\", \"KAMPUNG TENGAH\", \"KERENDANG\", \"KRAMAT JATI\", \"PAL MERIAM\", \"PINANG RANTI\", \"RAWA JATI\"),\n  Geospatial_BD=c(\"BALEKAMBAG\", \"HALIM PERDANA KUSUMA\", \"JATIPULO\", \"TENGAH\", \"KRENDANG\", \"KRAMATJATI\", \"PALMERIAM\", \"PINANGRANTI\", \"RAWAJATI\")\n  )\n\n# with dataframe a input, outputs a kable\nlibrary(knitr)\nlibrary(kableExtra)\nkable(spelling, caption=\"Mismatched Records\") %>%\n  kable_material(\"hover\", latex_options=\"scale_down\")\n\n\n\nMismatched Records\n \n  \n    Aspatial_Cases \n    Geospatial_BD \n  \n \n\n  \n    BALE KAMBANG \n    BALEKAMBAG \n  \n  \n    HALIM PERDANA KUSUMAH \n    HALIM PERDANA KUSUMA \n  \n  \n    JATI PULO \n    JATIPULO \n  \n  \n    KAMPUNG TENGAH \n    TENGAH \n  \n  \n    KERENDANG \n    KRENDANG \n  \n  \n    KRAMAT JATI \n    KRAMATJATI \n  \n  \n    PAL MERIAM \n    PALMERIAM \n  \n  \n    PINANG RANTI \n    PINANGRANTI \n  \n  \n    RAWA JATI \n    RAWAJATI \n  \n\n\n\n\n\nAs we can see these records have the same name, except that there is not standardization on how it is to be written. As a result, there is a mismatch between them. So now, lets correct this mismatch\n\n# We are replacing the mistmatched values in jakarta with the correct value\njakarta$Sub_District[jakarta$Sub_District == 'BALEKAMBANG'] <- 'BALE KAMBANG'\njakarta$Sub_District[jakarta$Sub_District == 'HALIM PERDANA KUSUMA'] <- 'HALIM PERDANA KUSUMAH'\njakarta$Sub_District[jakarta$Sub_District == 'JATIPULO'] <- 'JATI PULO'\njakarta$Sub_District[jakarta$Sub_District == 'KALI BARU'] <- 'KALIBARU'\njakarta$Sub_District[jakarta$Sub_District == 'TENGAH'] <- 'KAMPUNG TENGAH'\njakarta$Sub_District[jakarta$Sub_District == 'KRAMATJATI'] <- 'KRAMAT JATI'\njakarta$Sub_District[jakarta$Sub_District == 'KRENDANG'] <- 'KERENDANG'\njakarta$Sub_District[jakarta$Sub_District == 'PALMERIAM'] <- 'PAL MERIAM'\njakarta$Sub_District[jakarta$Sub_District == 'PINANGRANTI'] <- 'PINANG RANTI'\njakarta$Sub_District[jakarta$Sub_District == 'RAWAJATI'] <- 'RAWA JATI'\n\nNow, lets look into the 6 subdistrict names that we say in vaccination_jakarta which were not present in jakarta. This ideally suggests that these districts are not a part of Jakarta, however, we need to double check it just to be sure.\n\n\n\nUnique Subdistricts\n\n\n\n\n\nSubdistricts in Jakarta\n\n\nThis can be verified by taking a look at our excel file. The 2nd screenshot shows the subdistricts in Jakarta as they have the name Jakarta in ‘WILAYAH KOTA’ which means City Area. However, as seen in the 1st screenshot, these 6 subdistricts do not have the name Jakarta in ‘WILAYAH KOTA’ confirming the fact that they are not a part of Jakarta. Hence, we need to remove them.\n\nvaccination_jakarta <- vaccination_jakarta[!(vaccination_jakarta$Sub_District==\"PULAU HARAPAN\" | vaccination_jakarta$Sub_District==\"PULAU KELAPA\" | vaccination_jakarta$Sub_District==\"PULAU PANGGANG\" | vaccination_jakarta$Sub_District==\"PULAU PARI\" | vaccination_jakarta$Sub_District==\"PULAU TIDUNG\" | vaccination_jakarta$Sub_District==\"PULAU UNTUNG JAWA\"), ]"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#rejoining-eda",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#rejoining-eda",
    "title": "Take-Home Excercise 02",
    "section": "5.3 Rejoining + EDA",
    "text": "5.3 Rejoining + EDA\nNow, that we have a more standardized common identifier and have removed all the unnecessary values from our data, we can join them again once more!\n\n# joins vaccination_jakarta to jakarta based on Sub_District and  Sub_District_Code\ncombined_jakarta <- left_join(jakarta, vaccination_jakarta,\n                              by=c(\n                                \"Village_Code\"=\"Sub_District_Code\", \n                                \"Sub_District\"=\"Sub_District\")\n                              )\n\nLet’s check if there are any NA values now\n\ncombined_jakarta[rowSums(is.na(combined_jakarta))!=0,]\n\nSimple feature collection with 0 features and 12 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: DGN95 / Indonesia TM-3 zone 54.1\n [1] Object_ID          Village_Code       Village            Code              \n [5] Province           City               District           Sub_District      \n [9] Total_Population   Date               Target             Not_Yet_Vaccinated\n[13] geometry          \n<0 rows> (or 0-length row.names)\n\n\nLet’s re-visualize the data into ‘Target population to be Vaccinated’ , ‘Not Yet Vaccinated Population’ and ‘Total Population’\n\ntarget = tm_shape(combined_jakarta)+\n  tm_fill(\"Target\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=\"Target Count\")\n\nnot_yet_vaccinated = tm_shape(combined_jakarta)+\n  tm_fill(\"Not_Yet_Vaccinated\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=\"Not Yet Vaccinated Count\")\n\ntotal_population = tm_shape(combined_jakarta)+\n  tm_fill(\"Total_Population\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=\"Total Population Count\")\n\ntmap_arrange(target, not_yet_vaccinated, total_population)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#section-1",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#section-1",
    "title": "Take-Home Excercise 02",
    "section": "",
    "text": "6.1 Converting dataframs to sf objects\nBefore we move on into the mapping, we need to convert the dataframes into sf objects. We will convert combined_jakarta and vaccination_rate which will be using for our analysis.\n\ncombined_jakarta <- st_as_sf(combined_jakarta)\n\n# need to join our previous dataframes with the geospatial data to ensure that geometry column is present\nvaccination_rate <- vaccination_rate%>% left_join(jakarta, by=c(\"Sub_District\"=\"Sub_District\"))\nvaccination_rate <- st_as_sf(vaccination_rate)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#jenks-choropleth-maps",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#jenks-choropleth-maps",
    "title": "Take-Home Excercise 02",
    "section": "7.1.1 Jenks Choropleth Maps",
    "text": "7.1.1 Jenks Choropleth Maps\nAfter testing, I have decided to stick to 6 classes, as too many classes makes it hard for the human eye to differentiate between the gradients, while too few makes it hard for any differentiation to be seen. Hence, 6 classes is the optimum number of classes.\n\n# using the jenks method, with 6 classes\ntmap_mode(\"plot\")\ntm_shape(vaccination_rate)+\n  tm_fill(\"2021-07-31\", \n          n= 6,\n          style = \"jenks\", \n          title = \"Vaccination Rate\") +\n  tm_layout(main.title = \"Distribution of Vaccination Rate in July 2021\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.5, \n            legend.width = 0.4,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nWe have to plot it for all the months, hence, let’s have a function to help us do it!\n\n# input: the dataframe and the variable name - in this case, the month \n# with style=\"jenks\" for the jenks classification method\njenks_plot <- function(df, varname) {\n  tm_shape(vaccination_rate) +\n    tm_polygons() +\n  tm_shape(df) +\n    tm_fill(varname, \n          n= 6,\n          style = \"jenks\", \n          title = \"Vaccination Rate\") +\n    tm_layout(main.title = varname,\n          main.title.position = \"center\",\n          main.title.size = 1.2,\n          legend.height = 0.45, \n          legend.width = 0.35,\n          frame = TRUE) +\n    tm_borders(alpha = 0.5)\n}\n\n\ntmap_mode(\"plot\")\ntmap_arrange(jenks_plot(vaccination_rate, \"2021-07-31\"),\n             jenks_plot(vaccination_rate, \"2021-08-31\"),\n             jenks_plot(vaccination_rate, \"2021-09-30\"),\n             jenks_plot(vaccination_rate, \"2021-10-31\"))\n\n\n\n\n\ntmap_mode(\"plot\")\ntmap_arrange(jenks_plot(vaccination_rate, \"2021-11-30\"),\n             jenks_plot(vaccination_rate, \"2021-12-31\"),\n             jenks_plot(vaccination_rate, \"2022-01-31\"),\n             jenks_plot(vaccination_rate, \"2022-02-27\"))\n\n\n\n\n\ntmap_mode(\"plot\")\ntmap_arrange(jenks_plot(vaccination_rate, \"2022-03-31\"),\n             jenks_plot(vaccination_rate, \"2022-04-30\"),\n             jenks_plot(vaccination_rate, \"2022-05-31\"),\n             jenks_plot(vaccination_rate, \"2022-06-30\"))\n\n\n\n\nPlotting all 12 maps together\n\ntmap_mode(\"plot\")\ntmap_arrange(jenks_plot(vaccination_rate, \"2021-07-31\"),\n             jenks_plot(vaccination_rate, \"2021-08-31\"),\n             jenks_plot(vaccination_rate, \"2021-09-30\"),\n             jenks_plot(vaccination_rate, \"2021-10-31\"),\n             jenks_plot(vaccination_rate, \"2021-11-30\"),\n             jenks_plot(vaccination_rate, \"2021-12-31\"),\n             jenks_plot(vaccination_rate, \"2022-01-31\"),\n             jenks_plot(vaccination_rate, \"2022-02-27\"),\n             jenks_plot(vaccination_rate, \"2022-03-31\"),\n             jenks_plot(vaccination_rate, \"2022-04-30\"),\n             jenks_plot(vaccination_rate, \"2022-05-31\"),\n             jenks_plot(vaccination_rate, \"2022-06-30\")\n             )"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#section-2",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#section-2",
    "title": "Take-Home Excercise 02",
    "section": "",
    "text": "7.1.2 Observations from Jenks Choropleth maps\nThe Vaccination Rate values (scale) are different for each month, hence it is hard for us to compare each month based on the ranging colour. But we do see that the vaccination rates increase over the months, with the minimum vaccination rate increasing every month.\nHowever, we can notice the following things for sub-districts regarding high vacciniation rate :\n\nThe highest vaccination rate from the periods of 31/07/2021 to 31/08/2021 seems to be more concentrated towards the North of Jakarta.\nFrom the period of 30/09/2021 to 31/10/2021, the high vaccination rates seems to be more spread out throughout Jakarta\nThe high vaccination rates seem to be more concentrated towards the South and South-East of Jakarta from the period of 30/11/2021.\n\nWe can notice the following things for sub-districts regarding low vaccination rate :\n\nThe map of 31/08/2021 shows more sub-districts with a lighter colour (indicating) more sub-districts had a low vaccination rate\nHowever, it looks like most of the sub-districts caught up the following month (30/09/2021) with a more uniform colour (i.e. fewer sub-districts with light colours)\nFrom the period 31/01/2022, there were more sub-districts with lower vaccination rate (lighter colour). Especially the majority of sub-districts in the North and West seems to have a low vaccination rate in comparison to others. This is most apparent in 30/06/2022 where most sub-districts in the North and West have a lower vaccination rate (except for a few sub-districts in the North with a relatively higher vaccination rate). Further, some of the sub-districts in the Central seem to have the lowest vaccination rate consistently from as seen from the maps from 27/02/2022 onwards.\n\nLets check for the sub-districts with the highest cases rate at the various stages -\n\n#highest vaccination rate for each month\nvaccination_rate$Sub_District[which.max(vaccination_rate$`2021-07-31`)]\n\n[1] \"KAMAL MUARA\"\n\n\n\nvaccination_rate$Sub_District[which.max(vaccination_rate$`2021-08-31`)]\n\n[1] \"KAMAL MUARA\"\n\n\n\nvaccination_rate$Sub_District[which.max(vaccination_rate$`2021-09-30`)]\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\n\nvaccination_rate$Sub_District[which.max(vaccination_rate$`2021-10-31`)]\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\n\nvaccination_rate$Sub_District[which.max(vaccination_rate$`2021-11-30`)]\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\n\nvaccination_rate$Sub_District[which.max(vaccination_rate$`2021-12-31`)]\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\n\nvaccination_rate$Sub_District[which.max(vaccination_rate$`2022-01-31`)]\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\n\nvaccination_rate$Sub_District[which.max(vaccination_rate$`2022-02-27`)]\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\n\nvaccination_rate$Sub_District[which.max(vaccination_rate$`2022-03-31`)]\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\n\nvaccination_rate$Sub_District[which.max(vaccination_rate$`2022-04-30`)]\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\n\nvaccination_rate$Sub_District[which.max(vaccination_rate$`2022-05-31`)]\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\n\nvaccination_rate$Sub_District[which.max(vaccination_rate$`2022-06-30`)]\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\nAs we can see, the first 2 months (July 2022 to August 2021), the sub-district with the highest vaccination rate is Kamal Maura, which is located in North Jakarta. However, following that, the highest vaccination rate is continuously in Halim Perdana Kusumah, which is in East Jakarta. Thus verifying our observations mentioned above.\nNow lets check the sub-districts with the lowest vaccination rate\n\n#lowest vaccination rate for each month\nvaccination_rate$Sub_District[which.min(vaccination_rate$`2021-07-31`)]\n\n[1] \"BALE KAMBANG\"\n\n\n\nvaccination_rate$Sub_District[which.min(vaccination_rate$`2021-08-31`)]\n\n[1] \"PETAMBURAN\"\n\n\n\nvaccination_rate$Sub_District[which.min(vaccination_rate$`2021-09-30`)]\n\n[1] \"KALIBARU\"\n\n\n\nvaccination_rate$Sub_District[which.min(vaccination_rate$`2021-10-31`)]\n\n[1] \"KALIBARU\"\n\n\n\nvaccination_rate$Sub_District[which.min(vaccination_rate$`2021-11-30`)]\n\n[1] \"KALIBARU\"\n\n\n\nvaccination_rate$Sub_District[which.min(vaccination_rate$`2021-12-31`)]\n\n[1] \"KEBON MELATI\"\n\n\n\nvaccination_rate$Sub_District[which.min(vaccination_rate$`2022-01-31`)]\n\n[1] \"KALIBARU\"\n\n\n\nvaccination_rate$Sub_District[which.min(vaccination_rate$`2022-02-27`)]\n\n[1] \"KEBON MELATI\"\n\n\n\nvaccination_rate$Sub_District[which.min(vaccination_rate$`2022-03-31`)]\n\n[1] \"KEBON MELATI\"\n\n\n\nvaccination_rate$Sub_District[which.min(vaccination_rate$`2022-04-30`)]\n\n[1] \"KEBON MELATI\"\n\n\n\nvaccination_rate$Sub_District[which.min(vaccination_rate$`2022-05-31`)]\n\n[1] \"KEBON MELATI\"\n\n\n\nvaccination_rate$Sub_District[which.min(vaccination_rate$`2022-06-30`)]\n\n[1] \"KEBON MELATI\"\n\n\nThe first month in our anlaysis has Bale Kambang has the sub-district with the lowest vaccination rate which is in the East district. However, in the next month (31/08/2021), it is Petamburan (Center District) with the lowest vaccination rate. It is then followed by Kali Baru in the North District from 30/09/2021 to 31/01/2022 with an exception of 31/12/2021. However, from the map of 27/02/2022 onward, Kebon Melati (in the Central District) has the lowest vaccination rates. This verifies what we analysed previously from viewing the thematic maps."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#spatio-temporal-mapping-with-custom-breakpoints",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#spatio-temporal-mapping-with-custom-breakpoints",
    "title": "Take-Home Excercise 02",
    "section": "7.2.1 Spatio-Temporal Mapping With Custom Breakpoints",
    "text": "7.2.1 Spatio-Temporal Mapping With Custom Breakpoints\nIn the above section, we see that each month has its own vaccination rate range, but in order to see the spatio-temporal progression of vaccination rates, we need to set a fixed range. Hence, we need to customise our breakpoints into 6 breakpoints (just like we did above into 6 classes)\nFor that, we need to find the highest and lowest vaccination rate. The highest vaccination rate will come from the latest month - June 2022. Whereas, the lowest vaccination rate will come from the first month - July 2021.\n\nmax(vaccination_rate$`2022-06-30`)\n\n[1] 89.77894\n\n\n\nmin(vaccination_rate$`2021-07-31`)\n\n[1] 37.00901\n\n\n\nsummary(vaccination_rate)\n\n Sub_District         2021-07-31      2021-08-31      2021-09-30   \n Length:261         Min.   :37.01   Min.   :54.56   Min.   :66.97  \n Class :character   1st Qu.:47.59   1st Qu.:61.94   1st Qu.:73.74  \n Mode  :character   Median :51.34   Median :63.50   Median :75.46  \n                    Mean   :51.07   Mean   :63.64   Mean   :75.34  \n                    3rd Qu.:54.19   3rd Qu.:65.40   3rd Qu.:76.88  \n                    Max.   :65.20   Max.   :72.99   Max.   :83.70  \n   2021-10-31      2021-11-30      2021-12-31      2022-01-31   \n Min.   :71.76   Min.   :73.85   Min.   :75.65   Min.   :76.80  \n 1st Qu.:77.98   1st Qu.:79.80   1st Qu.:80.97   1st Qu.:81.90  \n Median :79.37   Median :81.14   Median :82.08   Median :82.96  \n Mean   :79.25   Mean   :80.94   Mean   :82.01   Mean   :82.94  \n 3rd Qu.:80.77   3rd Qu.:82.32   3rd Qu.:83.20   3rd Qu.:83.94  \n Max.   :86.60   Max.   :87.50   Max.   :88.34   Max.   :89.03  \n   2022-02-27      2022-03-31      2022-04-30      2022-05-31   \n Min.   :77.23   Min.   :77.66   Min.   :78.01   Min.   :78.13  \n 1st Qu.:82.18   1st Qu.:82.60   1st Qu.:82.95   1st Qu.:83.03  \n Median :83.17   Median :83.54   Median :83.80   Median :83.85  \n Mean   :83.16   Mean   :83.53   Mean   :83.84   Mean   :83.93  \n 3rd Qu.:84.15   3rd Qu.:84.53   3rd Qu.:84.89   3rd Qu.:84.95  \n Max.   :89.19   Max.   :89.46   Max.   :89.69   Max.   :89.76  \n   2022-06-30      Object_ID     Village_Code         Village         \n Min.   :78.31   Min.   :25384   Length:261         Length:261        \n 1st Qu.:83.18   1st Qu.:25449   Class :character   Class :character  \n Median :84.03   Median :25514   Mode  :character   Mode  :character  \n Mean   :84.08   Mean   :25514                                        \n 3rd Qu.:85.05   3rd Qu.:25579                                        \n Max.   :89.78   Max.   :25644                                        \n      Code          Province             City             District        \n Min.   :317101   Length:261         Length:261         Length:261        \n 1st Qu.:317204   Class :character   Class :character   Class :character  \n Median :317308   Mode  :character   Mode  :character   Mode  :character  \n Mean   :317334                                                           \n 3rd Qu.:317410                                                           \n Max.   :317510                                                           \n Total_Population          geometry  \n Min.   :  3088   MULTIPOLYGON :261  \n 1st Qu.: 26177   epsg:23845   :  0  \n Median : 38845   +proj=tmer...:  0  \n Mean   : 42082                      \n 3rd Qu.: 52424                      \n Max.   :167523                      \n\n\nOur range for the breakpoints is 37 to 90. After experimenting with the breakpoints, I have chosen the following breakpoints as they provide a proper categorization such that we can differentiate sub-districts with lower vaccination rate from those with higher vaccination rate (i.e. not making majority of sub-districts) in the same colour.\n\nbreakpoints = c(37, 55, 72, 80, 84, 90)\n\nNow lets create a function to help us plot for 12 months\n\nbreak_plot <- function(df, varname) {\n  tm_shape(vaccination_rate) +\n    tm_polygons() +\n  tm_shape(df) +\n    tm_fill(varname, \n          breaks= breakpoints,\n          title = \"Vaccination Rate\") +\n    tm_layout(main.title = varname,\n          main.title.position = \"center\",\n          main.title.size = 1.2,\n          legend.height = 0.45, \n          legend.width = 0.35,\n          frame = TRUE) +\n    tm_borders(alpha = 0.5)\n}\n\n\ntmap_mode(\"plot\")\ntmap_arrange(break_plot(vaccination_rate, \"2021-07-31\"),\n             break_plot(vaccination_rate, \"2021-08-31\"),\n             break_plot(vaccination_rate, \"2021-09-30\"),\n             break_plot(vaccination_rate, \"2021-10-31\"))\n\n\n\n\n\ntmap_mode(\"plot\")\ntmap_arrange(break_plot(vaccination_rate, \"2021-11-30\"),\n             break_plot(vaccination_rate, \"2021-12-31\"),\n             break_plot(vaccination_rate, \"2022-01-31\"),\n             break_plot(vaccination_rate, \"2022-02-27\"))\n\n\n\n\n\ntmap_mode(\"plot\")\ntmap_arrange(break_plot(vaccination_rate, \"2022-03-31\"),\n             break_plot(vaccination_rate, \"2022-04-30\"),\n             break_plot(vaccination_rate, \"2022-05-31\"),\n             break_plot(vaccination_rate, \"2022-06-30\"))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#observations-from-spatio-temporal-map",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#observations-from-spatio-temporal-map",
    "title": "Take-Home Excercise 02",
    "section": "7.2.2 Observations from Spatio-Temporal Map",
    "text": "7.2.2 Observations from Spatio-Temporal Map\n\n\n\nVaccination Rate gif created using https://imgflip.com/gif-maker\n\n\nNow, we can supplement our our observations made in 6.1.2 Observations from Jenks Choropleth maps. Here are the observations -\n\nIn July 2021, we can see a slightly higher vaccination rate in the North and Central districts\nIn the month August and September 2021, there seems to be a more uniform distribution of vaccination rate (almost same colour range throughout Jakarta)\nHowever, from December 2021, some sub-districts have a consistent/increasing high vaccination rate. This seems to be most evident in the sub-districts in the South and East district (with most of them having high Vaccination Rate). But we can also see an increasing vaccination rate in many sub-districts in the North and Central Jakarta."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#observations-from-jenks-choropleth-maps",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#observations-from-jenks-choropleth-maps",
    "title": "Take-Home Excercise 02",
    "section": "7.1.2 Observations from Jenks Choropleth maps",
    "text": "7.1.2 Observations from Jenks Choropleth maps\nWe can notice the following things for sub-districts regarding high vaccination rate (sub-district in darker colour) :\n\nThe highest vaccination rate from the periods of 31/07/2021 to 31/08/2021 seems to be more concentrated towards the North of Jakarta.\nFrom the period of 30/09/2021 to 30/11/2021, the high vaccination rates are more spread out throughout Jakarta\nThe high vaccination rates seem to be more concentrated towards the South and East of Jakarta from the period of 31/12/2021.\n\nWe can notice the following things for sub-districts regarding low vaccination rate (sub-district in lighter colour) :\n\nThe map of 31/08/2021 shows more sub-districts with a lighter colour (indicating) low vaccination rate\nHowever, it looks like most of the sub-district caught up the following month (30/09/2021) with a more uniform colour (i.e. fewer sub-districts with light colours)\nFrom the period 31/01/2022, there were more sub-districts with lower vaccination rate (lighter colour). Especially sub-districts in the North and West (except for a few sub-districts in the North with a relatively higher vaccination rate). Further, some of the sub-districts in the Central seem to have the lowest vaccination rate consistently from as seen from the maps from 27/02/2022 onward."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-local-gi-values-of-monthly-vaccination-rate",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-local-gi-values-of-monthly-vaccination-rate",
    "title": "Take-Home Excercise 02",
    "section": "8.1 Computing Local Gi* Values of Monthly Vaccination Rate",
    "text": "8.1 Computing Local Gi* Values of Monthly Vaccination Rate\n8.1.1 Create an Attribute Table\nBefore we create a time series cube, we need to first have an attribute table with the relevant data - Date, Sub_District and Vaccination Rate.\n\n# Make new vaccination attribute table with Date, Sub_District, Target, Not_Yet_Vaccinated\nvacc_attr_table <- combined_jakarta %>% select(10, 8, 11, 12) %>% st_drop_geometry()\n\n# Adding a new field for Vaccination_Rate\nvacc_attr_table$Vaccination_Rate <- ((vacc_attr_table$Target - vacc_attr_table$Not_Yet_Vaccinated) / vacc_attr_table$Target) *100\n\n# Vaccination attribute table with just Date, Sub_District, Vaccination_Rate\nvacc_attr_table <- tibble(vacc_attr_table %>% select(1,2,5))\n\nNow, lets look into the attribute table we created and make sure everything is correct\n\nvacc_attr_table\n\n# A tibble: 3,132 x 3\n   Date       Sub_District Vaccination_Rate\n   <date>     <chr>                   <dbl>\n 1 2022-02-27 KEAGUNGAN                84.2\n 2 2022-04-30 KEAGUNGAN                85.1\n 3 2022-06-30 KEAGUNGAN                85.3\n 4 2021-11-30 KEAGUNGAN                82.2\n 5 2021-09-30 KEAGUNGAN                75.8\n 6 2021-08-31 KEAGUNGAN                65.2\n 7 2021-12-31 KEAGUNGAN                83.2\n 8 2022-01-31 KEAGUNGAN                84.0\n 9 2021-07-31 KEAGUNGAN                53.3\n10 2022-03-31 KEAGUNGAN                84.6\n# ... with 3,122 more rows\n\n\n\n8.1.2 Create a Spatio-Temporal Cube\nNow we use spacetime() to create an spatio-temporal cube\n\nvacc_rate_st <- spacetime(vacc_attr_table, jakarta,\n                          .loc_col = \"Sub_District\",\n                          .time_col = \"Date\")\n\nNext we need to verify if vacc_rate_st is indeed a space-time cube by using the is_spacetime_cube() of sfdep package\n\nis_spacetime_cube(vacc_rate_st)\n\n[1] TRUE\n\n\nThe TRUE return confirms that vacc_rate_st object is indeed an time-space cube.\n\n\n8.1.3 Derive Spatial Weights\nNext, we will compute the local Gi* weights, but before that we need derive the spatial weights. The below code chunk is used to identify neighbors and derive an inverse distance weights.\n\nvacc_rate_nb <- vacc_rate_st %>%\n  activate(\"geometry\") %>%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale=1,\n                                  alpha=1),\n         .before=1) %>%\n  set_nbs(\"nb\") %>%\n  set_wts(\"wt\")\n\nNote -\n\nactivate() is used to activate the geometry context\nmutate() is used to create two new columns nb and wt.\nThen we will activate the data context again and copy over the nb and wt columns to each time-slice using set_nbs() and set_wts()\n\nrow order is very important so do not rearrange the observations after using set_nbs() or set_wts().\n\n\nAs a result, this dataset has neighbors and weights for each time-slice\n\nhead(vacc_rate_nb)\n\n# A tibble: 6 x 5\n  Date       Sub_District  Vaccination_Rate nb        wt       \n  <date>     <chr>                    <dbl> <list>    <list>   \n1 2021-07-31 KEAGUNGAN                 53.3 <int [6]> <dbl [6]>\n2 2021-07-31 GLODOK                    61.6 <int [7]> <dbl [7]>\n3 2021-07-31 HARAPAN MULIA             49.7 <int [6]> <dbl [6]>\n4 2021-07-31 CEMPAKA BARU              46.7 <int [7]> <dbl [7]>\n5 2021-07-31 PASAR BARU                59.3 <int [9]> <dbl [9]>\n6 2021-07-31 KARANG ANYAR              52.2 <int [7]> <dbl [7]>\n\n\nWe will use set.seed() before performing simulation to ensure that the computation is reproducible. When a random number generator is used, the results can be different each time the code is run, which makes it difficult to reproduce results. By setting the seed to a specific value (e.g., set.seed(1234)), the same random numbers will be generated each time the code is run, making the results reproducible and consistent.\n\nset.seed(1234)\n\n\n\n8.1.4 Computing Gi* Value\nWe will now compute the Gi* value for each sub-district, grouping by Date\n\ngi_values <- vacc_rate_nb |>\n  group_by(Date) |>\n  mutate(gi_values = local_gstar_perm(\n    Vaccination_Rate, nb, wt, nsim=99)) |>\n      tidyr::unnest(gi_values)\n\nLet’s take a look at the Gi* values calculated\n\ngi_values\n\n# A tibble: 3,132 x 13\n# Groups:   Date [12]\n   Date       Sub_Di~1 Vacci~2 nb    wt    gi_star    e_gi  var_gi p_value p_sim\n   <date>     <chr>      <dbl> <lis> <lis>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>\n 1 2021-07-31 KEAGUNG~    53.3 <int> <dbl>   2.44  0.00383 2.13e-8 1.46e-2  0.02\n 2 2021-07-31 GLODOK      61.6 <int> <dbl>   3.85  0.00384 1.56e-8 1.18e-4  0.02\n 3 2021-07-31 HARAPAN~    49.7 <int> <dbl>   0.309 0.00382 2.20e-8 7.57e-1  0.84\n 4 2021-07-31 CEMPAKA~    46.7 <int> <dbl>  -1.05  0.00383 1.53e-8 2.96e-1  0.34\n 5 2021-07-31 PASAR B~    59.3 <int> <dbl>   2.71  0.00383 1.38e-8 6.82e-3  0.02\n 6 2021-07-31 KARANG ~    52.2 <int> <dbl>   1.67  0.00382 2.17e-8 9.49e-2  0.1 \n 7 2021-07-31 MANGGA ~    51.6 <int> <dbl>   1.35  0.00384 1.80e-8 1.77e-1  0.22\n 8 2021-07-31 PETOJO ~    47.2 <int> <dbl>  -0.179 0.00382 1.92e-8 8.58e-1  0.96\n 9 2021-07-31 SENEN       54.4 <int> <dbl>   1.51  0.00382 1.20e-8 1.32e-1  0.1 \n10 2021-07-31 BUNGUR      52.8 <int> <dbl>   0.797 0.00385 1.54e-8 4.25e-1  0.48\n# ... with 3,122 more rows, 3 more variables: p_folded_sim <dbl>,\n#   skewness <dbl>, kurtosis <dbl>, and abbreviated variable names\n#   1: Sub_District, 2: Vaccination_Rate"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualising-the-gi-values-of-monthly-vaccination-rate",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualising-the-gi-values-of-monthly-vaccination-rate",
    "title": "Take-Home Excercise 02",
    "section": "7.2 Visualising the Gi* values of Monthly Vaccination Rate",
    "text": "7.2 Visualising the Gi* values of Monthly Vaccination Rate\nIn order for us to be able to visualize the Gi* values of the monthly vaccination rate, we need to join it with combined_jakarta, to be able to plot the Gi* values on the map. As the gi_values do not have any coordinates.\n\njakarta_gi_values <- combined_jakarta %>%\n  left_join(gi_values)\n\nWe can see that, it has joined them by ‘Sub_District’ and ‘Date’. Now, lets look into what our jakarta_gi_values look like\n\njakarta_gi_values\n\nSimple feature collection with 3132 features and 23 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -3644275 ymin: 663887.8 xmax: -3606237 ymax: 701380.1\nProjected CRS: DGN95 / Indonesia TM-3 zone 54.1\nFirst 10 features:\n   Object_ID Village_Code   Village   Code    Province          City   District\n1      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n2      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n3      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n4      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n5      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n6      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n7      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n8      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n9      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n10     25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n   Sub_District Total_Population       Date Target Not_Yet_Vaccinated\n1     KEAGUNGAN            21609 2022-02-27  17387               2755\n2     KEAGUNGAN            21609 2022-04-30  17387               2593\n3     KEAGUNGAN            21609 2022-06-30  17387               2553\n4     KEAGUNGAN            21609 2021-11-30  17387               3099\n5     KEAGUNGAN            21609 2021-09-30  17387               4203\n6     KEAGUNGAN            21609 2021-08-31  17387               6054\n7     KEAGUNGAN            21609 2021-12-31  17387               2924\n8     KEAGUNGAN            21609 2022-01-31  17387               2783\n9     KEAGUNGAN            21609 2021-07-31  17387               8126\n10    KEAGUNGAN            21609 2022-03-31  17387               2675\n   Vaccination_Rate                      nb\n1          84.15483 1, 2, 39, 152, 158, 166\n2          85.08656 1, 2, 39, 152, 158, 166\n3          85.31662 1, 2, 39, 152, 158, 166\n4          82.17634 1, 2, 39, 152, 158, 166\n5          75.82677 1, 2, 39, 152, 158, 166\n6          65.18088 1, 2, 39, 152, 158, 166\n7          83.18284 1, 2, 39, 152, 158, 166\n8          83.99379 1, 2, 39, 152, 158, 166\n9          53.26393 1, 2, 39, 152, 158, 166\n10         84.61494 1, 2, 39, 152, 158, 166\n                                                                             wt\n1  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n2  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n3  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n4  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n5  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n6  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n7  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n8  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n9  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n10 0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n    gi_star        e_gi       var_gi     p_value p_sim p_folded_sim    skewness\n1  2.478859 0.003831172 8.419778e-10 0.013180341  0.02         0.01 -0.03194341\n2  2.825027 0.003827108 7.494269e-10 0.004727670  0.04         0.02 -0.06356613\n3  2.856078 0.003828377 6.980492e-10 0.004289104  0.02         0.01  0.09797571\n4  2.400280 0.003831389 1.665572e-09 0.016382514  0.02         0.01 -0.75383323\n5  2.340497 0.003839767 1.969413e-09 0.019258078  0.02         0.01 -0.45706127\n6  2.697283 0.003843766 4.229906e-09 0.006990777  0.02         0.01  0.19649652\n7  2.737341 0.003831004 9.440138e-10 0.006193804  0.02         0.01 -0.13372915\n8  2.601179 0.003833862 7.779184e-10 0.009290410  0.02         0.01 -0.51408533\n9  2.442508 0.003830045 2.133669e-08 0.014585591  0.02         0.01 -0.40723702\n10 2.631489 0.003829259 7.973859e-10 0.008501151  0.04         0.02  0.23980167\n      kurtosis                       geometry\n1  -0.81316154 MULTIPOLYGON (((-3626874 69...\n2   0.55021722 MULTIPOLYGON (((-3626874 69...\n3  -0.50749002 MULTIPOLYGON (((-3626874 69...\n4   0.54499553 MULTIPOLYGON (((-3626874 69...\n5   0.28836755 MULTIPOLYGON (((-3626874 69...\n6   0.03187466 MULTIPOLYGON (((-3626874 69...\n7  -0.02562365 MULTIPOLYGON (((-3626874 69...\n8   0.07882560 MULTIPOLYGON (((-3626874 69...\n9   0.28865884 MULTIPOLYGON (((-3626874 69...\n10 -0.20275849 MULTIPOLYGON (((-3626874 69...\n\n\nNow, we can start with the visualization process. Let’s proceed with visualizing the first month (July 2021). We will be plotting both the Gi* value and the p-value of Gi* for the Vaccination Rates.\nNote - As per requirement, we will only be plotting the significant (i.e. p-value < 0.05)\n\ngi_value_plot <- function(date, title) {\n  gi_star_map = tm_shape(filter(jakarta_gi_values, Date == date)) +\n    tm_fill(\"gi_star\") +\n    tm_borders(alpha=0.5) +\n    tm_view(set.zoom.limits = c(6,8)) +\n    tm_layout(main.title = paste(\"Gi* values for vaccination rates in\", title), main.title.size=0.8)\n\n  p_value_map = tm_shape(filter(jakarta_gi_values, Date == date)) +\n    tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n    tm_borders(alpha=0.5) + \n    tm_layout(main.title = paste(\"p-values of Gi* for vaccination rates in\", title), main.title.size=0.8)\n\n  tmap_arrange(gi_star_map, p_value_map)\n}\n\n\ngi_star_plot <- function(date, title) {\n  gi_star_map = tm_shape(filter(jakarta_gi_values, Date == date)) +\n    tm_fill(\"gi_star\") +\n    tm_borders(alpha=0.5) +\n    tm_view(set.zoom.limits = c(6,8)) +\n    tm_layout(main.title = paste(\"Gi* values for vaccination rates in\", title), main.title.size=0.8)\n\n  p_value_map = tm_shape(filter(jakarta_gi_values, Date == date)) +\n    tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n    tm_borders(alpha=0.5) + \n    tm_layout(main.title = paste(\"p-values of Gi* for vaccination rates in\", title), main.title.size=0.8)\n\n  tmap_arrange(gi_star_map, p_value_map)\n}\n\n\ntmap_mode(\"plot\")\ngi_value_plot(\"2021-07-31\", \"July 2021\")\n\n\n\n\n\ngi_value_plot(\"2021-08-31\", \"August 2021\")\n\n\n\n\n\ngi_value_plot(\"2021-09-30\", \"September 2021\")\n\n\n\n\n\ngi_value_plot(\"2021-10-31\", \"October 2021\")\n\n\n\n\n\ngi_value_plot(\"2021-11-30\", \"November 2021\")\n\n\n\n\n\ngi_value_plot(\"2021-12-31\", \"December 2021\")\n\n\n\n\n\ngi_value_plot(\"2022-01-31\", \"January 2022\")\n\n\n\n\n\ngi_value_plot(\"2022-02-27\", \"February 2022\")\n\n\n\n\n\ngi_value_plot(\"2022-03-31\", \"March 2022\")\n\n\n\n\n\ngi_value_plot(\"2022-04-30\", \"April 2022\")\n\n\n\n\n\ngi_value_plot(\"2022-05-31\", \"May 2022\")\n\n\n\n\n\ngi_value_plot(\"2022-06-30\", \"June 2022\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#analysing-the-results",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#analysing-the-results",
    "title": "Take-Home Excercise 02",
    "section": "7.2 Analysing the Results",
    "text": "7.2 Analysing the Results\nWe have plotted p-value less than 0.05. As the p-value represents the probability of observing a clustering. Hence, a significant p-value (i.e., <0.05) suggests that the observed pattern is unlikely to have occurred by chance and may indicate the presence of a spatial process."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualizing-the-gi-values-of-monthly-vaccination-rate",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualizing-the-gi-values-of-monthly-vaccination-rate",
    "title": "Take-Home Excercise 02",
    "section": "8.2 Visualizing the Gi* values of Monthly Vaccination Rate",
    "text": "8.2 Visualizing the Gi* values of Monthly Vaccination Rate\nIn order for us to be able to visualize the Gi* values of the monthly vaccination rate, we need to join it with combined_jakarta, to be able to plot the Gi* values on the map. As the gi_values do not have any coordinates.\n\njakarta_gi_values <- combined_jakarta %>%\n  left_join(gi_values)\n\nWe can see that, it has joined them by ‘Sub_District’ and ‘Date’. Now, lets look into what our jakarta_gi_values look like\n\njakarta_gi_values\n\nSimple feature collection with 3132 features and 23 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -3644275 ymin: 663887.8 xmax: -3606237 ymax: 701380.1\nProjected CRS: DGN95 / Indonesia TM-3 zone 54.1\nFirst 10 features:\n   Object_ID Village_Code   Village   Code    Province          City   District\n1      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n2      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n3      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n4      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n5      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n6      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n7      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n8      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n9      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n10     25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n   Sub_District Total_Population       Date Target Not_Yet_Vaccinated\n1     KEAGUNGAN            21609 2022-02-27  17387               2755\n2     KEAGUNGAN            21609 2022-04-30  17387               2593\n3     KEAGUNGAN            21609 2022-06-30  17387               2553\n4     KEAGUNGAN            21609 2021-11-30  17387               3099\n5     KEAGUNGAN            21609 2021-09-30  17387               4203\n6     KEAGUNGAN            21609 2021-08-31  17387               6054\n7     KEAGUNGAN            21609 2021-12-31  17387               2924\n8     KEAGUNGAN            21609 2022-01-31  17387               2783\n9     KEAGUNGAN            21609 2021-07-31  17387               8126\n10    KEAGUNGAN            21609 2022-03-31  17387               2675\n   Vaccination_Rate                      nb\n1          84.15483 1, 2, 39, 152, 158, 166\n2          85.08656 1, 2, 39, 152, 158, 166\n3          85.31662 1, 2, 39, 152, 158, 166\n4          82.17634 1, 2, 39, 152, 158, 166\n5          75.82677 1, 2, 39, 152, 158, 166\n6          65.18088 1, 2, 39, 152, 158, 166\n7          83.18284 1, 2, 39, 152, 158, 166\n8          83.99379 1, 2, 39, 152, 158, 166\n9          53.26393 1, 2, 39, 152, 158, 166\n10         84.61494 1, 2, 39, 152, 158, 166\n                                                                             wt\n1  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n2  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n3  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n4  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n5  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n6  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n7  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n8  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n9  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n10 0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n    gi_star        e_gi       var_gi     p_value p_sim p_folded_sim    skewness\n1  2.478859 0.003831172 8.419778e-10 0.013180341  0.02         0.01 -0.03194341\n2  2.825027 0.003827108 7.494269e-10 0.004727670  0.04         0.02 -0.06356613\n3  2.856078 0.003828377 6.980492e-10 0.004289104  0.02         0.01  0.09797571\n4  2.400280 0.003831389 1.665572e-09 0.016382514  0.02         0.01 -0.75383323\n5  2.340497 0.003839767 1.969413e-09 0.019258078  0.02         0.01 -0.45706127\n6  2.697283 0.003843766 4.229906e-09 0.006990777  0.02         0.01  0.19649652\n7  2.737341 0.003831004 9.440138e-10 0.006193804  0.02         0.01 -0.13372915\n8  2.601179 0.003833862 7.779184e-10 0.009290410  0.02         0.01 -0.51408533\n9  2.442508 0.003830045 2.133669e-08 0.014585591  0.02         0.01 -0.40723702\n10 2.631489 0.003829259 7.973859e-10 0.008501151  0.04         0.02  0.23980167\n      kurtosis                       geometry\n1  -0.81316154 MULTIPOLYGON (((-3626874 69...\n2   0.55021722 MULTIPOLYGON (((-3626874 69...\n3  -0.50749002 MULTIPOLYGON (((-3626874 69...\n4   0.54499553 MULTIPOLYGON (((-3626874 69...\n5   0.28836755 MULTIPOLYGON (((-3626874 69...\n6   0.03187466 MULTIPOLYGON (((-3626874 69...\n7  -0.02562365 MULTIPOLYGON (((-3626874 69...\n8   0.07882560 MULTIPOLYGON (((-3626874 69...\n9   0.28865884 MULTIPOLYGON (((-3626874 69...\n10 -0.20275849 MULTIPOLYGON (((-3626874 69...\n\n\nNow, we can start with the visualization process. Let’s proceed with visualizing the first month (July 2021). We will be plotting both the Gi* value and the p-value of Gi* for the Vaccination Rates.\nNote - As per requirement, we will only be plotting the significant (i.e. p-value < 0.05)\n\ngi_value_plot <- function(date, title) {\n  gi_star_map = tm_shape(filter(jakarta_gi_values, Date == date)) +\n    tm_fill(\"gi_star\") +\n    tm_borders(alpha=0.5) +\n    tm_view(set.zoom.limits = c(6,8)) +\n    tm_layout(main.title = paste(\"Gi* values for vaccination rates in\", title), main.title.size=0.8)\n\n  p_value_map = tm_shape(filter(jakarta_gi_values, Date == date)) +\n    tm_fill(\"p_sim\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n    tm_borders(alpha=0.5) + \n    tm_layout(main.title = paste(\"p-values of Gi* for vaccination rates in\", title), main.title.size=0.8)\n\n  tmap_arrange(gi_star_map, p_value_map)\n}\n\n\ngi_value_plot(\"2021-07-31\", \"July 2021\")\n\n\n\n\n\ngi_value_plot(\"2021-08-31\", \"August 2021\")\n\n\n\n\n\ngi_value_plot(\"2021-09-30\", \"September 2021\")\n\n\n\n\n\ngi_value_plot(\"2021-10-31\", \"October 2021\")\n\n\n\n\n\ngi_value_plot(\"2021-11-30\", \"November 2021\")\n\n\n\n\n\ngi_value_plot(\"2021-12-31\", \"December 2021\")\n\n\n\n\n\ngi_value_plot(\"2022-01-31\", \"January 2022\")\n\n\n\n\n\ngi_value_plot(\"2022-02-27\", \"February 2022\")\n\n\n\n\n\ngi_value_plot(\"2022-03-31\", \"March 2022\")\n\n\n\n\n\ngi_value_plot(\"2022-04-30\", \"April 2022\")\n\n\n\n\n\ngi_value_plot(\"2022-05-31\", \"May 2022\")\n\n\n\n\n\ngi_value_plot(\"2022-06-30\", \"June 2022\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#analyzing-the-results",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#analyzing-the-results",
    "title": "Take-Home Excercise 02",
    "section": "8.3 Analyzing the Results",
    "text": "8.3 Analyzing the Results\nThe p-value represents the probability of observing a clustering. Sub-districts with significant p-value (i.e., p_value<0.05) suggests that the observed pattern is unlikely to have occurred by chance and may indicate the presence of a spatial process. Hence, the vaccination rate of the sub-district at that period is significant. From the maps plotted, we see that there is in increase in number of sub-districts (with p_values<0.05) in the southern and eastern sub-district.\nNow, lets find the hot and cold spots. The above code filters our sub-districts with p-value<0.05. Hence, we can find which sub-districts are hot or cold spots, depending on their g-value.\n\nsignificant <- function(date, title){\n significant_gi = tm_shape(filter(jakarta_gi_values, Date == date)) +\n    tm_polygons() +\n    tm_shape(filter(jakarta_gi_values, Date == date) %>% filter(p_sim <0.05)) +\n    tm_fill(\"gi_star\",\n            style=\"equal\",\n            n=5) +\n    tm_borders(alpha = 0.5) +\n    tm_layout(main.title = paste(\"Siginificant Gi* values in \", title), main.title.size=0.8)\n  return(significant_gi)\n}\n\n\ntmap_arrange(\n  significant(\"2021-07-31\", \"July 2021\"),\n  significant(\"2021-08-31\", \"August 2021\"),\n  significant(\"2021-09-30\", \"September 2021\"),\n  significant(\"2021-10-31\", \"October 2021\")\n)\n\n\n\n\n\ntmap_arrange(\n  significant(\"2021-11-30\", \"November 2021\"),\n  significant(\"2021-12-31\", \"December 2021\"),\n  significant(\"2022-01-31\", \"January 2022\"),\n  significant(\"2022-02-27\", \"February 2022\")\n)\n\n\n\n\n\ntmap_arrange(\n  significant(\"2022-03-31\", \"March 2022\"),\n  significant(\"2022-04-30\", \"April 2022\"),\n  significant(\"2022-05-31\", \"May 2022\"),\n  significant(\"2022-06-30\", \"June 2022\")\n  )\n\n\n\n\nSub-districts with gi_star > 0 are hot spot areas, where those < 0 are cold spot areas. Hot spot areas are areas with clustering of high concentration of vaccination rate. Where as cold spot areas are sub-districts with low concentration. In the above maps, sub-districts in the shade of green are hot spot areas and those in the shades of red are cold-spot areas.\nIn the beginning, there were more hot-spot areas in the North Jakarta, however, we see a change where most of the hotspots are now concentrated in the South Jakarta. This could be due to higher percentage of ageing population in South Jakarta or an increase in availability and accessibility of vaccine sites in South Jakarta. For the cold spots, some sub-districts in the Center seem to be a cold-spot. This suggests that there is a continuous shortage of vaccine or that the residents are unwilling to take the vaccine."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#mann-kendall-trend-test",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#mann-kendall-trend-test",
    "title": "Take-Home Excercise 02",
    "section": "9.1 Mann-Kendall Trend Test",
    "text": "9.1 Mann-Kendall Trend Test\n\n9.1.1 Sub-District – Halim Perdana Kusumah\n\nhalim_pk <- gi_values |>\n  ungroup() |>\n  filter(Sub_District == \"HALIM PERDANA KUSUMAH\") |>\n  select(Sub_District, Date, gi_star)\n\nNow, we plot the result by using ggplot2 functions.\n\nggplot(data = halim_pk, \n       aes(x = Date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\nWe can also plot this interactively\n\np <- ggplot(data = halim_pk, \n       aes(x = Date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)\n\n\n\n\n\n\nhalim_pk %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 x 5\n    tau     sl     S     D  varS\n  <dbl>  <dbl> <dbl> <dbl> <dbl>\n1 0.394 0.0865    26  66.0  213.\n\n\nThe p-value is 0.086 which is > 0.05 hence p-value is not significant. This result tells us that there is no trend and the data points are independent and identically distributed.\n\n\n9.1.2 Sub-District – Bale Kambang\n\nbale_k <- gi_values |>\n  ungroup() |>\n  filter(Sub_District == \"BALE KAMBANG\") |>\n  select(Sub_District, Date, gi_star)\n\nNow, we plot the results\n\np <- ggplot(data = bale_k, \n       aes(x = Date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)\n\n\n\n\n\n\nbale_k %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 x 5\n    tau     sl     S     D  varS\n  <dbl>  <dbl> <dbl> <dbl> <dbl>\n1 0.576 0.0112    38  66.0  213.\n\n\nThe tau value is greater than 0 indicating a monotonic increasing trend. Further, p-value is 0.01 which is < 0.05 hence p-value is significant. This result tells us that here is an overall upward (positive) trend. This means that as time passes, the Gi* value will increase, thus a higher clustering of high vaccination rate. That is more people will be getting their vaccine.\n\n\n9.1.3 Sub-District – Kamal\n\nkamal <- gi_values |>\n  ungroup() |>\n  filter(Sub_District == \"KAMAL\") |>\n  select(Sub_District, Date, gi_star)\n\nNow, we plot the results\n\np <- ggplot(data = kamal, \n       aes(x = Date, \n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)\n\n\n\n\n\n\nkamal %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 x 5\n     tau       sl     S     D  varS\n   <dbl>    <dbl> <dbl> <dbl> <dbl>\n1 -0.848 0.000162   -56  66.0  213.\n\n\nThe tau value (-0.84) is negative, indicating a strong monotonic decreasing trend. The p-value is 0.0001 which is < 0.05 hence p-value is significant. This result tells us that here is an overall negative trend. As time passes by, the Gi* value will decrease, thus a higher clustering of low vaccination rate. This could either be due to shortage of vaccines or the residents of Kamal are increasingly becoming resistant towards taking vaccine. This is not good, and the issue must be addressed immediately in this pandemic era."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#ehsa-map-of-the-gi-values-of-the-vaccination-rate",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#ehsa-map-of-the-gi-values-of-the-vaccination-rate",
    "title": "Take-Home Excercise 02",
    "section": "9.2 EHSA map of the Gi* values of the vaccination rate",
    "text": "9.2 EHSA map of the Gi* values of the vaccination rate\nIn order for us to find the significant hot and cold spots, we need to conduct the Mann Kendall test on all the subdistricts. Hence, we will conduct this by using the group_by() for Sub_Districts.\n\nehsa <- gi_values %>%\n  group_by(Sub_District) %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>%\n  tidyr::unnest_wider(mk)\n\nThen we arrange to show significant emerging hot/cold spots\n\nemerging <- ehsa %>% \n  arrange(sl, abs(tau)) %>% \n  slice(1:5)\nemerging\n\n# A tibble: 5 x 6\n  Sub_District       tau        sl     S     D  varS\n  <chr>            <dbl>     <dbl> <dbl> <dbl> <dbl>\n1 PETOJO UTARA    -0.970 0.0000156   -64  66.0  213.\n2 KAYU MANIS       0.970 0.0000156    64  66.0  213.\n3 JATINEGARA KAUM  0.939 0.0000287    62  66.0  213.\n4 PISANGAN BARU    0.939 0.0000287    62  66.0  213.\n5 PASAR BARU      -0.939 0.0000288   -62  66.0  213.\n\n\nLastly, we will perform EHSA analysis by using emerging_hotspot_analysis() of sfdep package. It takes a spacetime object x (i.e. vacc_rate_st), and the quoted name of the variable of interest (i.e. Vaccinaton Rate) for .var argument. The k argument is used to specify the number of time lags which is set to 1 by default. Lastly, nsim map numbers of simulation to be performed.\n\nehsa <- emerging_hotspot_analysis(\n  x = vacc_rate_st,\n  .var = \"Vaccination_Rate\",\n  k = 1,\n  nsim = 99\n)\n\nWe then visualize the distribution of the EHSA classes\n\nggplot(data = ehsa,\n       aes(x=classification, fill=classification)) + \n  geom_bar()\n\n\n\n\nFigure above shows that sporadic hot spots class has the high numbers of sub-districts.\nBefore, we visualise the geographic distribution EHSA classes, we need to combine jakarta and ehsa together\n\njakarta_ehsa <- jakarta %>%\n  left_join(ehsa, by = c(\"Sub_District\" = \"location\"))\n\nNext, tmap functions will be used to plot a categorical choropleth map by using the code chunk below.\n\n# We use the filter to filter out values with p-value < 0.05\njakarta_ehsa_sig <- jakarta_ehsa  %>%\n  filter(p_value < 0.05)\ntmap_mode(\"plot\")\ntm_shape(jakarta_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(jakarta_ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\nBelow are the meanings of the terms -\n\nOscilating hotspot - It refers to a spatial pattern where a location or area alternates between being a hot spot (i.e., having a statistically significant high value) and a cold spot (i.e., having a statistically significant low value) over time. These hot-spots have an increasing trend in intensity over time.\nOscilating coldspot - It refers to areas that consistently experience lower values or intensity than surrounding areas, but the intensity levels in these areas fluctuate over time. They have a decreasing trend over time.\nSporadic coldspot - Sub-disticts which exhibits unusually low values for vaccination rate, as compared to its surrounding areas.\nNo pattern detected - Sub-districts that do not fall into any hot or cold spot patterns\n\nThe maps shows the largest number of oscillating hotspots which are located evenly in Jakarta. This means that there is a fluctuation between people getting vaccine with people not being able to get vaccine. This could be due to shortage of vaccines sometimes. This is followed by Spordiac coldspot (lesser than oscillating hotspots), which is quite spread out in Jakarta. These have extremely low vaccination rate and hence, needs to be looked at immediately. This is lastly followed by Oscilating coldspot which appear to be more around the border and in the central of Jakarta. Lastly, there are areas with no pattern detected, these are mainly located in the central area. Further, the sub-districts with p-value > 0.05 are in grey colour as they are insignificant."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#converting-dataframs-to-sf-objects",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#converting-dataframs-to-sf-objects",
    "title": "Take-Home Excercise 02",
    "section": "6.1 Converting dataframs to sf objects",
    "text": "6.1 Converting dataframs to sf objects\nBefore we move on into the mapping, we need to convert the dataframes into sf objects. We will convert combined_jakarta and vaccination_rate which will be using for our analysis.\n\ncombined_jakarta <- st_as_sf(combined_jakarta)\n\n# need to join our previous dataframes with the geospatial data to ensure that geometry column is present\nvaccination_rate <- vaccination_rate%>% left_join(jakarta, by=c(\"Sub_District\"=\"Sub_District\"))\nvaccination_rate <- st_as_sf(vaccination_rate)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "title": "Hands-On Excercise 09 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "pacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary, readr, dplyr, ggpubr)\n\npackage 'ggpubr' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Mayuri Salunke\\AppData\\Local\\Temp\\RtmpquoBCp\\downloaded_packages\npackage 'vctrs' successfully unpacked and MD5 sums checked\npackage 'cli' successfully unpacked and MD5 sums checked\npackage 'dplyr' successfully unpacked and MD5 sums checked\npackage 'tidyverse' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Mayuri Salunke\\AppData\\Local\\Temp\\RtmpquoBCp\\downloaded_packages\npackage 'gtsummary' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Mayuri Salunke\\AppData\\Local\\Temp\\RtmpquoBCp\\downloaded_packages\npackage 'ggpubr' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Mayuri Salunke\\AppData\\Local\\Temp\\RtmpquoBCp\\downloaded_packages"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#updating-crs-information",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#updating-crs-information",
    "title": "Hands-On Excercise 09 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Updating CRS Information",
    "text": "Updating CRS Information\n\nmpsz_svy21 <- st_transform(mpsz, 3414)\n\n\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_bbox(mpsz_svy21) #view extent\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#converting-aspatial-data-frame-into-a-sf-object",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#converting-aspatial-data-frame-into-a-sf-object",
    "title": "Hands-On Excercise 09 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Converting aspatial data frame into a sf object",
    "text": "Converting aspatial data frame into a sf object\n\ncondo_resale.sf <- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %>%\n  st_transform(crs=3414)\n\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLI…¹ AREA_…²   AGE PROX_…³ PROX_…⁴ PROX_…⁵ PROX_…⁶ PROX_…⁷ PROX_…⁸\n     <dbl>   <dbl>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1   118635 3000000     309    30    7.94   0.166   2.52     6.62   1.77   0.0584\n2   288420 3880000     290    32    6.61   0.280   1.93     7.51   0.545  0.616 \n3   267833 3325000     248    33    6.90   0.429   0.502    6.46   0.378  0.141 \n4   258380 4250000     127     7    4.04   0.395   1.99     4.91   1.68   0.382 \n5   467169 1400000     145    28   11.8    0.119   1.12     6.41   0.565  0.461 \n6   466472 1320000     139    22   10.3    0.125   0.789    5.09   0.781  0.0994\n# … with 12 more variables: PROX_MRT <dbl>, PROX_PARK <dbl>,\n#   PROX_PRIMARY_SCH <dbl>, PROX_TOP_PRIMARY_SCH <dbl>,\n#   PROX_SHOPPING_MALL <dbl>, PROX_SUPERMARKET <dbl>, PROX_BUS_STOP <dbl>,\n#   NO_Of_UNITS <dbl>, FAMILY_FRIENDLY <dbl>, FREEHOLD <dbl>,\n#   LEASEHOLD_99YR <dbl>, geometry <POINT [m]>, and abbreviated variable names\n#   ¹​SELLING_PRICE, ²​AREA_SQM, ³​PROX_CBD, ⁴​PROX_CHILDCARE, ⁵​PROX_ELDERLYCARE,\n#   ⁶​PROX_URA_GROWTH_AREA, ⁷​PROX_HAWKER_MARKET, ⁸​PROX_KINDERGARTEN"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#eda-using-statistical-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#eda-using-statistical-graphics",
    "title": "Hands-On Excercise 09 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "EDA using statistical graphics",
    "text": "EDA using statistical graphics\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\ncondo_resale.sf <- condo_resale.sf %>%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#multiple-histogram-plots-distribution-of-variables",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#multiple-histogram-plots-distribution-of-variables",
    "title": "Hands-On Excercise 09 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Multiple Histogram Plots distribution of variables",
    "text": "Multiple Histogram Plots distribution of variables\n\nAREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n#ggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n #         PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n  #        PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n   #       ncol = 3, nrow = 4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#drawing-statistical-point-map",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#drawing-statistical-point-map",
    "title": "Hands-On Excercise 09 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Drawing Statistical Point Map",
    "text": "Drawing Statistical Point Map\n\ntmap_mode(\"view\")\n\n\n#tm_shape(mpsz_svy21)+\n  #tm_polygons() +\n#tm_shape(condo_resale.sf) +  \n  #tm_dots(col = \"SELLING_PRICE\",\n   #       alpha = 0.6,\n    #      style=\"quantile\") +\n  #tm_view(set.zoom.limits = c(11,14))\n\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#simple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#simple-linear-regression-method",
    "title": "Hands-On Excercise 09 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Simple Linear Regression Method",
    "text": "Simple Linear Regression Method\n\ncondo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: < 2.2e-16\n\n\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#multiple-linear-regression-method",
    "title": "Hands-On Excercise 09 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Multiple Linear Regression Method",
    "text": "Multiple Linear Regression Method\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "title": "Hands-On Excercise 09 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Building a hedonic pricing model using multiple linear regression method",
    "text": "Building a hedonic pricing model using multiple linear regression method\n\ncondo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  < 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  < 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  < 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  < 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#preparing-publication-quality-table-olsrr-method",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#preparing-publication-quality-table-olsrr-method",
    "title": "Hands-On Excercise 09 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Preparing Publication Quality Table: olsrr method",
    "text": "Preparing Publication Quality Table: olsrr method\n\ncondo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                             Model Summary                               \n------------------------------------------------------------------------\nR                       0.807       RMSE                     755957.289 \nR-Squared               0.651       Coef. Var                    43.168 \nAdj. R-Squared          0.647       MSE                571471422208.591 \nPred R-Squared          0.638       MAE                      414819.628 \n------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#preparing-publication-quality-table-gtsummary-method",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#preparing-publication-quality-table-gtsummary-method",
    "title": "Hands-On Excercise 09 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Preparing Publication Quality Table: gtsummary method",
    "text": "Preparing Publication Quality Table: gtsummary method\n\n#tbl_regression(condo.mlr1, intercept = TRUE)\n\n\n#tbl_regression(condo.mlr1, \n #              intercept = TRUE) %>% \n  #add_glance_source_note(\n   # label = list(sigma ~ \"\\U03C3\"),\n    #include = c(r.squared, adj.r.squared, \n     #           AIC, statistic,\n      #          p.value, sigma))\n\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\n\nols_test_normality(condo.mlr1)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\n\nmlr.output <- as.data.frame(condo.mlr1$residuals)\n\n\ncondo_resale.res.sf <- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %>%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\n\ncondo_resale.sp <- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\n\ntmap_mode(\"view\")\n\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\nnb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\n\nnb_lw <- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-fixed-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-fixed-bandwidth-gwr-model",
    "title": "Hands-On Excercise 09 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Building Fixed Bandwidth GWR Model",
    "text": "Building Fixed Bandwidth GWR Model\n\nbw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\n\ngwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\n\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-03-05 19:22:07 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2023-03-05 19:22:08"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-adaptive-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-adaptive-bandwidth-gwr-model",
    "title": "Hands-On Excercise 09 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Building Adaptive Bandwidth GWR Model",
    "text": "Building Adaptive Bandwidth GWR Model\n\nbw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\n\ngwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\n\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-03-05 19:22:16 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2023-03-05 19:22:17"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualising-gwr-output",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualising-gwr-output",
    "title": "Hands-On Excercise 09 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Visualising GWR Output",
    "text": "Visualising GWR Output\n\ncondo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%\n  st_transform(crs=3414)\n\n\ncondo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.94        0   -0.72065800   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\n\n\ngwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\n\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                <dbl> 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       <dbl> 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 <dbl> -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               <dbl> 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              <dbl> 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   <dbl> -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              <dbl> -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        <dbl> 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      <dbl> -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  <dbl> -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              <dbl> -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             <dbl> -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      <dbl> 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    <dbl> 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         <dbl> 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           <dbl> 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       <dbl> -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              <dbl> 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    <dbl> 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                <dbl> 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           <dbl> 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            <dbl> 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             <dbl> 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  <dbl> 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             <dbl> 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       <dbl> 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     <dbl> 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE <dbl> 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             <dbl> 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            <dbl> 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     <dbl> 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   <dbl> 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        <dbl> 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          <dbl> 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      <dbl> 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             <dbl> 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            <dbl> 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             <dbl> 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  <dbl> -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             <dbl> -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       <dbl> 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     <dbl> -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV <dbl> -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             <dbl> -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            <dbl> -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     <dbl> 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   <dbl> 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        <dbl> 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          <dbl> 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      <dbl> -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             <dbl> 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                <dbl> 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               <dbl> 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               <dbl> 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                <POINT [m]> POINT (22085.12 29951.54), POINT (25656.…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualising-local-r2",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualising-local-r2",
    "title": "Hands-On Excercise 09 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Visualising local R2",
    "text": "Visualising local R2\n\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualising-coefficient-estimates",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualising-coefficient-estimates",
    "title": "Hands-On Excercise 09 : Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Visualising coefficient estimates",
    "text": "Visualising coefficient estimates\n\ntmap_mode(\"view\")\nAREA_SQM_SE <- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV <- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  }
]